import json, os, time
import pandas as pd

from multiprocessing import Pool, current_process
from configs import AVAILABLE_LLMs
from prompt_agent import PromptAgent
from data_agent import DataAgent
from model_agent import ModelAgent
from operation_agent import OperationAgent
from utils import print_message, get_client
from num2words import num2words
from agent_manager.retriever import retrieve_knowledge
from glob import glob

from experiments import FREE_PROMPTS

# ê¸°ë³¸ ë²„ì „
# agent_profile = """You are a helpful assistant."""

# ì—­í•  ëª…ì‹œ ë²„ì „: assistant
# agent_profile = """You are a helpful assistant. You have two main responsibilities as follows.
# 1. Receive requirements and/or inquiries from users through a well-structured JSON object.
# 2. Using recent knowledge and state-of-the-art studies to devise promising high-quality plans for data scientists, machine learning research engineers, and MLOps engineers in your team to execute subsequent processes based on the user requirements you have received.
# """

#  AutoML í”„ë¡œì íŠ¸ì˜ ì‹œë‹ˆì–´ PM ê°•ì¡° ë²„ì „ : ë‹¨ìˆœ ë„ì›€ì„ ë„˜ì–´ì„œ íŒ€ ë‚´ ë°ì´í„°Â·ëª¨ë¸Â·MLOps ë‹´ë‹¹ì ê´€ë¦¬
# agent_profile = """You are a senior project manager of a automated machine learning project (AutoML). You have two main responsibilities as follows.
# 1. Receive requirements and/or inquiries from users through a well-structured JSON object.
# 2. Using recent knowledge and state-of-the-art studies to devise promising high-quality plans for data scientists, machine learning research engineers, and MLOps engineers in your team to execute subsequent processes based on the user requirements you have received.
# """

# ê²½í—˜ ê°•ì¡° ë²„ì „
agent_profile = """You are an experienced senior project manager of a automated machine learning project (AutoML). You have two main responsibilities as follows.
1. Receive requirements and/or inquiries from users through a well-structured JSON object.
2. Using recent knowledge and state-of-the-art studies to devise promising high-quality plans for data scientists, machine learning research engineers, and MLOps engineers in your team to execute subsequent processes based on the user requirements you have received.
"""
# ì„¸ê³„ ìµœê³  PMë²„ì „
# agent_profile = """You are the world's best senior project manager of a automated machine learning project (AutoML). You have two main responsibilities as follows.
# 1. Receive requirements and/or inquiries from users through a well-structured JSON object.
# 2. Using recent knowledge and state-of-the-art studies to devise promising high-quality plans for data scientists, machine learning research engineers, and MLOps engineers in your team to execute subsequent processes based on the user requirements you have received.
# """

## json í˜•íƒœë¡œ ML ê°œë°œ ê³„íšì„ ì‘ì„±í•˜ë„ë¡ ì§€ì¹¨
json_plan = """Each of the following plans should cover the entire process of machine learning model development when applicable based on the given requirements, i.e., from problem formulation to deployment.
Please ansewer your plans in list of the JSON object with `title` and `steps` keys."""

# _is_relevant,_is_enough()ì—ì„œ system prompt
basic_profile = """You are a helpful, respectful and honest "human" assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.
If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."""

plan_conditions = """
- Ensure that your plan is up-to-date with current state-of-the-art knowledge.
- Ensure that your plan is based on the requirements and objectives described in the above JSON object.
- Ensure that your plan is designed for AI agents instead of human experts. These agents are capable of conducting machine learning and artificial intelligence research.
- Ensure that your plan is self-contained with sufficient instructions to be executed by the AI agents. 
- Ensure that your plan includes all the key points and instructions (from handling data to modeling) so that the AI agents can successfully implement them. Do NOT directly write the code.
- Ensure that your plan completely include the end-to-end process of machine learning or artificial intelligence model development pipeline in detail (i.e., from data retrieval to model training and evaluation) when applicable based on the given requirements."""

possible_states = {
    "INIT": "",
    "PLAN": "",
    "ACT": "",
    "PRE_EXEC": "",
    "EXEC": "",
    "POST_EXEC": "",
    "REV": "",
    "RES": "",
}

"""
ì—ì´ì „íŠ¸/ì‹œìŠ¤í…œ ìƒíƒœ ê´€ë¦¬ìš© ë”•ì…”ë„ˆë¦¬

INIT: ì´ˆê¸° ìƒíƒœ
PLAN: ê³„íš ìˆ˜ë¦½
ACT: í™œë™ ë‹¨ê³„
PRE_EXEC: ì‹¤í–‰ ì „ ì¤€ë¹„
EXEC: ì‹¤í–‰ ì¤‘
POST_EXEC: ì‹¤í–‰ í›„
REV: ê²€í† 
RES: ê²°ê³¼
"""

# prompt Agentê°ì²´ ìƒì„± ::: managerê°ì²´ ì•„ë‹˜!
# ì‚¬ìš©ì ìì—°ì–´ë¥¼ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• 
# ./prompt_agent >> WizardLAMP í™•ì¸í•˜ê¸°
parser = PromptAgent()

class AgentManager:
    """
    ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì´ê´„í•˜ëŠ” ë§¤ë‹ˆì € ì—­í• 
    - ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ê³„íš(plan)ì„ ê´€ë¦¬
    - ì—¬ëŸ¬ ì—ì´ì „íŠ¸(DataAgent, ModelAgent, OperationAgent)ì™€ ì—°ê³„
    - ê³„íš ì‹¤í–‰ê³¼ ê²°ê³¼ ìˆ˜ì§‘
    - ìƒíƒœ ê´€ë¦¬, ì¬ì‹œë„, ê²€ì¦ ë“± ì „ì²´ AutoML íŒŒì´í”„ë¼ì¸ ì¡°ì •
    
    í•¨ìˆ˜ :
    make_plans
    execute_plan --> Data,Model Agent ì‹¤í–‰
    verify_solution
    implement_solution
    generate_reply
    _is_relevant : ML/AI ê´€ë ¨ ë‚´ìš©ì¸ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜(llm-based)
    _is_enough() : Auto<ML ìˆ˜í–‰ì— ì¶©ë¶„í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜(llm-based)
    
    
    """
    
    def __init__(
        self,
        task,                                           # task == downstream = 'tabular_classification'
        n_plans=3,                                      # ìƒì„±í•  ê³„íš
        n_candidates=3,                                 # ê³„íš í›„ë³´
        n_revise=3,                                     # ìˆ˜ì • íšŸìˆ˜
        device=0,
        interactive=False,                              # Trueë©´, ìƒíƒœ ì „í™˜ ì‹œ ì‚¬ìš©ì í™•ì¸ í—ˆìš©
        llm="qwen",
        user_requirements=None,                         # user_requirements : json í˜•íƒœ / ì—†ë‹¤ë©´ []ë¡œ ë°˜í™˜ë¨
        plans=None,                                     # plans: json í˜•íƒœ / ì—†ë‹¤ë©´ []ë¡œ ë°˜í™˜ë¨ 
        plan_knowledge='./example_plans/plan_knowledge.md',                                 # './example_plans/plan_knowledge.md',   
        data_path=None,                                 # í…ŒìŠ¤íŠ¸í•  ë•Œ ì‘ì„± í•„ìš”
        full_pipeline=True,
        rap=True,
        decomp=True,
        verification=True,
        result_path=None,
        instruction_path=None,                          # ì½”ë“œ ë° ì‹¤í–‰ ì§€ì¹¨ íŒŒì¼ ê²½ë¡œ(ì¶”ì¸¡)
        exp_configs=None,
        uid=None,                                           # ì‚¬ìš©ì/ì‹¤í—˜ ID?
        inj=None
    ):
        # Setup Agent Manager
        self.agent_type = "manager"
        self.exp_config = exp_configs  # {"task": "", "prompt_type": "", "uid": 0}
        self.rap = rap
        self.decomp = decomp
        self.verification = verification
        self.full_pipeline = full_pipeline
        self.llm = llm
        self.model = AVAILABLE_LLMs[llm]["model"]
        self.chats = []                                         # generate_reply() :: Agentê°€ ìœ ì§€ ì¤‘ì¸ ì „ì²´ ëŒ€í™” ê¸°ë¡ (ëŒ€í™” íˆìŠ¤í† ë¦¬)
        self.state = "INIT"                     # ì´ˆê¸° ìƒíƒœë¡œ ì‹œì‘
        
        # Plan and Result
        if plans != None:
            f = open(plans)
            self.plans = json.load(f)
        else:
            self.plans = []
        self.action_results = []
        
        # AgentManagerê°€ ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš©(interactive) ëª¨ë“œì¸ì§€ ì—¬ë¶€
        # í•œ ë²ˆì˜ ì…ë ¥/ì¶œë ¥ìœ¼ë¡œ ëë‚˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì—¬ëŸ¬ í„´ì˜ ëŒ€í™”ë¥¼ ê°•ì œí•  ìˆ˜ ìˆìŒ : ìë™í™” íŒŒì´í”„ë¼ì¸ ì¤‘ê°„ì¤‘ê°„ì— ì‚¬ìš©ì í™•ì¸/ìŠ¹ì¸ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ëª¨ë“œ
        self.interactive = interactive  # enable the manager to ask user before proceeding to the next state (force multi-turn dialogue)
        # ex : ê³„íš ë‹¨ê³„ì—ì„œ LLMì´ ìƒì„±í•œ ê³„íšì„ í™•ì¸í•˜ê³  ì‚¬ìš©ìê°€ ìˆ˜ì •í•  ìˆ˜ ìˆìŒ 
        # ìë™ ëª¨ë“œ(interactive=False)ì¼ ê²½ìš° â†’ ìë™ìœ¼ë¡œ ë‹¤ìŒ ìƒíƒœ ì§„í–‰, ì‚¬ìš©ì ê°œì… ì—†ìŒ
        if user_requirements != None:
            f = open(user_requirements)
            self.user_requirements = json.load(f)
        else:
            self.user_requirements = None
        self.req_summary = ""
        self.has_valid_requirement = False
        self.n_plans = n_plans
        self.n_candidates = n_candidates
        self.n_revise = n_revise
        self.is_solution_found = False
        if plan_knowledge != None:
            with open(plan_knowledge, "r") as f:                    # plan_knowledge, "r"
                self.plan_knowledge = f.read()
        else:
            self.plan_knowledge = None
            print("############## í™•ì¸ìš© : plan_knowledge==None")
        self.data_path = data_path
        self.device = device
        
        # result_path ì´ì „ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ë¡œë“œ, EXECìƒíƒœë¡œ ì „í™˜
        if result_path:
            plans = glob(result_path + "/*")
            for plan in plans:
                f = open(plan)
                self.action_results.append(json.load(f))
                self.state = "EXEC"
        if instruction_path:
            with open(instruction_path + "/code_instruction.txt", "r") as f:
                self.code_instruction = f.read()
        else:
            self.code_instruction = None
        if exp_configs:
            self.code_path = f"/{self.llm}_{exp_configs.task}_{exp_configs.prompt_type}_{exp_configs.uid}"
        else:
            self.code_path = f"/{uid}_{self.llm}_p{self.n_plans}_{'rap' if self.rap else ''}_{'decomp' if self.decomp else ''}_{'ver' if self.verification else ''}_{'full' if self.full_pipeline else ''}"
        self.n_attempts = 0
        self.task = task
        self.inj = inj
        self.timer = {}
        self.money = {}

    def make_plans(self, is_revision=False):
        """
        new plan ìƒì„±
        ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­(self.user_requirements) + ê´€ë ¨ ì§€ì‹(self.plan_knowledge)ìœ¼ë¡œ ì—¬ëŸ¬ ê°œì˜ end-to-actionable plan ìƒì„±
        
        is_revision
        ì´ì „ ê³„íšì´ ì‹¤íŒ¨í–ˆì„ ë•Œ, ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ í›„ ê°œì„ ëœ ê³„íš ìƒì„±
        
        instruction: Prompt Agentê°€ ì‚¬ìš©ì ì…ë ¥ì„ íŒŒì‹±í•˜ë„ë¡ ì•ˆë‚´
        """
        # planning should include action_id, completion_status, action_dependencies (with required prior action ids), and
        # instruction (i.e., prompt to tell how Prompt Agent should parse user's input prompt (e.g., what keys should be included etc.)) for the repsective agent(s) responding to the given tasks
        
        ### ê³„íš ìˆ˜ì •
        if is_revision:
            start_time = time.time()
            fail_prompt = "I found that all the plans you provided are failed or unsatisfied with the given requirements. Now, your task is to find the reasons 'why' and 'how' the above plans were unsatisfied by carefully comparing them with the requirements again. Please answer me your findings and insights as we will use them to create the new set of plans."
            fail_rationale = self.generate_reply(
                system_prompt=agent_profile,
                user_prompt=fail_prompt,
                return_content=True,
                caller_id='manager_fail_plan_reflection'
            )
            print_message(
                self.agent_type,
                "Sorry, I am revising the plans for you ğŸ’­.",
            )
            plan_prompt = f"""Now, you will be asked to revise and rethink {num2words(self.n_plans)} different end-to-end actionable plans according to the user's requirements described in the JSON object below.
            
            ```json
            {self.user_requirements}
            ```
            
            Please use to the following findings and insights summarized from the previously failed plans. Try as much as you can to avoid the same failure again.
            {fail_rationale}
            
            Finally, when devising a plan, follow these instructions and do not forget them:
            {plan_conditions}
            """
            self.plans = []
            self.timer[f'fail_plan_reflection_{self.n_attempts}'] = time.time() - start_time
        else:
            start_time = time.time()
            # retrieve relevant knowledge/expereince (from internal and external sources) for effective planning
            
            ## ìˆ˜ì • False,
            ### ìƒˆ ê³„íš ìƒì„±
            if self.plan_knowledge == None and self.rap and self.inj in [None, 'pre']:      # ì•„ì§ ê³„íšì„ ìœ„í•œ ì°¸ì¡° ì§€ì‹ì´ ì—†ëŠ” ê²½ìš°
                self.plan_knowledge = retrieve_knowledge(self.user_requirements, self.req_summary, llm=self.llm, inj=self.inj)
            else:
                # ì¶”ê°€ í›„ì²˜ë¦¬(post_noise) :: retrieve_knowledge í•¨ìˆ˜ ver2 ì‚¬ìš©í•¨
                # self.plan_knowledge, self.post_noise = retrieve_knowledge(self.user_requirements, self.req_summary, llm=self.llm, inj=self.inj)
                #self.plan_knowledge = f""""{self.plan_knowledge}\r\nHere is a list of knowledge written by an AI agent for a relevant task:\r\n{self.post_noise}"""
                pass
            print_message(
                self.agent_type,
                f"Now, I am making a set of plans for you based on your requirements and the following knowledge ğŸ’­.\n{self.plan_knowledge}",
            )
            self.timer['retrieve_knowledge'] = time.time() - start_time
            
            # Independent Planning (i.e., The agent does not know how it previously made the plans. Pros: Significantly less contexnt length consumption --> have room for knowledge sources, Cons: Diversity is not guaranteed.)
            plan_prompt = f"""Now, I want you to devise an end-to-end actionable plan according to the user's requirements described in the following JSON object.
            
            ```json
            {self.user_requirements}
            ```
            
            Here is a list of past experience cases and knowledge written by an human expert for a relevant task: 
            {self.plan_knowledge}

            When devising a plan, follow these instructions and do not forget them:
            {plan_conditions}
            """

        ### LLMí˜¸ì¶œ ë° ê³„íš ìƒì„±
        start_time = time.time()
        for i in range(1, self.n_plans + 1):
            print(f"########################## make_plansì—ì„œ ì‹¤í–‰ë˜ê³  ìˆìŒ. : {i}ë²ˆì§¸ LLM \n")
            messages = [
                {"role": "system", "content": agent_profile},
                {"role": "user", "content": plan_prompt},
            ]
            while True:
                try:
                    response = get_client(self.llm).chat.completions.create(
                        model=self.model, messages=messages, temperature=0.7
                    )
                    break
                except Exception as e:
                    print_message("system", e)
                    continue
            plan = response.choices[0].message.content.strip()
            self.plans.append(plan)
            self.money[f'manager_plan_{i}'] = response.usage.to_dict(mode='json')
            print(f"##########################: {i}ë²ˆì§¸ LLM ê³„íš : \n{plan}\n###################################### {i}ë²ˆì§¸ LLM ê³„íš END plan part \n")
        self.timer['planning'] = time.time() - start_time

    def execute_plan(self, plan):
        """
        ë‹¨ì¼ ê³„íšì„ ì‹¤ì œë¡œ ìˆ˜í–‰í•˜ëŠ” ì—­í• (################# 3. ACT ë‹¨ê³„)
        
        1. Data Agent
        2. Model Agent
        
        return ::
        Dict(ê²°ê³¼ str)
        """
        
        print(f"################# 3. ACT ë‹¨ê³„(í™•ì¸ìš©) execute_plan í•¨ìˆ˜ : \n")
        ############### ì—¬ê¸° ìˆ˜ì • ê³ ë¯¼ì¤‘
        # plan = FREE_PROMPTS["tabular"]["tabular_classification"][0]

        # langauge (text) based execution
        pid = current_process()._identity[0]  # for checking the current plan : í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ID ê°€ì ¸ì˜´(ê° ê³„íš ì‹¤í–‰ ê²°ê³¼ë¥¼ êµ¬ë¶„ìš©)

        ######### 1. Data Agent ì‹¤í–‰ #########################
        start_time = time.time()
        # Data Agent generates the results after execute the given plan
        data_llama = DataAgent(
            user_requirements=self.user_requirements,
            llm=self.llm,
            rap=self.rap,
            decomp=self.decomp,
        )
        ############## ì‹¤í—˜ì„ ìœ„í•œ
        add_prompt = "\n\n **Important Instruction: All data loading must strictly use the absolute path specified. Do not attempt relative paths or alternative locations.**\n**Be careful not to import from incorrect modules. Do not import from non-existent paths.**\n\n"
        
        data_result = data_llama.execute_plan(plan, self.data_path, pid)      
        data_result +=add_prompt

        print(f"################# 3. ACT ë‹¨ê³„(Data Agentëª¨ë¸ ìˆ˜í–‰) execute_plan - ê²°ê³¼ : \n{data_result}\n################# Data Agentëª¨ë¸ data_result END ########\n")  
        # # data_result(str) :
        # # LLMì´ ìƒì„±í•œ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ ë‹¨ê³„ ì„¤ëª…((ë¬¸ìì—´, ì „ì²˜ë¦¬Â·ì¦ê°•Â·íŠ¹ì„± ì¶”ì¶œ ë‹¨ê³„ í¬í•¨))
        
        self.timer[f'data_execution_{pid}'] = time.time() - start_time
        self.money['Data'] = data_llama.money

        ######### 2. Model Agent ì‹¤í–‰ #########################
        # Model Agent summarizes the given plan for optimizing data relevant processes : ëª¨ë¸ ì—ì´ì „íŠ¸ëŠ” ì£¼ì–´ì§„ ê³„íšì„ ìš”ì•½í•˜ì—¬ ë°ì´í„° ê´€ë ¨ í”„ë¡œì„¸ìŠ¤ë¥¼ ìµœì í™”
        # Model Agent generates the results after execute the given plan : ëª¨ë¸ ì—ì´ì „íŠ¸ëŠ” ì£¼ì–´ì§„ ê³„íšì„ ì‹¤í–‰í•œ í›„ ê²°ê³¼ë¥¼ ìƒì„±
        start_time = time.time()
        model_llama = ModelAgent(
            user_requirements=self.user_requirements,
            llm=self.llm,
            rap=self.rap,
            decomp=self.decomp,
        )
        model_result = model_llama.execute_plan(
            k=self.n_candidates, project_plan=plan, data_result=data_result, pid=pid            # data_result :: Data Agentê°€ ì¶œë ¥í•œ ê²°ê³¼(str, ì¸ì‚¬ì´íŠ¸)ê¸°ë°˜ ë°ì´í„° ê¸°ë°˜ ëª¨ë¸ë§ ì§„í–‰
        )
        print(f"################# 3. ACT ë‹¨ê³„(Model Agentëª¨ë¸ ìˆ˜í–‰) execute_plan í•¨ìˆ˜ : {model_result}\n")  
        ## model_result ê²°ê³¼ íƒ€ì… í™•ì¸í•˜ê¸°
        self.timer[f'model_execution_{pid}'] = time.time() - start_time
        self.money['Model'] = model_llama.money
        
        return {"data": data_result, "model": model_result}

    def verify_solution(self, solution):
        """
        
        return ::
        (str) pass or fail
        """
        
        
        pid = current_process()._identity[0]  # for checking the current plan
        
        start_time = time.time()
        
        is_pass = False

        # pre-execution verification
        # LLMì—ê²Œ **ì†”ë£¨ì…˜ì´ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ”ì§€** íŒë‹¨í•˜ë„ë¡ ìš”ì²­  
        verification_prompt = """Given the proposed solution and user's requirements, please carefully check and verify whether the proposed solution 'pass' or 'fail' the user's requirements.
        
        **Proposed Solution and Its Implementation**
        Data Manipulation and Analysis: {}
        Modeling and Optimization: {}
        
        **User Requirements**
        ```json
        {}
        ```
                
        Answer only 'Pass' or 'Fail'
        """ 

        prompt = verification_prompt.format(
            solution["data"], solution["model"], self.user_requirements
        )
        messages = [
            {"role": "system", "content": basic_profile},
            {"role": "user", "content": prompt},
        ]

        
        # res : ê²°ê³¼ ë©”ì„¸ì§€ëŠ” promptì— ì˜í•´ pass or fail
        while True:
            try:
                res = get_client(self.llm).chat.completions.create(
                    model=self.model, messages=messages, temperature=0
                )
                break
            except Exception as e:
                print_message("system # Error Function :: Agent Manager verify_solution #", e)
                continue
        ans = res.choices[0].message.content.strip()                                       
        is_pass = "pass" in ans.lower()
        self.money['manager_execution_verification'] = res.usage.to_dict(mode='json')
        
        self.timer[f'execution_verification_{pid}'] = time.time() - start_time

        return is_pass

    def implement_solution(self, selected_solution):
        """
        ############ ì‹¤ì œë¡œ python ì½”ë“œë¥¼ ìˆ˜í–‰í•˜ëŠ” êµ¬ê°„ :: ops_llama.implement_solutionì˜ ê²°ê³¼ê°’ ops_result
        Manager Agentê°€ ì„ ì •ëœ ê³„íš/ì†”ë£¨ì…˜(selected_solution)ì„ ê°€ì ¸ì˜¤ê³ , ì½”ë“œ í…œí”Œë¦¿ë„ ê°€ì ¸ì˜´. OperationAgentì—ê²Œ ì‹¤ì œ ì‹¤í–‰ì„ ë§¡ê¸°ëŠ” êµ¬ì¡°
        selected_solutionëŠ” generate_replayë¡œ ìƒì„±ë¨
        
        prompt_pool/{self.task}.py : â€œOperationAgentê°€ ì‹¤ì œë¡œ ì½”ë“œë¥¼ ì‚½ì…í•˜ê³  ì‹¤í–‰í•  í‹€(frame)â€
        code_path : ìƒì„±ëœ ì½”ë“œê°€ ì €ì¥ë  ê²½ë¡œ
        code_instructions == selected_solution = Model/Data Agentê°€ ë§Œë“  ìµœì¢… ì†”ë£¨ì…˜ì˜ ì§€ì‹œë¬¸ (pseudo codeë‚˜ step-by-step)
        
        """
        with open(f"prompt_pool/{self.task}.py") as file:
            template_code = file.read()        
        # code-based execution
        ops_llama = OperationAgent(
            user_requirements=self.user_requirements,
            llm=self.llm,
            code_path=self.code_path,
            device=self.device,
        )
        ops_result = ops_llama.implement_solution(
            code_instructions=selected_solution, 
            full_pipeline=self.full_pipeline, 
            code=template_code
        )
        self.money['Operation'] = ops_llama.money
        return ops_result

    def generate_reply(
        self,
        user_prompt,
        system_prompt=basic_profile,
        return_content=False,                       # Trueë©´ return ê°’ì´ llmìˆœìˆ˜ í…ìŠ¤íŠ¸, Falseë©´ ì‘ë‹µêµ¬ì¡°(ë©”íƒ€ë°ì´í„°)
        system_use=False,
        caller_id=None
    ):
        """
        AgentManager, DataAgent, ModelAgent ë“± ëª¨ë“  ì—ì´ì „íŠ¸ë“¤ì´ ê³µí†µì ìœ¼ë¡œ LLMì—ê²Œ â€œì§ˆë¬¸ â†’ ë‹µë³€â€ì„ ìš”ì²­í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ìœ í‹¸ í•¨ìˆ˜
        LLMì—ê²Œ ì§ˆë¬¸í•˜ê³ , ë‹µë³€ì„ ë°›ì•„, ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì—­í• 
        
        ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸(user_prompt) + ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(system_prompt) -> LLM -> ì‘ë‹µ(response)
        
        self.chats :  í˜„ì¬ Agentê°€ ìœ ì§€ ì¤‘ì¸ ì „ì²´ ëŒ€í™” ê¸°ë¡ (ëŒ€í™” íˆìŠ¤í† ë¦¬) :: ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ë¨
        
        return ::
        reply(str)   LLMì´ ìƒì„±í•œ ì‘ë‹µêµ¬ì¡°(ë©”íƒ€ë°ì´í„°)
        
        
        log 
        ### ê³¼ê±° ëŒ€í™” ê¸°ë¡ì„ LLM inputì— ë³µì›í•˜ëŠ” ê²ƒ
        # n_calls max_lenght == self.chatsì˜ ìˆ˜
        
        """
        n_calls = 0
        self.chats.append({"role": "user", "content": user_prompt})
        messages = [{"role": "system", "content": system_prompt}]
        
        test_trriger = False
        for msg in self.chats:
            
            if msg["role"] in ["function", "tool"]:                 
                print(f"@@@@@@@@@@@@@@@ ì±— í™•ì¸í•˜ê¸° :\n {msg}\n@@@@@@@@@@@@@@@@@@@@\n")
                test_trriger = True
                n_calls = n_calls + 1
            if n_calls > 0:
                messages.append(msg)
            else:
                messages.append({"role": msg["role"], "content": msg["content"]})   
        
        if test_trriger :
            raise SystemExit("â›” generate_reply ì¤‘ë‹¨: LLM í˜¸ì¶œ ì§ì „ì—ì„œ ì¢…ë£Œë¨")
        ## LLM í˜¸ì¶œ 
        retry = 0
        response = None
        while retry < 5:
            try:
                response = get_client(self.llm).chat.completions.create(
                    model=self.model, messages=messages, temperature=0.3
                )
                break
            except Exception as e:
                print_message("system :: Error Type :: Manager - generate_reply", e)
                retry += 1
                continue
        
        if response:
            reply = response.choices[0].message.content.strip() if return_content else response
        else:
            reply = ''
            print("generate_replyì—ì„œ 5íšŒ ì´ìƒ ì‹œë„ - ì‘ë‹µ ì—†ìŒ(ë¹ˆ ê°’)")
        # add a new response message
        ### ëŒ€í™” ê¸°ë¡ ê°±ì‹ 
        # system_use=Falseì¼ ë•Œë§Œ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•¨
        # "ë‚´ë¶€ì ì¸ LLM í˜¸ì¶œ" (ex. ë°ì´í„° ê²€ì¦ìš© ë“±)ì€ ê¸°ë¡í•˜ì§€ ì•ŠìŒ
        if not system_use and response:
            self.chats.append(dict(response.choices[0].message))
        
        ## ë¹„ìš© ê¸°ë¡
        if caller_id and response:
            self.money[caller_id] = response.usage.to_dict(mode='json')
        return reply

    def _is_relevant(self, msg):
        """
        msg (ë¬¸ìì—´)ì´ "ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)" ë˜ëŠ” "ì¸ê³µì§€ëŠ¥(AI)" ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì¸ì§€ LLMì—ê²Œ ë¬¼ì–´ë³´ê³  íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
        """
        init_prompt = f"""Is the following statement relevant to machine learning or artificial intelligence?
        
        `{msg}`
        
        Answer only 'Yes' or 'No'
        """
        messages = [
            {"role": "system", "content": basic_profile},
            {"role": "user", "content": init_prompt},
        ]
        retry = 0
        while retry < 5:
            try:
                response = get_client(self.llm).chat.completions.create(
                    model=self.model, messages=messages, temperature=0
                )
                break
            except Exception as e:
                print_message("system", e)
                retry += 1
                continue
        return "yes" in response.choices[0].message.content.strip().lower()

    def _is_enough(self, msg):
        """
        _is_relevant()ë³´ë‹¤ í•œ ë‹¨ê³„ â€œë” ê¹Šì€ í•„í„°ë§ ë‹¨ê³„â€ì— í•´ë‹¹ : "AutoML íŒŒì´í”„ë¼ì¸ì„ ì‹¤ì œë¡œ ì‹¤í–‰í•  ë§Œí¼ ì •ë³´ê°€ ì¶©ë¶„í•œê°€?"ë¥¼ íŒë‹¨í•˜ëŠ” ì—­í• 
        
        """
        
        
        init_prompt = f"""
        Given the following JSON object representing the user's requirement for a potential ML or AI project, please tell me whether we have essential information (e.g., problem and dataset) to be used for a AutoML project?
        Please note that our users are not AI experts, you must focus only on the essential requirements, e.g., problem and brief dataset descriptions.
        You do not need to check every details of the requirements. You must also answer 'yes' even though it lacks detailed and specific information.
        
        ```json
        {msg}
        ```
        
        Please answer with this format: `a 'yes' or 'no' answer; your reasons for the answer` by using ';' to separate between the answer and its reasons.
        If the answer is 'no', you must tell me the alternative solutions or examples for completing such missing information.
        """
        messages = [
            {"role": "system", "content": basic_profile},
            {"role": "user", "content": init_prompt},
        ]
        while True:
            try:
                response = get_client(self.llm).chat.completions.create(
                    model=self.model, messages=messages, temperature=0
                )
                break
            except Exception as e:
                print_message("system", e)
                continue
        ans, reason = response.choices[0].message.content.strip().split(";")
        self.money['manager_request_verification'] = response.usage.to_dict(mode='json')
        
        if "yes" in ans.strip().lower():
            return True, reason.strip()
        else:
            return False, reason.strip()

    def _on_stop(self, msg):
        """
        ëŒ€í™” ì¢…ë£Œ íŠ¸ë¦¬ê±°
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ msgê°€ **ëŒ€í™” ì¢…ë£Œë¥¼ ì˜ë„í•œ ëª…ë ¹**ì¸ì§€ íŒë³„í•˜ëŠ” ì—­í• 
        """
        
        return msg.lower() in [
            "stop",
            "close",
            "exit",
            "terminate",
            "end",
            "done",
            "finish",
            "complete",
            "bye",
            "goodbye",
        ]
### Main Loop í•¨ìˆ˜
    def initiate_chat(self, prompt, plan_path=None, instruction_path=None):
        """
        [ ì‚¬ìš©ìì˜ ìš”ì²­ â†’ ë¶„ì„ â†’ ê³„íš ìˆ˜ë¦½ â†’ ì‹¤í–‰ â†’ ê²€ì¦ â†’ ìˆ˜ì • â†’ ì™„ë£Œ ] ì „ ë‹¨ê³„ë¥¼ ê´€ë¦¬í•¨.
        self.state ê°’ì— ë”°ë¼ ë™ì‘ì´ ë°”ë€Œë©° ë‹¨ê³„ë¥¼ ì‹¤í–‰í•¨ : possible_states ì°¸ê³ 
        
        INPUT parameters
        - prompt: ì‚¬ìš©ìê°€ ì²˜ìŒ ì…ë ¥í•œ ìš”ì²­ (ex: â€œMNIST ë¶„ë¥˜ ëª¨ë¸ ë§Œë“¤ì–´ì¤˜â€)
        - plan_path: ê³„íš ê²°ê³¼ë¥¼ ì €ì¥í•  ê²½ë¡œ (ì˜µì…˜)
        - instruction_path: ì½”ë“œ ìƒì„± ì§€ì¹¨ì„ ì €ì¥í•  ê²½ë¡œ (ì˜µì…˜)
        
        Q. pool
        Q. input() ëŠ” ì–´ë””ì„œ ë‚˜ì˜¨ê±°ì§€?
        
        """
        
        last_msg = prompt
        pool = Pool(self.n_plans)           # multiprocessing íŒŒì¼ì— ì •ì˜ë˜ëŠ” ê±° ê°™ì€ë° ëª»ì°¾ìŒ
        
        start_time = time.time() 
        init_time = time.time() # init time
        
        # last_msg, self.stateë¡œ ë£¨í”„ ë©ˆì¶¤
        while not self._on_stop(last_msg) and self.state != "END":
            
            # ì—¬ê¸°ê°€ ë£¨í”„ ë„ëŠ” íŠ¸ë¦¬ê±° ìœ„ì¹˜(state ìƒíƒœ, last_msg)
            # reply process: current state + current state description + response : ì‘ë‹µ ì²˜ë¦¬ ê³¼ì •: í˜„ì¬ ìƒíƒœ + í˜„ì¬ ìƒíƒœ ì„¤ëª… + ì‘ë‹µ
            if last_msg == "":
                sys_query = "Please give feedback or answer to proceed. You may type 'exit' to end the session."
                last_msg = input(sys_query)
                if last_msg == "" or self._on_stop(last_msg):
                    continue
                else:
                    prompt = last_msg

            ########### 1. INIT ë‹¨ê³„ ###########
            if self.state == "INIT":
                print(f"@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 1. INIT ë‹¨ê³„(í™•ì¸ìš©) ì‹œì‘ ìœ„ì¹˜\n")
                # display user's input prompt
                self.chats.append({"role": "user", "content": prompt})
                print_message("user", prompt)
                
                """
                1. _is_relevant : ìš”ì²­ì´ AI/ML ê´€ë ¨ì¸ì§€ ë¶„ë¥˜
                1-1. â€œYesâ€ â†’ ë¶„ì„ ê³„ì†
                1-2. â€œNoâ€ â†’ ê·¸ëƒ¥ ëŒ€í™”(generate_reply)ë¡œ ì‘ë‹µ í›„ ì¢…ë£Œ
                """
                if self._is_relevant(prompt) or self.verification == False:
                    ############# Request Vericication : ê²€ì¦ ë‹¨ê³„(_is_relevant,_is_enough)
                    """
                    1-1-1. ìš”ì²­ì„ JSONìœ¼ë¡œ íŒŒì‹±
                    1-1-2. _is_enough() : ìš”ì²­ì´ ì¶©ë¶„íˆ êµ¬ì²´ì ì¸ì§€ ê²€ì‚¬
                    1-1-3. request_summary ë§Œë“œëŠ” ë‹¨ê³„
                    state ë°”ê¾¸ê³  ë£¨í”„ ë„ëŠ” ìœ„ì¹˜ë¡œ.
                    """
                    # 1-1-1. ìš”ì²­ì„ JSONìœ¼ë¡œ íŒŒì‹±
                    if self.user_requirements == None:
                        ######### parser.parseëŠ” ./prompt_agentì˜ WizardLAMPì— ì˜í•´?
                        self.user_requirements = parser.parse(prompt, return_json=True) # or parser.parse_openai(prompt, return_json=True)
                        # check user's requirement quality (JSON schema validation)
                        self.timer['prompt_parsing'] = time.time() - start_time 
                        ######################## í™•ì¸ìš©
                        print(f"################# 1. INIT ë‹¨ê³„(í™•ì¸ìš©) user_requirements : {self.user_requirements}\n")
                
                        start_time = time.time()
                        ########### 1-1-2. _is_enough() : ìš”ì²­ì´ ì¶©ë¶„íˆ êµ¬ì²´ì ì¸ì§€ ê²€ì‚¬       
                        is_enough, reasons = self._is_enough(self.user_requirements)
                        self.timer['request_verification'] = time.time() - start_time
                    else:
                        # user_requirementsì— ê°’ì„ ë„£ìœ¼ë©´ is_enoughëŠ” ê·¸ëƒ¥ pass
                        is_enough = True
                        
                    if 'confidence' in self.user_requirements.keys():
                        del self.user_requirements["confidence"]
                    
                    ########### 1-1-3. LLMì´ JSON ë‚´ìš©ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë‹¨ê³„(PLAN ë‹¨ê³„ ë°”ë¡œ ì „) :: request_summary
                    #######      user_requirementsê°€ ì´ë¯¸ ìˆìŒ.
                    if is_enough or self.verification == False:
                        start_time = time.time()
                        messages = [
                            {"role": "system", "content": agent_profile},
                            {
                                "role": "user",
                                "content": f"Please briefly summarize the user's request represented in the following JSON object into a single paragraph based on how you understand it.\n\r{self.user_requirements}",
                            },
                        ]
                        retry = 0
                        while retry < 5:
                            try:
                                res = get_client(self.llm).chat.completions.create(
                                    model=self.model, messages=messages, temperature=0.3
                                )
                                break
                            except Exception as e:
                                print_message("system", e)
                                retry += 1
                                continue
                        self.req_summary = res.choices[0].message.content.strip()
                        self.timer['request_summary'] = time.time() - start_time
                        self.money['manager_request_summary'] = res.usage.to_dict(mode='json')

                        ########################### í™•ì¸ìš©
                        print(f"################# 1. INIT ë‹¨ê³„(í™•ì¸ìš©) request_summary : {self.req_summary}\n")
                        print_message(
                            "prompt",
                            f"""I understand your request as follows.\n\r{self.req_summary}""",
                        )
                        self.chats.append(
                            {
                                "role": "assistant",
                                "content": f"""I understand your request as follows.\n\r{self.req_summary}""",
                            }
                        )
                        if self.interactive:
                            ans = input(
                                "Please check whether I understand your requirements correctly? (Yes/No)"
                            )
                            if ans.lower() in ["yes", "correct", "right", "sure"]:
                                self.state = "PLAN"
                        else:
                            self.state = "PLAN"
                            # key_point : whileë¬¸ìœ¼ë¡œ ëŒì•„ê°(ë‹¤ìŒ ë‹¨ê³„ PLANë¡œ)
                            
                    else:
                        print_message(
                            self.agent_type,
                            f"""Based on the analysis result from ğŸ¦™ Prompt Agent, it seems that, for the following reasons, we cannot process your request or solve your task.\n{reasons}""",
                        )
                        last_msg = "" if self.interactive else "stop"
                else:
                    # chit-chat case : ì¼ë°˜ ëŒ€í™”ë¡œ ì „í™˜ í›„ ìŠ¤í†±
                    res = self.generate_reply(user_prompt=prompt, return_content=True, caller_id='manager_chitchat')
                    print_message(self.agent_type, res)
                    last_msg = "" if self.interactive else "stop"
                    
            ########### 2. PLAN ë‹¨ê³„ ###########
            elif self.state == "PLAN":
                """
                make_plans() : ì—¬ëŸ¬ ê³„íš(self.n_plans)ì„ ìƒì„±    - ex. XGBoost ê¸°ë°˜ íŒŒì´í”„ë¼ì¸, CNNê¸°ë°˜ ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸
                * interactive ëª¨ë“œì¼ ê²½ìš°, ìƒì„±ëœ planë“¤ì„ userì˜ ìŠ¹ì¸ì´ í•„ìš”
                """
                print(f"@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 2. PLAN ë‹¨ê³„(í™•ì¸ìš©) ì‹œì‘ ìœ„ì¹˜\n")
                start_time = time.time()
                # Planning Stage
                self.make_plans()
                self.timer['planning_total'] = time.time() - start_time

                display_plans = "I have the following plan(s) for your task ğŸ“œ!\n\n"
                for plan in self.plans:
                    display_plans = display_plans + plan + "\n\n"

                # display all plans to the users
                print_message(self.agent_type, display_plans)
                if self.interactive:
                    # ask user before executing the plans
                    ans = input(
                        "Do you want me to proceed with the above plan(s)? (Yes/No)"
                    )
                    if ans.lower() in ["yes", "correct", "right", "sure"]:
                        self.state = "ACT"
                else:
                    self.state = "ACT"
                    
            ########### 3. ACT ë‹¨ê³„ ########### ê³„íš ì‹¤í–‰ ë‹¨ê³„(ê³„íšêµ¬í˜„í•˜ëŠ”ê±°ì§€ ì‹¤ì œ ì‹¤í–‰ì€ ì•„ë‹˜)
            elif self.state == "ACT":
                # Action (executing the plans) Stage
                print(f"@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 3. ACT ë‹¨ê³„(í™•ì¸ìš©) ì‹œì‘ ìœ„ì¹˜\n")
                print_message(
                    self.agent_type,
                    "With the above plan(s), our ğŸ¦™ Data Agent and ğŸ¦™ Model Agent are going to find the best solution for you!",
                )
                start_time = time.time()
                
                """
                ê° planì€ ë‚´ë¶€ì ìœ¼ë¡œ Data Agent, Model Agent í˜¸ì¶œ.
                # Data Agent : ë°ì´í„° ì¤€ë¹„/ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„±
                # Model Agent : ë¸ íƒìƒ‰ / í•™ìŠµ ê³„íš
                self.action_resultsì— ì €ì¥ë¨
                """

                # Parallelization
                with Pool(self.n_plans) as pool:
                    # print("##################### test print í™•ì¸ìš© ############# : ",self.plans) :: ì—¬ê¸°ì„œ ì˜¤ë¥˜
                    self.action_results = pool.map(self.execute_plan, self.plans)
                self.timer['plan_execution_total'] = time.time() - start_time
                
                self.state = "PRE_EXEC"

            ############ 4. PRE_EXEC ë‹¨ê³„ ########### ì‹¤í–‰ ê²°ê³¼ ê²€ì¦ ë‹¨ê³„
            elif self.state == "PRE_EXEC":
                # Pre-(Code)Execution Verification stage
                """
                ê° action_result(self.action_results)ë¥¼ verify_solution()ìœ¼ë¡œ ê²€ì¦.
                í†µê³¼í•œ planë§Œ pass=True ì„¤ì •.
                
                5.EXEC ë‹¨ê³„ or 7.REV ë‹¨ê³„ ê²°ì •
                """
                print(f"@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 4. PRE_EXEC ë‹¨ê³„(í™•ì¸ìš©) ì‹œì‘ ìœ„ì¹˜\n")
                if self.verification:
                    print_message(
                        self.agent_type,
                        "I am now verifying the solutions found by our Agent team ğŸ¦™.",
                    )
                    
                    start_time = time.time()
                    # Parallelization
                    with Pool(self.n_plans) as pool:
                        verification_result = pool.map(self.verify_solution, self.action_results)
                    self.timer['execution_verification_total'] = time.time() - start_time
                    
                    # í•˜ë‚˜ë¼ë„ Trueì¸ ê³„íšì´ ìˆë‹¤ë©´ ## 5. EXEC ë‹¨ê³„ë¡œ ë„˜ì–´ê°
                    for i, result in enumerate(verification_result):
                        self.action_results[i]["pass"] = result
                        if result:
                            self.is_solution_found = True

                    if self.is_solution_found:
                        ###################### 5. EXEC ë‹¨ê³„
                        result_text = f"""Thanks to all the hard-working ğŸ¦™ Agents ğŸ¦™, we have found \033[4m{num2words(sum([result['pass'] for result in self.action_results]))}\033[0m suitable solution(s) for you ğŸ¥³.\nThen, let our Operation Agent ğŸ¦™ implement and evaluate these solutions ğŸ‘¨ğŸ»â€ğŸ’»!"""
                        self.state = "EXEC"
                    else:
                        ###################### 7. REV ë‹¨ê³„
                        result_text = f"""Despite all the hard work by ğŸ¦™ Agents ğŸ¦™, we have not found a suitable solution that matches your requirements yet ğŸ˜­."""
                        self.state = "REV"
                else:
                    result_text = f"""Thanks to all the hard-working ğŸ¦™ Agents ğŸ¦™. Then, let our Operation Agent ğŸ¦™ implement and evaluate these solutions ğŸ‘¨ğŸ»â€ğŸ’»!"""
                    for action in self.action_results:
                        action["pass"] = True
                    self.state = "EXEC"

                if plan_path:
                    for i, action in enumerate(self.action_results):
                        if action["pass"]:
                            # save pass plan
                            filename = f"{plan_path}/plan_{i}.json"
                            os.makedirs(os.path.dirname(filename), exist_ok=True)
                            with open(filename, "w") as f:
                                json.dump(action, f)
                                print_message(
                                    self.agent_type,
                                    f"Saved a pass plan: {plan_path}/plan_{i}.json",
                                )
                print_message(self.agent_type, result_text)

            ############ 5. EXEC ë‹¨ê³„ ########### Operation Agentì—ê²Œ ì‹¤ì œë¡œ ì½”ë“œ ìˆ˜í–‰
            elif self.state == "EXEC":
                # Code Execution stage
                """
                1. summary_prompt : ì—¬ëŸ¬ ê°œíš(plan) ì¤‘ í†µê³¼(Ture)ëœ ê²ƒë§Œ ëª¨ì•„ì„œ ìš”ì•½
                2. generate_reply : Operation Agentì—ê²Œ ì§€ì¹¨ ì£¼ëŠ” í”„ë¡¬í”„íŠ¸ ë¬¸ì¥ ìƒì„±(ì§ì ‘ ì½”ë“œ ì‘ì„± ê¸ˆì§€!) -> code_instruction ìƒì„±ë¨(ì½”ë“œ ìƒì„± ì§€ì¹¨ë¬¸).
                3. implementation_result : implement_solutioní•¨ìˆ˜ í†µí•´ì„œ Operation Agentê°€ ì½”ë“œ ì‘ì„±(ì—¬ê¸°ì„œ skeleton codeí™œìš©í•´ì„œ í‹€ ì±„ì›€)
                """
                print(f"@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 5. EXEC ë‹¨ê³„(í™•ì¸ìš©) ì‹œì‘ ìœ„ì¹˜\n")
                if not self.code_instruction:
                    start_time = time.time()
                    
                    data_plan_for_execution = ""
                    model_plan_for_execution = ""
                    for action in self.action_results:
                        if action["pass"]:
                            data_plan_for_execution = (
                                data_plan_for_execution + action["data"] + "\n"
                            )
                            model_plan_for_execution = (
                                model_plan_for_execution + action["model"] + "\n"
                            )

                    # Summarize the passed plan for operation llama to write and execute the code
                    upload_path = (
                        f"This is the retrievable data path: {self.data_path}."
                        if self.data_path
                        else ""
                    )
                    summary_prompt = f"""As the project manager, please carefully read and understand the following instructions suggested by data scientists and machine learning engineers. Then, select the best solution for the given user's requirements.
                    
                    - Instructions from Data Scientists
                    {data_plan_for_execution}
                    If there is no predefined data split or the data scientists suggest the data split other than train 70%, validation 20%, and test 10%, please use 70%, 20%, and 10% instead for consistency across different tasks. {upload_path}
                    You should exclude every suggestion related to data visualization as you will be unable to see it.
                    - Instructions from Machine Learning Engineers
                    {model_plan_for_execution}                    
                    - User's Requirements
                    {self.req_summary}
                    
                    Note that you must select only ONE promising solution (i.e., one data processing pipeline and one model from the top-{num2words(self.n_candidates)} models) based on the above suggestions.
                    After choosing the best solution, give detailed instructions and guidelines for MLOps engineers who will write the code based on your instructions. Do not write the code by yourself. Since PyTorch is preferred for implementing deep learning and neural networks models, please guide the MLOPs engineers accordingly.
                    Make sure your instructions are sufficient with all essential information (e.g., complete path for dataset source and model location) for any MLOps or ML engineers to enable them to write the codes using existing libraries and frameworks correctly."""
                    self.code_instruction = self.generate_reply(
                        system_prompt=agent_profile,
                        user_prompt=summary_prompt,
                        return_content=True,
                        system_use=True,
                        caller_id='manager_code_instruction'
                    )
                    self.timer['code_instruction'] = time.time() - start_time
                    
                    if instruction_path:
                        with open(f"{instruction_path}/code_instruction.txt", "w") as f:
                            f.write(self.code_instruction)

                start_time = time.time()
                ### ìœ„ì—ì„œ code_instruction(ì½”ë“œ ìƒì„± ì§€ì¹¨ë¬¸, í”„ë¡¬í”„íŠ¸)ë¥¼ í™œìš©í•´ì„œ ì‹¤ì œ ìˆ˜í–‰(ì½”ë“œ ìƒì„±)
                ### ì‹¤ì œ ì½”ë“œê°€ ì‘ì„± ë° ìƒì„±ë¨ : implementation_result
                self.implementation_result = self.implement_solution(self.code_instruction)
                print_message('system', f'{self.code_path}, <<< END CODING, TIME USED: {time.time() - init_time} SECS >>>')
                self.timer['implementation'] = time.time() - start_time
                
                self.n_attempts += 1
                self.state = "POST_EXEC"

            ############ 6. POST_EXEC ë‹¨ê³„ ########### ë§ˆì§€ë§‰
            elif self.state == "POST_EXEC":                
                # Post-(Code)Execution Verification stage
                print(f"@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 6. POST_EXEC ë‹¨ê³„(í™•ì¸ìš©) ì‹œì‘ ìœ„ì¹˜\n")
                if self.implementation_result["rcode"] == 0:
                    start_time = time.time()
                    verification_prompt = f"""As the project manager, please carefully verify whether the given Python code and results satisfy the user's requirements.
                    
                    - Python Code
                    ```python
                    {self.implementation_result['code']}
                    ```
                    
                    - Code Execution Result
                    {self.implementation_result['action_result']}
                    
                    - User's Requirements
                    {self.user_requirements}
                    
                    Answer only 'Pass' or 'Fail'"""
                    messages = [
                        {"role": "system", "content": agent_profile},
                        {"role": "user", "content": verification_prompt},
                    ]
                    while True:
                        try:
                            res = get_client(self.llm).chat.completions.create(
                                model=self.model, messages=messages, temperature=0
                            )
                            break
                        except Exception as e:
                            print_message("system", e)
                            continue
                    ans = res.choices[0].message.content.strip()
                    is_pass = "pass" in ans.lower()
                    if is_pass:
                        self.state = "END"
                        self.solution = self.implementation_result["code"]
                        print_message(
                            self.agent_type,
                            f"We have successfully built your pipeline as follows!\n{self.solution}",
                        )
                    else:
                        self.state = "REV"
                    self.timer['implementation_verification'] = time.time() - start_time
                    self.money['manager_implementation_verification'] = res.usage.to_dict(mode='json')
                else:
                    if self.n_revise >= 0:
                        start_time = time.time()
                        print_message(
                            self.agent_type,
                            f"It seems that the previous attempt (# {self.n_attempts}) has failed. I am start revising it for you!",
                        )
                        # Summarize the passed plan for operation llama to write and execute the code
                        upload_path = (
                            f"This is the retrievable data path: {self.data_path}."
                            if self.data_path
                            else ""
                        )
                        summary_prompt = f"""As the project manager, you have provided an instruction that was not good enough for the MLOps engineer to write a correct code for the user's requirements.
                        Please carefully check your previous instruction, the written Python, the execution results, and the user's requirements.
                        
                        - Your Previous Instruction
                        {self.code_instruction}
                        
                        - Python Code
                        ```python
                        {self.implementation_result['code']}
                        ```
                        
                        - Code Execution Result (Error)
                        {self.implementation_result['error_logs']}
                        
                        - User's Requirements
                        {self.user_requirements}
                        
                        {upload_path}
                        After you figure out the causes, give detailed instructions and guidelines for MLOps engineers who will write the code based on your instructions. Do not write the code by yourself.
                        Make sure your instructions are sufficient with all essential information (e.g., complete path for dataset source and model location) for any MLOps or ML engineers to enable them to write the codes using existing libraries and frameworks correctly."""
                        messages = [
                            {"role": "system", "content": agent_profile},
                            {"role": "user", "content": summary_prompt},
                        ]
                        self.code_instruction = self.generate_reply(
                            system_prompt=agent_profile,
                            user_prompt=summary_prompt,
                            return_content=True,
                            system_use=True,
                            caller_id='manager_code_revision'
                        )
                        self.state = "EXEC"
                        self.n_revise = self.n_revise - 1
                        self.timer['code_revision'] = time.time() - start_time
                    else:
                        print_message(
                            self.agent_type,
                            "Sorry, even after a round of revision, we could not find a suitable solution for your problem ğŸ™ğŸ».",
                        )
                        break

            elif self.state == "REV":
                # Plan Revision stage
                print(f"@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 7. REV ë‹¨ê³„(í™•ì¸ìš©) ì‹œì‘ ìœ„ì¹˜\n")
                if self.n_revise > 0:
                    start_time = time.time()
                    self.make_plans(is_revision=True)
                    self.n_revise = self.n_revise - 1
                    print_message(
                        "system", f"Remaining revision: {self.n_revise} round."
                    )
                    self.timer[f'plan_revision_{self.n_attempts}'] = time.time() - start_time
                else:
                    print_message(self.agent_type, "Sorry, even after a round of revision, we could not find a suitable solution for your problem ğŸ™ğŸ».",)
                    break

            elif self.state == "END":
                break
