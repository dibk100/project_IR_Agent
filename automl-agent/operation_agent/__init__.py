import os
import shutil

from configs import AVAILABLE_LLMs
from utils import print_message, get_client
from operation_agent.execution import execute_script

import time

# testìš©
agent_profile = """You are the world's best MLOps engineer of an automated machine learning project (AutoML) that can implement the optimal solution for model training and saving, given any datasets and models. You have the following main responsibilities to complete.
1. Write accurate Python codes to retrieve/load the given dataset from the corresponding source.
2. Write effective Python codes to preprocess the retrieved dataset.
3. Write precise Python codes to retrieve/load the given model and optimize it with the suggested hyperparameters.
4. Write efficient Python codes to train/finetune the retrieved model.
5. Write suitable Python codes to save the trained model to the appropriate directory.
6. Run the model evaluation using the given Python functions and summarize the results for validation against the user's requirements.
"""

class OperationAgent:
    def __init__(self, user_requirements, llm, code_path, device=0):
        # setup Farm Manager
        self.agent_type = "operation"
        self.llm = llm
        self.model = AVAILABLE_LLMs[llm]["model"]
        self.experiment_logs = []
        self.user_requirements = user_requirements
        self.root_path = "agent_workspace" # + f"{code_path}"
        self.code_path = code_path
        self.device = device
        self.money = {}
        

    def self_validation(self, filename):
        """
        ìƒì„±í•œ ì½”ë“œë¥¼ í™•ì¸
        """
        rcode, log = execute_script(filename, device=self.device)
        return rcode, log

    def implement_solution(self, code_instructions, full_pipeline=False, code="", n_attempts=5):
        """
        ì‹¤ì œ ìˆ˜í–‰ : LLMê³¼ ì‹¤ì œ Python ì‹¤í–‰(subprocess)ì„ ì—°ê²°í•˜ëŠ” ì¤‘ì‹¬ë¶€
        ## full_pipeline : False :: ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ (ë°ì´í„° ê°€ì ¸ì˜¤ê¸°ë¶€í„° ëª¨ë¸ ì €ì¥ê¹Œì§€)
        Operation ë‹¨ê³„ëŠ” qwen_coder ëª¨ë¸ ì‚¬ìš© í›„ ë‹¤ì‹œ mistralë¡œ ë³µê·€
        """
    
        print_message(
            self.agent_type,
            f"I am implementing the following instruction:\n\r{code_instructions}",
        )
        from utils.switch_model import switch_model
        print(f"[OperationAgent] ğŸ”„ Switching model: mistral â†’ qwen_coder")
        switch_model(self.llm)
        
        log = "Nothing. This is your first attempt."
        error_logs = []
        code = code  # if a template/skeleton code is provided
        iteration = 0
        completion = None
        action_result = ""
        rcode = -1
        
        while iteration < n_attempts:
            try:
                ##################### 1. ìˆ˜í–‰ í”„ë¡¬í”„íŠ¸ : LLMì—ê²Œ â€œì´ëŸ° instructionëŒ€ë¡œ ì½”ë“œë¥¼ ì¨ë´â€ ìš”ì²­
                exec_prompt = """Carefully read the following instructions to write Python code for {} task.
                {}
                
                # Previously Written Code
                ```python
                {}
                ```
                
                # Error from the Previously Written Code
                {}
                
                Note that you need to write the python code for the {}. If saving model is required, you must save the trained model to "./agent_workspace/trained_models" directory.
                Start the python code with "```python". Please ensure the completeness of the code so that it can be run without additional modifications.
                If there is any error from the previous attempt, please carefully fix it first."""
                pipeline = (
                    "entire machine learning pipeline (from data retrieval to model deployment via Gradio)"
                    if full_pipeline
                    else "modeling pipeline (from data retrieval to model saving)"
                )
                exec_prompt = exec_prompt.format(
                    self.user_requirements["problem"]["downstream_task"],
                    code_instructions,
                    code,                                   # ì´ˆê¸° ì½”ë“œ or ì˜ëª» ì‘ì„±ë˜ì—ˆë˜ ì½”ë“œ
                    log,
                    pipeline,
                )

                messages = [
                    {"role": "system", "content": agent_profile},
                    {"role": "user", "content": exec_prompt},
                ]
                print("ì¬í™•ì¸ ::: self.model : ",self.model)
                res = get_client(self.llm).chat.completions.create(
                    model=self.model, messages=messages, temperature=0.3
                )
                ############################ 2. LLMì´ Python ì½”ë“œë¥¼ ìƒì„±
                raw_completion = res.choices[0].message.content.strip()
                completion = raw_completion.split("```python")[1].split("```")[0]
                self.money[f'Operation_Coding_{iteration}'] = res.usage.to_dict(mode='json')

                if not completion.strip(" \n"):
                    print("### ?????? ì˜¤ë¥˜ê°€ ì—¬ê¸°ì„œ ì¡íˆë‚˜?")
                    continue
                
                ############################# 3. ì½”ë“œ ì €ì¥
                filename = f"{self.root_path}{self.code_path}_{iteration}.py"
                os.makedirs(os.path.dirname(filename), exist_ok=True)
                with open(filename, "wt") as file:
                    file.write(completion)
                code = completion                       ## ìƒì„±ëœ ì½”ë“œ ì…ë ¥ë í…ë°?
                #print(">>>>>>>>>>>>>> í™•ì¸ìš© :\n",code)
                
                ############################## 4. ì§„ì§œ ì‹¤í–‰ ::: self_validation -> execute_script(ì–˜ê°€ ìˆ˜í–‰ë¨)
                rcode, log = self.self_validation(filename)
                if rcode == 0:
                    action_result = log
                    break
                
                else:
                    #### ì‹¤íŒ¨
                    log = log
                    error_logs.append(log)
                    action_result = log
                    print_message(self.agent_type, f"I got this error (itr #{iteration}): {log}")
                    iteration += 1                    
                    # whileë¬¸
            except Exception as e:
                iteration += 1
                print_message(self.agent_type, f"===== Retry: {iteration} =====")
                print_message(self.agent_type, f"Executioin error occurs: {e}")
            continue
        
        # ëª¨ë¸ ë³µê·€
        print(f"[OperationAgent] ğŸ” Restoring model: qwen_coder â†’ mistral")
        switch_model("prompt-llm")
        
        if not completion:
            completion = ""

        print_message(
            self.agent_type,
            f"I executed the given plan and got the follow results:\n\n{action_result}",
        )
        return {"rcode": rcode, "action_result": action_result, "code": completion, "error_logs": error_logs}
