{"task": "time-series classification", "instruction": "As a project manager for a cutting-edge time-series classification project, your team is tasked with developing a highly sophisticated model using the Heartbeat dataset. This dataset consists of intricate, real-world recordings partitioned into train, validation, and test sets, each with unique feature sequences (INPUT_SEQ_LEN=405, INPUT_DIM=61). Your challenge is to design and implement an advanced deep learning architecture that demonstrates exceptional multi-step pattern recognition and predictive accuracy, targeting labels {0, 1}. Additionally, the model must exhibit robust generalization abilities and outperform contemporary algorithms based on progressive validation. The team must also include detailed interpretability techniques and document their strategy for hyperparameter tuning.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"healthcare\",\n        \"description\": \"The team is to develop a highly sophisticated model for time-series classification using the Heartbeat dataset. The focus is on advanced deep learning architecture with multi-step pattern recognition, high predictive accuracy for labels {0, 1}, robust generalization, and outperforming contemporary algorithms. Interpretability techniques and hyperparameter tuning strategy are mandatory.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Heartbeat dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 405,\n                \"INPUT_DIM\": 61\n            },\n            \"description\": \"A real-world, intricate time-series dataset split into train, validation, and test sets with unique feature sequences. Target labels are {0, 1}.\",\n            \"preprocessing\": [\n                \"Data cleaning\",\n                \"Normalization\"\n            ],\n            \"augmentation\": [\"Random time warping\"],\n            \"visualization\": [\"Pattern analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"Advanced deep architecture for multi-step pattern recognition\",\n                \"hyperparameters\": \"To be optimized for exceptional performance\"\n            },\n            \"description\": \"A deep learning model for time-series classification on the Heartbeat dataset, with a focus on interpretability and outperforming contemporary methods.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The model should incorporate techniques such as LSTM or Transformer layers for time-series analysis.\",\n        \"Attention-based interpretability methods to enhance transparency.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"Feature extraction\", \"Feature selection\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"Apache MXNet\"],\n        \"demonstration\": \"Model performance demonstration on unseen test data\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON accurately captures the task, specifying advanced deep learning for time-series classification, interpretability, and hyperparameter tuning. Performance is focused on accuracy, and the dataset's unique characteristics are included. However, missing specific model performance values and target device details indicate potential room for further clarification.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "As a project manager for an advanced visual question-answering (VQA) system, I need you to design a cutting-edge model that integrates TextVQA dataset, leveraging deep convolutional neural networks and transformers for extracting both text and visual features. The system must exhibit multi-step reasoning, handle nuances, and consistently achieve state-of-the-art accuracy across diverse real-world images with embedded textual content.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"artificial intelligence\",\n        \"description\": \"The project requires the development of a cutting-edge visual question-answering system integrating the TextVQA dataset. The model should employ deep convolutional neural networks and transformers for feature extraction, prioritize multi-step reasoning, handle nuances, and aim for state-of-the-art accuracy across diverse real-world images containing textual content.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"state-of-the-art comparison\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"TextVQA dataset\",\n            \"modality\": [\"text\", \"image\"],\n            \"target_variables\": [\"answer\"],\n            \"specification\": {\n                \"image dimensions\": null,\n                \"text length\": null\n            },\n            \"description\": \"A dataset for visual question answering, combining text and visual features with the focus on real-world images with embedded textual content.\",\n            \"preprocessing\": [\n                \"deep convolutional feature extraction\",\n                \"transformer-based feature extraction\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"multimodal attention maps\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"advanced VQA model\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": [\"deep CNNs\", \"transformers\"],\n                \"architecture components\": [\"multi-step reasoning mechanism\", \"attention mechanisms\"]\n            },\n            \"description\": \"An advanced VQA model that leverages deep convolutional and transformer networks for text and visual feature extraction, designed for the TextVQA dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"multimodal learning techniques\",\n        \"state-of-the-art performance in VQA\",\n        \"real-world image complexity handling\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"ensembling, fine-tuning\", \"pre-training\"],\n        \"target_device\": \"cloud-based or specialized VQA hardware\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"custom-built for TextVQA-specific requirements\"],\n        \"demonstration\": \"interactive VQA performance demonstration\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON reflects the requirements of a build (intent) project, focusing on developing an advanced VQA model with deep CNNs and transformers. Expertise is high since it's for a project leader. The problem area, task, and TextVQA dataset usage are clearly defined. Performance metrics cover accuracy and state-of-the-art comparison, while complexity metrics involve inference time and memory. The dataset preprocessing, augmentation, and model features are tailored to the task. Confidence score is high due to the detailed response matching the provided task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "The project for image recognition focuses on the specialized Ford Car Variants Collection, leveraging advanced Inception-v5 architecture. The objective is to develop a state-of-the-art model adept at differentiating between extinct and current model variants, with high precision (99%) and recall (97%) under challenging weather effects, unique paint patterns, and complex urban backgrounds. The model must also exhibit an overall F1 score of 98% across multiple decades of vehicles.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"automotive\",\n        \"description\": \"The project aims to develop an image recognition model using the Inception-v5 architecture for the Ford Car Variants Collection. The goal is to differentiate between extinct and current model variants with high precision (99%), recall (97%), and an overall F1 score of 98% under challenging conditions such as different weather effects, unique paint patterns, and complex urban backgrounds, considering vehicles from multiple decades.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.99\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": 0.97\n            },\n            {\n                \"name\": \"F1_score\",\n                \"value\": 0.98\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Ford Car Variants Collection\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"model_variety\"],\n            \"specification\": {\n                \"architecture\": \"Inception-v5\"\n            },\n            \"description\": \"A specialized dataset for image recognition with advanced Inception-v5 architecture, focusing on Ford car variants under various challenging conditions.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Inception\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"specific to Inception-v5\"\n            },\n            \"description\": \"A state-of-the-art image classification model using Inception-v5 for Ford Car Variants Collection, targeting high precision, recall, and F1 score with focus on differentiating extinct and current models under challenging conditions.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": null\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is formed based on the given instruction, considering the user's intent to build a model, high expertise level, and focus on computer vision and image classification. The problem statement and performance metrics align with the given requirements of precision, recall, and F1 score. Since no source of dataset is specified, we've assumed 'user-upload'. Details like dataset specifications, source of information, and specific model details are derived directly from the instruction, while the target device, deployment details, and demo are left unspecified.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "Develop a cutting-edge machine translation model using the domain-specific ToymotaTechXtra dataset, which combines zero-shot cross-lingual understanding with a transformer-based M.T.E. (Multi-Modal Translation with Emotion Embedding) architecture. The system must adeptly translate between English and rare Hokkien dialect, while preserving nuanced cultural expressions and colloquialisms, while also deciphering and reflecting the subtextual emotions in both languages.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"domain-specific (ToyotaTechXtra)\",\n        \"description\": \"The task is to develop a cutting-edge machine translation model using the ToymotaTechXtra dataset. The model should incorporate zero-shot cross-lingual understanding, a transformer-based M.T.E architecture, with an emphasis on translating between English and Hokkien dialect while preserving cultural expressions and colloquialisms, and detecting subtextual emotions in both languages.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"cross-lingual understanding\",\n                \"value\": null\n            },\n            {\n                \"name\": \"emotion preservation/reproduction\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ToyotaTechXtra\",\n            \"modality\": [\"text\", \"multimodal\"],\n            \"target_variables\": [\"translated_text\", \"emotions\"],\n            \"specification\": {\n                \"source_languages\": [\"English\", \"Hokkien\"],\n                \"target_languages\": [\"English\", \"Hokkien\"],\n                \"size\": {\n                    \"train\": null,\n                    \"valid\": null,\n                    \"test\": null\n                },\n                \"emotions\": [\"subtextual\"]\n            },\n            \"description\": \"A domain-specific dataset combining English and Hokkien dialect with zero-shot cross-lingual understanding and emotion embedding for a transformer-based M.T.E model.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"M.T.E (Transformer-based)\",\n            \"family\": \"Transformer\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"M.T.E (Multi-Modal Translation with Emotion Embedding)\",\n                \"language_pair\": \"English to Hokkien and vice versa\",\n                \"emotion_inclusion\": true\n            },\n            \"description\": \"A high-end machine translation model leveraging M.T.E for domain-specific ToyotaTechXtra dataset, targeting nuanced cultural expressions, colloquialisms, and subtextual emotion detection.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The model should handle the rarity of Hokkien dialect, and be able to adapt to zero-shot cross-lingual scenarios.\",\n        \"Emphasis on cultural expression and colloquialism preservation may require specialized language resources or augmentation techniques.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"Custom language adaptation for Hokkien dialect\",\n            \"Emotion-aware training and fine-tuning\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": {\n            \"methodology\": \"Demonstrate system's ability to preserve subtextual emotions in translations\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the given task, adapting to the provided details about the ToymotaTechXtra dataset, M.T.E architecture, and the specific requirements for cultural expression preservation and emotion recognition. The task's complexity is assumed 'high' due to the zero-shot scenario and the need for handling nuances in Hokkien. Specific performance targets are left open for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "As an archaeologist working with a vast underwater repository of ancient maritime artifacts, we've recently discovered an uncharted trove of sunken maps and illustrations. Developing an advanced image segmentation algorithm is crucial to not only decipher the complex nautical charts but also to analyze the individual elements like ships, sea creatures, and topographical features. Can you propose a cutting-edge machine learning model that can handle the unique challenges of underwater document imaging and separate these elements with utmost precision, preserving the cultural and historical significance?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"archaeology\",\n        \"description\": \"The user requires an advanced image segmentation algorithm for deciphering complex nautical charts and analyzing underwater artifacts, including ships, sea creatures, and topographical features from the newly discovered sunken repository.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Underwater Archaeological Repository\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"ships\", \"sea creatures\", \"topographical features\"],\n            \"specification\": null,\n            \"description\": \"A diverse and challenging dataset of underwater artifact images with the need to isolate various elements.\",\n            \"preprocessing\": [\"noise reduction\", \"image normalization\"],\n            \"augmentation\": [\"geometric transformations\", \"color jittering\"],\n            \"visualization\": [\"segmentation mask visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced Underwater Imaging Segmentation Model\",\n            \"family\": \"deep learning (CNN or semantic segmentation)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"custom-designed for underwater imagery\",\n                \"depth\": null,\n                \"pre-trained\": false\n            },\n            \"description\": \"A deep learning model specifically tailored for underwater document imaging, designed to handle unique challenges with high precision.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Underwater imaging often requires robustness to光线 variations and noise, and a model should be resilient to these conditions.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"domain-specific feature extraction\"],\n        \"target_device\": \"cloud-based for computational resources\",\n        \"deployment_endpoint\": \"custom web application for artifact analysis\",\n        \"inference_engine\": [\"TensorRT, ONNX\"],\n        \"demonstration\": \"Live demonstration of model analysis on selected artifacts\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is based on the instruction, focusing on a 'build' task, with high expertise since the task is complex and requires advanced knowledge. The area and downstream task are determined as computer vision and image segmentation. Performance metrics are not specified, leaving room for optimization. The model is tailored for underwater imaging, addressing unique challenges. Data augmentation techniques and preprocessing steps are in line with the need for handling image quality issues. The service requirements imply a need for cloud-based processing and a web-based deployment.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "As a project manager, you're tasked with optimizing the use of high-resolution Sentinel-2 satellite imagery for land type classification, specifically targeting water bodies, dense forests, and urban landscapes. Evaluate the efficiency and accuracy of various segmentation models (like U-Net, FCN, or DeepLabV3+) considering their computational requirements, training time, and performance on similar datasets. Can you find a balance between speed and precision without compromising on the recognition ability?", "resposne": "{\n    \"user\": {\n        \"intent\": \"consult-build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"remote sensing\",\n        \"description\": \"The project aims to optimize the use of Sentinel-2 satellite imagery for land type classification, focusing on water bodies, dense forests, and urban landscapes. The goal is to evaluate the efficiency and accuracy of segmentation models like U-Net, FCN, or DeepLabV3+ while considering computational requirements, training time, and performance on similar datasets, searching for a balance between speed and precision without sacrificing recognition ability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"efficiency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"computational requirements\",\n                \"value\": null,\n                \"unit\": \"FLOPs\"\n            },\n            {\n                \"name\": \"training time\",\n                \"value\": null,\n                \"unit\": \"hours\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Sentinel-2 satellite imagery\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"water bodies\", \"dense forests\", \"urban landscapes\"],\n            \"specification\": {\n                \"image_size\": null,\n                \"bands\": null\n            },\n            \"description\": \"High-resolution satellite imagery dataset for land type classification tasks\",\n            \"preprocessing\": [\"image resizing\", \"normalization\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": [\"U-Net\", \"FCN\", \"DeepLabV3+\"],\n            \"family\": [\"encoder-decoder\", \"fully convolutional\", \"convolutional encoder\"],\n            \"type\": [\"neural networks\"],\n            \"specification\": {\n                \"parameters\": {\n                    \"model_size\": null,\n                    \"number_of_layers\": null\n                },\n                \"performance\": {\n                    \"accuracy\": null\n                },\n                \"computational\": {\n                    \"FLOPs\": null\n                }\n            },\n            \"description\": \"Candidate models for land type segmentation\"\n        }\n    ],\n    \"knowledge\": [\n        \"Similar datasets and tasks have shown that balancing speed and accuracy is possible in remote sensing.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"preprocessing techniques to optimize speed and performance\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"cloud-based platform\",\n        \"inference_engine\": [\"GPU-optimized libraries like TensorFlow or PyTorch\"],\n        \"demonstration\": \"Interactive and explainable visualizations of segmentation results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response captures the consulting aspect of the project since it suggests evaluating and finding a balance between speed and accuracy. Expertise level is assumed to be high based on the complex nature of the problem and the request for balancing multiple factors. The provided information is based on the schema but may require validation as some values, like model specifications and performance metrics, are not explicitly stated.\",\n        \"score\": 0.85\n    }\n}"}
{"task": "image segmentation", "instruction": "For a highly specialized medical imaging project, design and implement a novel DeepLabV3+ model on the combined dataset of subatomic particle interactions and cryo-electron tomography. The model should discern precisely between different subatomic structures with extreme precision, accounting for the unique noise patterns and instrument artifacts in high-energy particle microscopy. Additionally, propose a transfer learning strategy to improve segmentation in low-data regimes, while maintaining interpretability and efficiency for potential real-time analysis in particle accelerators.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"medical imaging\",\n        \"description\": \"The task is to design and implement a novel DeepLabV3+ model for highly precise subatomic structure segmentation in medical imaging using a combined dataset of subatomic particle interactions and cryo-electron tomography. The model should account for unique noise patterns and instrument artifacts in high-energy particle microscopy. Additionally, a transfer learning strategy is required to improve segmentation in low-data scenarios, with a focus on interpretability and efficiency for real-time analysis in particle accelerators.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean IoU (Intersection over Union)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"interpretablity metric (e.g., attention maps or model explainability)\",\n                \"value\": null,\n                \"unit\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Combined dataset of subatomic particle interactions and cryo-electron tomography\",\n            \"modality\": [\"image\", \"tabular\"],\n            \"target_variables\": [\"subatomic structures\"],\n            \"specification\": {\n                \"image_size\": null,\n                \"image_channels\": null,\n                \"tabular_features\": {\n                    \"noise patterns\": null,\n                    \"instrument artifacts\": null,\n                    \"high-energy particle microscopy metadata\": null\n                }\n            },\n            \"description\": \"A dataset that combines subatomic particle interactions and cryo-electron tomography data for accurate segmentation of subatomic structures in high-energy particle microscopy\",\n            \"preprocessing\": [\"noise reduction\", \"artifact correction\"],\n            \"augmentation\": [],\n            \"visualization\": [\"dataset examples\", \"feature visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"DeepLabV3+\",\n            \"family\": \"Convolutional Neural Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"novel adaptation of DeepLabV3+\",\n                \"parameters\": {\n                    \"number of layers\": null,\n                    \"kernel sizes\": null,\n                    \"encoder model\": \"pre-trained on ImageNet\"\n                }\n            },\n            \"description\": \"A DeepLabV3+ model tailored for medical imaging, addressing subatomic structure segmentation in high-precision settings.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"transfer learning for low-data regime\", \"real-time adaptation\"],\n        \"target_device\": \"high-performance compute cluster or specialized hardware for real-time analysis\",\n        \"deployment_endpoint\": \"optimized for particle accelerator environments\",\n        \"inference_engine\": [\"GPU-accelerated\", \"interpretable models\"],\n        \"demonstration\": \"segmentation results and interpretability explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the complexity and depth of the medical imaging project, indicating 'high' expertise level for the user. It covers all areas described in the task: a specialized DeepLabV3+ model, low-data transfer learning, interpretability, and efficiency for real-time analysis. The performance metrics capture accuracy and other desired segmentation measures, while the complexity metrics address inference time, memory usage, and interpretability. The dataset description and preprocessing steps reflect the unique challenges of the combined dataset. The model and service requirements are tailored to the project's needs. The confidence score is high, but missing specific numerical targets due to the nature of the task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "As a project manager for a specialized machine translation team, task them to design and implement a cutting-edge model that enhances translation from underrepresented Swahili to English. Utilize the Masakhane dataset, hybridizing Transformer-XL and ConvS2S models, targeting a minimum 5.5% absolute improvement in state-of-the-art BLEU scores, considering both efficiency and low-resource constraints.", "resposne": "{\n  \"user\": {\n    \"intent\": \"build\",\n    \"expertise\": \"high\"\n  },\n  \"problem\": {\n    \"area\": \"natural language processing\",\n    \"downstream_task\": \"machine translation\",\n    \"application_domain\": \"language services\",\n    \"description\": \"The task is to design and implement a state-of-the-art machine translation model focusing on underrepresented Swahili to English translation. The goal is to achieve a minimum 5.5% absolute improvement in BLEU scores compared to the current best, while considering efficiency and low-resource constraints. A hybrid model, Transformer-XL and ConvS2S, should be utilized, based on the Masakhane dataset.\",\n    \"performance_metrics\": [\n      {\n        \"name\": \"BLEU\",\n        \"value\": null\n      }\n    ],\n    \"complexity_metrics\": [\n      {\n        \"name\": \"efficiency\",\n        \"value\": null,\n        \"unit\": \"FLOPs\"\n      },\n      {\n        \"name\": \"low-resource constraint handling\",\n        \"value\": null,\n        \"unit\": \"\"\n      }\n    ]\n  },\n  \"dataset\": [\n    {\n      \"name\": \"Masakhane dataset\",\n      \"modality\": [\"text\"],\n      \"target_variables\": [\"Swahili\", \"English\"],\n      \"specification\": {\n        \"language_pair\": \"Swahili to English\",\n        \"resource_distribution\": \"low-resource\"\n      },\n      \"description\": \"The dataset for Swahili to English machine translation, designed to cater to underrepresented languages.\",\n      \"preprocessing\": [],\n      \"augmentation\": [],\n      \"visualization\": [],\n      \"source\": \"direct-search\"\n    }\n  ],\n  \"model\": [\n    {\n      \"name\": \"Hybrid Transformer-XL and ConvS2S\",\n      \"family\": \"neural networks\",\n      \"type\": \"neural networks\",\n      \"specification\": {\n        \"model_hybridization\": [\"Transformer-XL\", \"ConvS2S\"],\n        \"target_improvement\": 5.5,\n        \"units_of_improvement\": \"%\",\n        \"considerations\": [\"efficiency\", \"low-resource constraints\"]\n      },\n      \"description\": \"A state-of-the-art machine translation model combining Transformer-XL and ConvS2S architectures for Swahili to English translation, targeting a significant performance boost and optimized resource utilization.\"\n    }\n  ],\n  \"knowledge\": [\n    \"Masakhane dataset provides a valuable resource for underrepresented languages, and hybrid models are known to be effective in such scenarios.\"\n  ],\n  \"service\": {\n    \"feature_engineering\": [],\n    \"target_device\": \"cloud\",\n    \"deployment_endpoint\": \"cross-lingual translation API\",\n    \"inference_engine\": [\"GPU-accelerated\"],\n    \"demonstration\": \"Examples or use-cases showcasing Swahili to English translations and the 5.5% improvement\"\n  },\n  \"confidence\": {\n    \"rationale\": \"The JSON structure captures the user's intent to build a model with a high level of expertise. The problem area, task, and dataset are clearly defined, with the Masakhane dataset and hybrid model selection reflecting the instruction. Performance metrics focus on BLEU scores with a target improvement. Efficiency and low-resource constraints are considered. Missing specific values were left as 'null' to indicate optimization is necessary.\",\n    \"score\": 0.95\n  }\n}\n"}
{"task": "time-series anomaly detection", "instruction": "Sure! Here's a unique prompt for a more niche scenario:\r\n\r\nIn a research project for an industrial facility, you've been tasked with monitoring the real-time vibration data from hundreds of machine components across multiple shifts. The data spans a decade, with varying levels of granularity due to advancements in sensor technology. Your objective is to detect subtle anomalies in the time-series that could signal early signs of wear, impending equipment failures, or unexpected external impacts. However, the data also contains missing values and timestamp inconsistencies. Could you design and recommend a robust time-series analysis pipeline that not only identifies anomalies but also accounts for these complexities and integrates a predictive maintenance strategy? Additionally, please outline the evaluation metrics you'd use to assess the model's effectiveness in a safety-critical environment.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series anomaly detection\",\n        \"application_domain\": \"industrial facility, predictive maintenance\",\n        \"description\": \"In a real-world industrial scenario, a task is to develop a time-series analysis pipeline for monitoring vibration data from machine components. The pipeline should detect anomalies, handle missing values and timestamp inconsistencies, and incorporate predictive maintenance. The focus is on safety and early equipment failure prevention.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 Score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"Mean Average Precision (mAP)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"AUPRC (Area Under Precision-Recall Curve)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"Memory footprint\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Industrial Vibration Data\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"data_length\": \"decade\",\n                \"granularity_variations\": true,\n                \"number_of_components\": \"hundreds\",\n                \"missing_values\": true,\n                \"timestamp_inconsistencies\": true\n            },\n            \"description\": \"A large time-series dataset containing real-time vibration data from machine components across multiple shifts. Contains varying levels of data due to sensor advancements and challenges like missing values and inconsistent timestamps.\",\n            \"preprocessing\": [\n                \"imputation techniques for missing values\",\n                \"timestamp alignment and inconsistency handling\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\"data quality checks, anomaly patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning (RNN, LSTM, or Transformer-based)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"use_of_complex_models\": true,\n                \"predictive_maintenance_component\": true\n            },\n            \"description\": \"A deep learning model, possibly incorporating RNNs, LSTMs, or Transformers, designed to detect anomalies in real-time vibration data from industrial machine components, accounting for missing values and timestamp inconsistencies.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"preprocessing_strategy\": \"feature engineering based on domain knowledge\"\n        },\n        {\n            \"handling_complex_data\": \"use of ensemble methods or advanced imputation techniques\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"time-window slicing\", \"frequency domain analysis\"],\n        \"target_device\": \"cloud or edge computing\",\n        \"deployment_endpoint\": \"industrial monitoring system\",\n        \"inference_engine\": [\"GPU-based for faster inference\"],\n        \"demonstration\": \"real-time alerts and visualizations of anomaly predictions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response covers the user's intent to build a solution, high expertise level, and the specific requirements of the industrial scenario. It specifies the task of time-series anomaly detection, performance metrics like precision, recall, F1 Score, and AUPRC. Challenges like missing data and timestamp inconsistencies are addressed, along with the need for predictive maintenance. The dataset and model details are designed considering these requirements. Domain-specific knowledge and advanced techniques are included. The target deployment environment and evaluation process are also outlined.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "Apply a cutting-edge deep learning ensemble technique for time-series forecasting of daily mobile app DAUs, ensuring interpretability, robustness to anomalies, and cross-validation on multiple seasonal windows. The model should also incorporate feature engineering from external data sources and real-time performance evaluation with a rolling forecast window.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"mobile analytics\",\n        \"description\": \"The task is to develop a cutting-edge deep learning ensemble technique for time-series forecasting of daily mobile app DAUs (Daily Active Users). The model should prioritize interpretability, robustness to anomalies, and use cross-validation on multiple seasonal windows. It should also incorporate feature engineering from external data sources and provide real-time performance evaluation with a rolling forecast window.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"robustness to anomalies\",\n                \"value\": null\n            },\n            {\n                \"name\": \"model explainability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"response time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory consumption\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"DAUs\"],\n            \"specification\": {\n                \"data_length\": null,\n                \"feature_dim\": null\n            },\n            \"description\": \"A dataset containing daily mobile app DAUs for ensemble time-series forecasting, considering external data sources and real-time evaluation.\",\n            \"preprocessing\": [\"feature engineering from external data\"],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"seasonality analysis\",\n                \"anomaly detection\"\n            ],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning ensemble\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"ensemble_method\": \"ensemble of deep learning models\",\n                \"interpretability_features\": null,\n                \"anomaly_detection_technique\": null\n            },\n            \"description\": \"An ensemble of deep learning models for time-series forecasting, focusing on interpretability, anomaly robustness, and cross-validation across multiple seasonal windows.\"\n        }\n    ],\n    \"knowledge\": [\n        \"incorporate latest deep learning architectures like transformers or LSTMs with attention mechanisms\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature extraction from external data sources\",\n            \"real-time feature updates\"\n        ],\n        \"target_device\": \"cloud or server\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"efficient and optimized engines for real-time forecasting\"],\n        \"demonstration\": \"rolling forecast visualizations and performance metrics\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is derived from the given instruction, adhering to the JSON schema. The user's intent is to build a model, with high expertise level assumed. The problem area, tasks, and specific requirements (interpretability, anomaly detection, cross-validation) are included. The dataset source is a user-provided link, and a deep learning ensemble is suggested for the model. Real-time performance evaluation and feature engineering are clearly stated. Some details are missing, but they should be covered upon further discussion.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a machine learning project manager for a team tasked with enhancing a cutting-edge time-series forecasting system, you are now required to develop a state-of-the-art model using the ETTm2 dataset, split into train, validation, and test sets. The dataset consists of intricate, high-frequency real-world data with additional constraints on input sequence length (INPUT_SEQ_LEN=96 and INPUT_DIM=7) and prediction horizon (PRED_SEQ_LEN=96 and PRED_DIM=7). The model must not only minimize mean squared error (MSE) and mean absolute error (MAE) but also demonstrate robustness to seasonality and outliers, ensuring efficient anomaly detection and handling. Your team's objective is to achieve benchmark performance while implementing a novel feature extraction technique and adhering to a strict deadline of 60% less training time compared to previous projects.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"economics, finance, or industry\",\n        \"description\": \"The project involves enhancing a time-series forecasting system using the ETTm2 dataset with high-frequency real-world data, split into train, validation, and test sets. The model must handle seasonality, outliers, and anomaly detection while optimizing for mean squared error (MSE) and mean absolute error (MAE). Additionally, a novel feature extraction technique should be implemented, and the training time must be reduced by at least 60% compared to previous projects.\",\n        \"performance_metrics\": [\n            {\"name\": \"MSE\", \"value\": null},\n            {\"name\": \"MAE\", \"value\": null}\n        ],\n        \"complexity_metrics\": [\n            {\"name\": \"training time\", \"value\": null, \"unit\": \"% reduction from previous projects\"}\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ETTm2\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 7,\n                \"PRED_SEQ_LEN\": 96,\n                \"PRED_DIM\": 7,\n                \"data characteristics\": \"high-frequency, real-world, seasonality and outliers\"\n            },\n            \"description\": \"A high-frequency, real-world time-series dataset split into train, validation, and test sets for time-series forecasting. The model needs to handle seasonality and outliers while being efficient in anomaly detection.\",\n            \"preprocessing\": [\"novel feature extraction technique\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"state-of-the-art\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"time reduction\": \"60% less than previous projects\",\n                \"feature extraction\": \"novel technique\"\n            },\n            \"description\": \"A cutting-edge time-series forecasting model for the ETTm2 dataset, optimized for seasonality, anomaly detection, and efficient handling of outliers.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"benchmark performance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately captures the user's intent to build a state-of-the-art model, while acknowledging the need for high expertise level due to the advanced constraints. The problem description, metrics, and dataset requirements are derived from the given instruction. The novel feature extraction technique and reduced training time are incorporated in the model specifications. The '60% less training time' is translated to a reduction metric.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "As a machine learning project manager for a global e-commerce platform, you've been tasked with enhancing the user experience for a rapidly expanding international customer base. The company recently acquired a diverse set of startups, each with their own unique vernacular and product-related jargon. Develop an advanced machine translation system that not only translates queries in real-time but also adapts to regional dialects, technical terminology, and cultural idioms, while maintaining brand consistency in all responses. Additionally, outline a strategy for integrating this system seamlessly into the existing CRM system and training customer support agents to effectively leverage the technology for improved customer satisfaction and reduced response times.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"e-commerce, customer support\",\n        \"description\": \"The project aims to enhance the user experience by developing an advanced machine translation system for a global e-commerce platform. The system should handle real-time translations, adapt to regional dialects, technical jargon, and cultural idioms while maintaining brand consistency. Integration with the CRM system and training for customer support agents is also part of the scope, focusing on improved customer satisfaction and reduced response times.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"real-time translation accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"cultural adaptation accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"brand consistency score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"response time reduction\",\n                \"value\": null\n            },\n            {\n                \"name\": \"customer satisfaction rating\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"resource utilization\",\n                \"value\": null,\n                \"unit\": \"CPU cycles\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"latency (real-time translation)\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"system integration complexity\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"acquired startups' dialects and terminology data\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"language diversity\": \"various\",\n                \"domain-specific\": \"true\"\n            },\n            \"description\": \"Diverse data from acquired startups to train the system on regional vernaculars, technical jargon, and cultural idioms.\",\n            \"preprocessing\": [\"tokenization\", \"lemmatization\", \"terminology extraction\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced MT System\",\n            \"family\": \"neural machine translation\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"transformer-based\",\n                \"training data\": \"acquired startups' data\",\n                \"adaptation techniques\": \"context-aware, dynamic vocabulary\"\n            },\n            \"description\": \"A sophisticated NMT system designed to handle various languages and cultural nuances while maintaining brand consistency.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"context-sensitive translation\",\n            \"custom domain entity recognition\"\n        ],\n        \"target_device\": \"cloud-based, edge\",\n        \"deployment_endpoint\": \"CRM integration\",\n        \"inference_engine\": [\"GPU-optimized\", \"Caching mechanisms\"],\n        \"demonstration\": \"Mockaroo-generated simulation of real-world customer queries and responses\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction highlights a real-world business scenario, which suggests a build intent for a complex NLP project. The expert level is assumed to be high given the project's scale and requirements. Performance metrics, such as accuracy, response time, and customer satisfaction, are all critical, with real-time accuracy and brand consistency being specific targets. Complexity metrics are included to assess system efficiency and integration efforts.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a part of our ambitious biodiversity conservation initiative, we require a state-of-the-art machine learning model trained on a proprietary dataset of ultra-high-resolution aerial photographs captured from the rare Greenbelt Canopy Imaging System. The task is to classify not only the standard land use categories but also distinguish between endangered species habitats, pristine ecosystems, and human-intervened landscapes with sub-categories like coral reef health and elephant migration corridors. It is crucial that the model, built using a modified and hybridized version of the MViT (Mixed Vision Transformer) architecture, achieves an exceptional accuracy of at least 98%, demonstrates exceptional generalization across distinct geographical regions, and has a real-time prediction capability. Additionally, the deployed model should be optimized for edge computing on resource-constrained devices while maintaining low-latency, and come with exhaustive documentation including interpretability metrics, energy efficiency, and carbon footprint analysis. Please present a detailed plan for ethical considerations and data privacy regulations in the project.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"biodiversity conservation\",\n        \"description\": \"A state-of-the-art machine learning project is needed to classify land use categories, identify endangered species habitats, pristine ecosystems, and human-intervened landscapes using ultra-high-resolution aerial photographs from a Greenbelt Canopy Imaging System. The model should be based on a modified MViT architecture, achieve at least 98% accuracy, generalize across different regions, and have real-time prediction capability. The model must be optimized for edge computing on resource-constrained devices, with low latency, and include documentation for interpretability, energy efficiency, and carbon footprint analysis. Ethical considerations and data privacy regulations must be addressed in the project plan.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.98\n            },\n            {\n                \"name\": \"generalization\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time prediction\",\n                \"value\": true\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"energy efficiency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"carbon footprint\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size (on edge devices)\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": \"low\",\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Greenbelt Canopy Imaging System dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"land_use_categories\", \"endangered_species_habitats\", \"pristine_ecosystems\", \"human_intervened_landscapes\", \"coral_reef_health\", \"elephant_migration_corridors\"],\n            \"specification\": null,\n            \"description\": \"Proprietary dataset containing ultra-high-resolution aerial photographs for image classification tasks.\",\n            \"preprocessing\": [\"Modified MViT preprocessing\"],\n            \"augmentation\": [\"Geo-specific data augmentation\"],\n            \"visualization\": [\"Model interpretability visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Modified MViT\",\n            \"family\": \"neural networks\",\n            \"type\": \"hybridized vision transformer\",\n            \"specification\": {\n                \"accuracy\": {\n                    \"minimum\": 0.98,\n                    \"optimized\": true\n                },\n                \"geographical_generalization\": null,\n                \"real_time_inference\": true\n            },\n            \"description\": \"A cutting-edge image classification model based on a hybridized MViT, designed for high accuracy and real-time prediction on edge devices.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"data_privacy\": \"Compliance with GDPR and similar regulations, including data minimization and secure storage.\",\n            \"ethical_considerations\": \"Transparent AI, fairness, and consideration for endangered species and ecosystems.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"Edge computing optimization\", \"Real-time performance tuning\"],\n        \"target_device\": \"Resource-constrained edge devices\",\n        \"deployment_endpoint\": \"Edge computing infrastructure\",\n        \"inference_engine\": [\"Lightweight AI libraries\"],\n        \"demonstration\": \"Explainable AI predictions and comprehensive model performance visuals\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON captures the user's request, detailing a high-end machine learning project for biodiversity conservation. The MViT model modification, accuracy requirements, and edge computing constraints are all included. Performance metrics, interpretability, and ethical considerations are addressed, though some specific values remain unspecified, leaving room for optimization based on available resources.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "link prediction", "instruction": "Can a lightweight, interpretable deep learning architecture be effectively fine-tuned for link prediction in the specialized Citeseer repository, considering the dataset's sparse nature and accounting for domain-specific features?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"link prediction\",\n        \"application_domain\": \"information retrieval\",\n        \"description\": \"The user requests the development of a deep learning architecture for link prediction in the specialized Citeseer repository, specifically focusing on fine-tuning a lightweight and interpretable model. The challenge is the sparse nature of the dataset and the need to incorporate domain-specific features.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Citeseer graph\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"link_presence\"],\n            \"specification\": {\n                \"sparse\": true,\n                \"average_degree\": null,\n                \"feature_dimensions\": null,\n                \"number_of_nodes\": null\n            },\n            \"description\": \"A specialized graph dataset from the Citeseer repository for link prediction, with a sparse structure and domain-specific features.\",\n            \"preprocessing\": [\n                \"handle sparse data\",\n                \"feature engineering for domain-specific cues\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\"graph structure analysis\"],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Lightweight and interpretable deep learning model (e.g., Graph Convolutional Networks, Attention-based models)\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"number_of_layers\": null,\n                \"hidden_units\": null,\n                \"interpretability Techniques\": \"e.g., attention mechanisms or explainable AI methods\"\n            },\n            \"description\": \"A deep learning model designed for link prediction on the Citeseer dataset, accounting for its sparse nature and domain-specific features\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider optimizing for sparse data\",\n        \"Fine-tuning can improve performance on specialized domains\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"sparse data optimization\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"Citeseer-specific inference platform\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"PyTorch Inference\"],\n        \"demonstration\": \"explainable and interpretable model outcomes\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON response reflects the user's request to build a lightweight and interpretable deep learning model for link prediction in Citeseer, considering the sparse nature and domain-specific features. It includes a high-level plan for performance metrics, complexity constraints, dataset preprocessing, and deployment requirements. However, specific values for metrics and model architecture details are left open to be filled based on the user's expertise and a more comprehensive understanding of the task.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "object detection", "instruction": "The project manager must oversee the development of an advanced real-time sports event analytics system, utilizing a fine-tuned RetinaNet++ model optimized for detecting precise equipment and athlete movements in high Definition (HD) live streams. This adaptation must demonstrate exceptional speed and low latency, ensuring seamless performance in big-data broadcast scenarios involving the 'High-Resolution Sports-1M' dataset.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"sports analytics\",\n        \"description\": \"The task is to develop an advanced real-time sports event analytics system that employs a fine-tuned RetinaNet++ model for detecting equipment and athlete movements in high definition (HD) live streams. The system must have exceptional speed and low latency to ensure seamless performance in large-scale broadcast scenarios using the 'High-Resolution Sports-1M' dataset.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"frames per second (FPS)\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency\",\n                \"value\": null,\n                \"unit\": \"milliseconds (ms)\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"High-Resolution Sports-1M\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"equipment\", \"athlete movements\"],\n            \"specification\": {\n                \"image_resolution\": \"HD\",\n                \"data_format\": \"live streams\"\n            },\n            \"description\": \"A high-definition live-stream sports dataset for training and evaluating the fine-tuned RetinaNet++ model for equipment and athlete movements detection.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"RetinaNet++\",\n            \"family\": \"faster region-based convolutional neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"fine-tuning_details\": \"optimized for precision\",\n                \"input_resolution\": \"high definition (HD)\"\n            },\n            \"description\": \"A high-performance, real-time object detection model focusing on precise equipment and athlete movements detection in live sports streams.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"real-time processing hardware (for low latency)\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"optimized for specific hardware or streaming architecture\"],\n        \"demonstration\": \"a system showcasing seamless event analysis in live sports broadcasts\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is derived from the given instruction, with the user having a high level of expertise. The problem area is computer vision, specifically focusing on object detection for sports event analytics. The RetinaNet++ model, its requirements, and the High-Resolution Sports-1M dataset are accurately captured in the response. Performance metrics include accuracy, latency, and inference speed, while complexity metrics address low latency and memory footprint. The task's requirements for real-time performance are reflected in the target device and deployment details.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "The task is to develop an advanced wildlife monitoring system using the tailored iWildCam-Extended dataset, specifically focusing on endangered species in biodiverse low-light conditions. We require a state-of-the-art EfficientDet-Detector, optimized for real-time, high-resolution tracking on portable, energy-efficient devices with limited compute for field researchers in extreme environments.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"wildlife monitoring\",\n        \"description\": \"The user aims to develop an advanced wildlife monitoring system using the iWildCam-Extended dataset, targeting endangered species in low-light biodiverse conditions. The focus is on real-time, high-resolution tracking on portable, energy-efficient devices for field researchers in extreme environments.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"real-time performance\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean average precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"energy efficiency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"ms/frame\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"energy consumption per frame\",\n                \"value\": null,\n                \"unit\": \"mJ\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"iWildCam-Extended\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"specifically_endangered_species\": true,\n                \"low_light_conditions\": true,\n                \"high_resolution\": true\n            },\n            \"description\": \"A dataset focused on endangered species in biodiverse low-light environments for developing an advanced wildlife monitoring system.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"EfficientDet-Detector\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning object detection model\",\n            \"specification\": {\n                \"optimized_for_real_time\": true,\n                \"architecture\": \"EfficientDet\",\n                \"target_device\": \"portable, energy-efficient devices\",\n                \"compute_complexity\": \"limited\"\n            },\n            \"description\": \"A state-of-the-art object detection model designed for real-time tracking of endangered species in low-light conditions on portable devices with constrained compute resources.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"type\": \"requirement\",\n            \"content\": \"The model must be optimized for field researchers working in extreme environments.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"portable, energy-efficient devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"real-time optimization\"],\n        \"demonstration\": \"Field researcher scenarios and use cases\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent to build a model, their high expertise, and the specific details of the wildlife monitoring system. It includes the correct area (computer vision), downstream task (object detection), dataset, and model requirements. Performance and complexity metrics, as well as the dataset's specific characteristics, are included. The optimization for field researchers and the target deployment environment are also captured.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series classification", "instruction": "As a seasoned project manager for a cutting-edge AI research team, your mandate is to develop a highly specialized time-series classification algorithm. The UWave Gesture Library dataset, featuring intricate, real-world data with train, validation, and test partitions, has variable-length sequences (315 timesteps) and 3-dimensional feature vectors. The challenge lies in designing a model that not only accurately predicts one of the eight labels (ranging from 0 to 7) but also demonstrates robust generalization across diverse sub-populations. It's crucial to optimize for precision and efficiency while maintaining interpretability, all within a stringent computational budget and adhering to the latest deep learning best practices. Good luck in crafting a groundbreaking solution that outperforms state-of-the-art methods in terms of F1-score.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"AI research\",\n        \"description\": \"The task involves developing a specialized time-series classification algorithm using the UWave Gesture Library dataset with variable-length sequences (315 timesteps) and 3D feature vectors. The goal is to predict one of eight labels (0 to 7), demonstrate robust generalization, optimize precision, efficiency, and interpretability while adhering to computational budget and current deep learning practices, targeting high F1-score performance.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1-score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"computational budget\",\n                \"value\": null,\n                \"unit\": \"GPU hours\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"UWave Gesture Library\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"variable_length_sequences\": true,\n                \"feature_dimensions\": 3,\n                \"number_of_labels\": 8\n            },\n            \"description\": \"A dataset for time-series classification with variable-length sequences and real-world data split into train, validation, and test partitions.\",\n            \"preprocessing\": [\"latest deep learning data preprocessing techniques\"],\n            \"augmentation\": [\"None (since emphasizes interpretability and efficiency)\"],\n            \"visualization\": [\n                \"Interpretability-focused visualization techniques for model analysis\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"interpretability\": true\n            },\n            \"description\": \"A highly specialized time-series classification model using the latest deep learning practices, targeting precision, efficiency, and interpretability, optimized for the UWave Gesture Library dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Latest deep learning best practices and techniques for time-series analysis with variable-length sequences and a focus on interpretability.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"latest time-series specific techniques\",\n            \"efficiency-optimized transformations\"\n        ],\n        \"target_device\": \"high-performance GPU\",\n        \"deployment_endpoint\": \"efficient in-production environment\",\n        \"inference_engine\": [\"optimized for F1-score and computational efficiency\"],\n        \"demonstration\": \"Illustrative results showcasing improved F1-score over state-of-the-art\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response reflects the user's request for a high-expertise project in time-series classification, specifies the UWave dataset, highlights the importance of interpretability, and targets the F1-score optimization. The provided JSON structure is coherent and adheres to the given schema. However, without a specific model or exact metric values, the confidence score is slightly lower.\",\n        \"score\": 0.8\n    }\n}\n"}
{"task": "image classification", "instruction": "As a seasoned project manager for an advanced canine image classifier, your team must utilize the highly specific Stanford CanineVarieties4000 dataset. Optimize a real-time, deep convolutional neural network (ResNet50) with transfer learning for efficient breed detection, ensuring millisecond response times while maintaining accuracy across diverse lighting conditions.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"animal recognition\",\n        \"description\": \"Your team is tasked with optimizing a real-time canine image classifier using a deep convolutional neural network (ResNet50) with transfer learning. The focus is on the Stanford CanineVarieties4000 dataset, targeting efficient breed detection with millisecond response times and high accuracy under diverse lighting conditions.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"response time\",\n                \"value\": {\"unit\": \"milliseconds\", \"value\": null},\n                \"optimization_direction\": \"low\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Stanford CanineVarieties4000\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"breed\"],\n            \"specification\": {\n                \"image_size\": {\n                    \"width\": null,\n                    \"height\": null\n                },\n                \"number_of_classes\": 4000,\n                \"diverse_lighting\": true\n            },\n            \"description\": \"A highly specific dataset for canine breed detection, focusing on real-world conditions with the ResNet50 transfer learning.\",\n            \"preprocessing\": [],\n            \"augmentation\": [\"real-time lighting conditions\"],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"ResNet50\",\n            \"family\": \"deep convolutional neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_depth\": \"ResNet50\",\n                \"transfer_learning\": true,\n                \"architecture\": \"real-time\"\n            },\n            \"description\": \"A deep convolutional neural network (ResNet50) optimized with transfer learning for real-time canine breed detection.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"lighting normalization\"],\n        \"target_device\": \"embedded devices\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"Caffe\", \"TensorFlow Lite\"],\n        \"demonstration\": \"live canine detection with millisecond response\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is based on the given instruction, detailing a 'build' intent for optimizing a ResNet50 for real-time breed detection on the Stanford CanineVarieties4000 dataset. The user's high expertise is indicated. The problem area, specific dataset information, and performance metrics are clearly defined, along with the expected response times and optimization for diverse lighting conditions. Some missing details include image size, specific target accuracy value, and the exact device for deployment.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "In a high-security, HIPAA-compliant environment, a healthcare institution requires the machine learning team to develop an advanced image segmentation algorithm. The system must not only differentiate among skin conditions like rashes, moles, and lesions but also recognize subtle variations in severity, age-related changes, and track lesion evolution over time. Can you design a real-time, scalable, and interpretable solution that integrates seamlessly into our existing patient management platform?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"healthcare\",\n        \"description\": \"A healthcare institution needs an advanced image segmentation algorithm in a HIPAA-compliant environment. The algorithm should differentiate between skin conditions (rashes, moles, lesions), identify severity variations, account for age-related changes, and track lesion progression over time. The solution must be real-time, scalable, and interpretable, and integrate with the existing patient management platform.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 Score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"skin_condition\", \"severity\", \"age-related_changes\", \"lesion_evolution\"],\n            \"specification\": {\n                \"dimension\": \"depending on image resolution\",\n                \"color_channels\": \"RGB\"\n            },\n            \"description\": \"HIPAA-compliant images with skin conditions and lesion annotations for training, segmentation, and severity analysis.\",\n            \"preprocessing\": [\"data augmentation\", \"image resizing\"],\n            \"augmentation\": [\"rotation\", \"translation\", \"color jittering\"],\n            \"visualization\": [\"overlayed annotations\", \"heatmaps\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced Image Segmentation Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"architecture\": \"explainable deep learning\",\n                \"real-time capabilities\": true\n            },\n            \"description\": \"An advanced model designed for skin condition segmentation, considering severity, age-related changes, and lesion progression. Optimized for real-time inference in a scalable architecture.\"\n        }\n    ],\n    \"knowledge\": [\n        \"HIPAA compliance requirements and data handling\",\n        \"Integration with existing EHR systems\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"lesion evolution feature extraction\", \"age and severity feature encoding\"],\n        \"target_device\": \"cloud-based for HIPAA compliance\",\n        \"deployment_endpoint\": \"custom API or pre-built container\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"Docker\"],\n        \"demonstration\": \"Interactive dashboard or real-time image segmentation demo\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The given instruction provides a clear problem statement for a build intent. Expertise is assumed to be high due to the specific requirements of a healthcare environment and advanced image segmentation. Performance metrics and constraints (real-time, scalable, and interpretable) are included. The structure follows the JSON schema and aligns with the given examples.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Revise the Enron Email dataset project for node classification by employing a Hierarchical RGCN model, focusing on detecting collaboration roles among employees in specialized departments. Optimize for ultra-fast inductive learning on large-scale graphs with minimal resource consumption, targeting near-realtime analysis of millions of inter-departmental interactions.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"corporate network analysis\",\n        \"description\": \"The user wants to revise the Enron Email dataset project using a Hierarchical RGCN model for node classification, with the primary focus on detecting collaboration roles among employees in specialized departments. The goal is to optimize for ultra-fast inductive learning on large-scale graphs with minimal resource consumption for near-realtime analysis of millions of inter-departmental interactions.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"speed (inductive learning)\",\n                \"value\": \"near-realtime\",\n                \"unit\": \"minutes\"\n            },\n            {\n                \"name\": \"resource efficiency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"memory consumption (resource)\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Enron Email dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"employee_roles\"],\n            \"specification\": {\n                \"graph_size\": {\n                    \"nodes\": \"millions\",\n                    \"edges\": null\n                },\n                \"average_degree\": null,\n                \"department_structure\": \"specialized\"\n            },\n            \"description\": \"Large-scale graph dataset for inductive learning on the Enron Email network, representing employee collaboration among specialized departments.\",\n            \"preprocessing\": [\"cleaning\", \"graph construction\"],\n            \"augmentation\": [],\n            \"visualization\": [\"community detection\", \"role visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical RGCN\",\n            \"family\": \"graph neural networks\",\n            \"type\": \"ensemble models\",\n            \"specification\": {\n                \"architecture\": {\n                    \"层数\": null,\n                    \"隐藏层节点数\": null\n                },\n                \"optimization\": {\n                    \"optimizer\": \"optimized for resource efficiency\",\n                    \"learning_rate\": null,\n                    \"dropout\": null\n                }\n            },\n            \"description\": \"A Hierarchical RGCN model specifically designed for large-scale node classification with a focus on collaboration role detection among specialized departments.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"role embeddings\",\n            \"department-specific node features\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"optimized for edge or in-cluster inference\",\n        \"inference_engine\": [\"parallel processing\", \"lightweight libraries\"],\n        \"demonstration\": \"interactive visualizations and near-realtime updates\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response represents the given instruction well, reflecting the task of updating the Enron Email dataset project with a Hierarchical RGCN model. The specific focus on detecting collaboration roles, ultra-fast learning, and resource optimization for large-scale graphs is included. The model architecture, performance metrics, and service requirements align with the user's advanced expertise. Some details, like specific learning rate and model architecture, are left unspecified for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "As a project manager, you're seeking a sophisticated AI system to tackle the ADE20K indoor scene segmentation challenge, incorporating advanced Mask R-CNN with multi-scale feature pyramid networks. Mandate the team to develop a pipeline for joint training and inference that optimally handles crowded objects, targeting a minimum mAP of 45% with a focus on enhancing semantic accuracy. Emphasize the importance of rigorous benchmarking against current state-of-the-art models.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"indoor scene analysis\",\n        \"description\": \"The project aims to develop a sophisticated AI system for the ADE20K indoor scene segmentation challenge using advanced Mask R-CNN with multi-scale feature pyramid networks. The focus is on joint training and inference for crowded objects, targeting a minimum mAP of 45% while enhancing semantic accuracy.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mAP\",\n                \"value\": 0.45\n            },\n            {\n                \"name\": \"semantic accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference handling of crowded objects\",\n                \"value\": null,\n                \"unit\": \"optimized\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ADE20K indoor scene dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"scene segmentation\"],\n            \"specification\": {\n                \"architecture\": \"Mask R-CNN with multi-scale feature pyramid networks\"\n            },\n            \"description\": \"A dataset for the indoor scene segmentation task, incorporating advanced Mask R-CNN and targeted towards crowded objects and high mAP performance.\",\n            \"preprocessing\": [\"crowded object handling\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Mask R-CNN (Multi-scale FPN)\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"target mAP\": 0.45,\n                \"focus on semantic accuracy\": true\n            },\n            \"description\": \"A state-of-the-art Mask R-CNN model enhanced with multi-scale feature pyramid networks for advanced indoor scene segmentation with a focus on crowded objects.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Rigorous benchmarking against current state-of-the-art models is crucial.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"crowd handling techniques\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for crowded object scenarios\"],\n        \"demonstration\": \"Comparison with state-of-the-art models\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response accurately reflects the project manager's request for a sophisticated AI system using advanced Mask R-CNN with multi-scale feature pyramid networks for the ADE20K challenge. The expert level of the user and specific performance metrics are indicated. The dataset, model, and service requirements are based on the instructions provided, with a focus on benchmarking and handling crowded objects.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "The project manager needs a cutting-edge convolutional neural network (CNN) for image recognition, trained exclusively on the CIFAR-100 dataset, delivering a state-of-the-art accuracy of at least 99.5% while ensuring efficient hardware utilization and implementing transfer learning with a MobileNet backbone.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"deep learning\",\n        \"description\": \"The goal is to create a cutting-edge image recognition system using a convolutional neural network, specifically targeting the CIFAR-100 dataset. The expected performance is at least 99.5% accuracy, with a focus on efficient hardware utilization and implementing transfer learning with a MobileNet backbone.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.995\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"CIFAR-100\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"image_labels\"],\n            \"specification\": {\n                \"image_shape\": \"unknown (to be inferred from the CIFAR-100 data)\",\n                \"number_of_classes\": 100\n            },\n            \"description\": \"The CIFAR-100 dataset for training and testing the image recognition system.\",\n            \"preprocessing\": [\"transfer learning with MobileNet\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"CNN\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"convolutional neural network with MobileNet backbone\",\n                \"transfer_learning\": true,\n                \"hardware_optimization\": true,\n                \"FLOPs\": \"optimized for efficient hardware utilization\"\n            },\n            \"description\": \"A cutting-edge CNN for image recognition, leveraging MobileNet and achieving at least 99.5% accuracy on CIFAR-100. Transfer learning and hardware efficiency are key aspects.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Transfer learning from MobileNet is expected to boost performance\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"optimized for deployment on edge or cloud\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Visualize classification results and highlight efficiency improvements\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately captures the user's instruction, specifying a high-expertise level for building an advanced image recognition system with a CNN, MobileNet backbone, and the target accuracy. Transfer learning, hardware efficiency, and performance metrics are included. The dataset, model specifics, and service requirements are derived from the instruction. However, it's assumed that the dataset's image shape is unknown and should be inferred from the CIFAR-100. The confidence score is high given the clarity of the instructions.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a time-series forecasting project manager for the utilities sector, you are tasked with developing a cutting-edge deepAR model for the \"Smart Grid Electricity Demand Forecasting\" dataset. This dataset, collected over a decade, has been meticulously divided into training, validation, and test sets with hourly resolution. Your team must utilize a unique input sequence of the previous 96 days (with specific temperature and weather patterns as INPUT_SEQ_LEN=96 and INPUT_FEATURES=15), predicting the subsequent 96-hour energy consumption (PRED_SEQ_LEN=96, OUTPUT_FEATURES=50) with high accuracy. The model should excel in minimizing Mean Absolute Percentage Error (MAPE) and Root Mean Squared Percentage Error (RMSPE), while also incorporating seasonal trends and handling outliers. Your objective is to deliver a model with exceptional performance and real-world applicability.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"utilities\",\n        \"description\": \"As a time-series forecasting project manager, your team is assigned to develop a deepAR model for the Smart Grid Electricity Demand Forecasting dataset with hourly resolution. The task involves using a 96-day input sequence (featuring temperature and weather patterns) with 15 features to predict the subsequent 96 hours of energy consumption. The model should achieve high accuracy, minimize MAPE and RMSPE, account for seasonal trends, and handle outliers.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MAPE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"RMSPE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Inference time\",\n                \"value\": null,\n                \"unit\": \"hours\"\n            },\n            {\n                \"name\": \"Memory size\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Smart Grid Electricity Demand Forecasting\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"energy_consumption\"],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_FEATURES\": 15,\n                \"PRED_SEQ_LEN\": 96,\n                \"OUTPUT_FEATURES\": 50\n            },\n            \"description\": \"A decade-long dataset for electricity demand forecasting, divided into training, validation, and test sets. The task is to predict 96-hour energy consumption based on a 96-day input sequence with 15 specific temperature and weather-related features.\",\n            \"preprocessing\": [\"Seasonal decomposition\", \"Outlier detection\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"deepAR model\",\n            \"family\": \"neural networks\",\n            \"type\": \"sequence-to-sequence\",\n            \"specification\": {\n                \"architecture\": {\n                    \"model_type\": \"deepAR\",\n                    \"seasonality\": true\n                },\n                \"training\": {\n                    \"loss\": [\"MAPE\", \"RMSPE\"]\n                }\n            },\n            \"description\": \"A cutting-edge deep learning model for electricity demand forecasting, considering seasonal trends, handling outliers, and utilizing a 96-day input sequence with 15 features.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"feature scaling\", \"custom feature extraction\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"cloud-based deployment\"],\n        \"demonstration\": \"A demo showcasing model performance on real-world data from the Smart Grid Electricity Demand Forecasting dataset.\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This JSON response reflects the user's instruction, including the task to build a deepAR model for electricity demand forecasting. The user's expertise level is high, and the problem area, task, and dataset characteristics are well-explained. Metrics and preprocessing/augmentation steps match the requirements, and a suitable model description is provided. Target device, deployment, and the demonstration specifics are mentioned but not detailed in the instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a project manager for a high-accuracy visual recognition system, I need a state-of-the-art machine learning model that not only discriminates between cat and dog images but also differentiates among various breeds, ages, and actions within each category, with minimal false positives under variable lighting and background conditions. Develop a scalable and robust classifier using a deep convolutional neural network architecture.", "resposne": "{\n  \"user\": {\n    \"intent\": \"build\",\n    \"expertise\": \"high\"\n  },\n  \"problem\": {\n    \"area\": \"computer vision\",\n    \"downstream_task\": \"image classification\",\n    \"application_domain\": \"artificial intelligence\",\n    \"description\": \"The project requires a high-accuracy visual recognition system that can differentiate between cat and dog images, as well as their breeds, ages, and actions. The model should be scalable, robust, and have minimal false positives, accounting for variable lighting and background conditions.\",\n    \"performance_metrics\": [\n      {\n        \"name\": \"accuracy\",\n        \"value\": null\n      },\n      {\n        \"name\": \"precision\",\n        \"value\": null\n      },\n      {\n        \"name\": \"recall\",\n        \"value\": null\n      },\n      {\n        \"name\": \"specificity\",\n        \"value\": null\n      }\n    ],\n    \"complexity_metrics\": [\n      {\n        \"name\": \"scalability\",\n        \"value\": \"high\"\n      },\n      {\n        \"name\": \"robustness\",\n        \"value\": null\n      },\n      {\n        \"name\": \"inference time\",\n        \"value\": null,\n        \"unit\": \"seconds\"\n      },\n      {\n        \"name\": \"memory size\",\n        \"value\": null,\n        \"unit\": \"MB\"\n      }\n    ]\n  },\n  \"dataset\": [\n    {\n      \"name\": \"\",\n      \"modality\": [\"image\"],\n      \"target_variables\": [\"category\", \"breed\", \"age\", \"action\"],\n      \"specification\": null,\n      \"description\": \"A collection of cat and dog images with varying breeds, ages, and actions under different lighting and background conditions.\",\n      \"preprocessing\": [\"image resizing\", \"data augmentation\"],\n      \"augmentation\": [\"color jittering\", \"affine transformations\"],\n      \"visualization\": [\"data distribution\", \"error analysis\"],\n      \"source\": \"user-upload\"\n    }\n  ],\n  \"model\": [\n    {\n      \"name\": \"\",\n      \"family\": \"deep convolutional neural networks\",\n      \"type\": \"neural networks\",\n      \"specification\": {\n        \"architecture\": \"state-of-the-art\",\n        \"layers\": [\n          {\n            \"type\": \"convolutional\",\n            \"parameters\": {\n              \"filters\": 64,\n              \"kernel_size\": 3,\n              \"stride\": 1\n            }\n          },\n          {\n            \"type\": \"max-pooling\",\n            \"parameters\": {\n              \"pool_size\": 2,\n              \"stride\": 2\n            }\n          }\n        ],\n        \"optimizer\": {\n          \"type\": \"Adam\",\n          \"learning_rate\": null\n        },\n        \"dropout_rate\": null\n      },\n      \"description\": \"A deep CNN for high-accuracy visual recognition system, catering to multiple criteria like breed, age, and action.\"\n    }\n  ],\n  \"knowledge\": [\n    \"State-of-the-art models like ResNet, DenseNet, or EfficientNet could be a good starting point.\"\n  ],\n  \"service\": {\n    \"feature_engineering\": [],\n    \"target_device\": \"cloud\",\n    \"deployment_endpoint\": \"API service\",\n    \"inference_engine\": [\"TensorFlow Serving\", \"on-demand GPU inference\"],\n    \"demonstration\": \"Interactive web demo with real-time predictions\"\n  },\n  \"confidence\": {\n    \"rationale\": \"The JSON response captures the key requirements of the visual recognition system, including the desire for a deep CNN architecture, high accuracy, and robustness against varying conditions. Performance metrics and model complexity constraints have been specified. However, there is a lack of specific dataset or model details, so these are left open. The target device and deployment details are estimated based on the need for scalability. The confidence score is high because the structure and essential details align with the instruction.\",\n    \"score\": 0.95\n  }\n}\n"}
{"task": "time-series forecasting", "instruction": "You are now tasked with developing a sophisticated time-series forecasting system for a comprehensive real-world dataset (ILI), with a focus on the train, validation, and test partitions. The data consists of complex, non-linear patterns in a time series of 7-dimensional observations (INPUT_SEQ_LEN=36). Your challenge is to design a multi-step predictive model that forecasts the subsequent 24 steps (PRED_SEQ_LEN=24) with accuracy, utilizing advanced feature extraction and considering seasonality effects. To demonstrate proficiency, you must optimize the model's performance using Mean Squared Error (MSE) and Mean Absolute Error (MAE) as key evaluation metrics, while ensuring interpretability and scalability.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"healthcare or economics\",\n        \"description\": \"The task is to develop a sophisticated time-series forecasting system using a real-world dataset (ILI) with 7-dimensional observations. The focus is on train, validation, and test partitions, and the objective is to predict the subsequent 24 steps with complex, non-linear patterns, considering seasonality. The model should be interpretable and scalable, and performance should be optimized with Mean Squared Error (MSE) and Mean Absolute Error (MAE).\",\n        \"performance_metrics\": [\n            {\"name\": \"Mean Squared Error (MSE)\", \"value\": null},\n            {\"name\": \"Mean Absolute Error (MAE)\", \"value\": null}\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ILI\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 36,\n                \"features\": {\n                    \"dimension\": 7,\n                    \"interpretability\": true,\n                    \"complexity\": \"non-linear\"\n                }\n            },\n            \"description\": \"A comprehensive dataset with 7-dimensional time series data, considering seasonality, for developing a multi-step forecasting model.\",\n            \"preprocessing\": [\"advanced feature extraction\", \"seasonality adjustment\"],\n            \"augmentation\": [],\n            \"visualization\": [\"interpretability-focused\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks\",\n            \"type\": \"multi-step forecasting model\",\n            \"specification\": {\n                \"model_structure\": \"interpretable\",\n                \"scalability\": true,\n                \"number_of_steps\": 24\n            },\n            \"description\": \"A sophisticated, interpretable multi-step forecasting model designed for complex, non-linear time series data, accounting for seasonality and optimized for performance with MSE and MAE.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"focus on interpretability and model performance for 24-step forecasting\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure adheres to the provided schema. The user's intent to build a model with high expertise is evident. The task is clearly defined as time-series forecasting, with focus on dataset characteristics, advanced feature extraction, seasonality, and evaluation metrics. The model is specified as a neural network-based multi-step forecasting model for interpretability and scalability. Performance is emphasized on MSE and MAE, as instructed.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "sequential recommendation", "instruction": "## Created Prompt ##\r\nIn an ambitious project for the specialized anime streaming platform 'AnimeVerse,' we aim to develop a state-of-the-art sequential recommendation system.Utilizing the unique combination of audio descriptions and fan subbed comments in the 'AnimeVerse Conversations' dataset, design a deep learning model based on the fusion of MFT-Transformer and SimCSE, tailored to comprehend the nuanced emotions and in-depth preferences of users. The system must not only predict the next episode but also suggest related fan art and discussion threads for an immersive user experience, thereby enhancing user engagement and retention. Ensure the model integrates real-time sentiment analysis and community topic trends for dynamically personalized recommendations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"recommendation systems\",\n        \"downstream_task\": \"sequential recommendation\",\n        \"application_domain\": \"entertainment\",\n        \"description\": \"The user is asking for a state-of-the-art sequential recommendation system for AnimeVerse, which will combine audio descriptions and fan-subbed comments from the 'AnimeVerse Conversations' dataset. The model should be based on MFT-Transformer and SimCSE fusion to understand users' nuanced emotions and preferences, and must predict next episodes, suggest related fan art, and incorporate real-time sentiment analysis and community topic trends for personalized recommendations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean average precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean reciprocal rank\",\n                \"value\": null\n            },\n            {\n                \"name\": \"user engagement rate\",\n                \"value\": null\n            },\n            {\n                \"name\": \"user retention rate\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"AnimeVerse Conversations\",\n            \"modality\": [\"text\", \"audio\", \"multimodal\"],\n            \"target_variables\": [\n                \"next_episode\", \n                \"related_fan_art\", \n                \"discussion_threads\"\n            ],\n            \"specification\": {\n                \"audio_features_length\": null, \n                \"text_length\": null,\n                \"multimodal_data_format\": null\n            },\n            \"description\": \"Dataset combining audio descriptions and fan-subbed comments from AnimeVerse, capturing user interactions for understanding preferences and sentiment.\",\n            \"preprocessing\": [\"audio feature extraction\", \"text tokenization\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"MFT-Transformer-SimCSE\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"MFT-Transformer\",\n                \"training_strategy\": \"SimCSE-based fine-tuning\",\n                \"num_layers\": null,\n                \"hidden_units\": null,\n                \"attention_heads\": null\n            },\n            \"description\": \"A deep learning model that fuses MFT-Transformer and SimCSE for sequential recommendations, incorporating real-time sentiment analysis and community trends.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Real-time sentiment analysis\",\n        \"Community topic trending detection\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"audio embeddings\", \"sentiment analysis embeddings\"],\n        \"target_device\": \"cloud-based for scalability\",\n        \"deployment_endpoint\": \"AnimeVerse recommendation API\",\n        \"inference_engine\": [\"GPU-optimized for faster processing\"],\n        \"demonstration\": \"Interactive dashboard showcasing personalized recommendations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure accurately represents the provided instruction, following the schema. The intent is 'build' as a new recommendation system is requested. The expertise level is assumed to be 'high' due to the complexity of the project. The problem area and downstream task are clearly defined. Performance metrics include precision, recall, and engagement rates. Real-time sentiment analysis and community trends are key features. The 'confidence' score is not explicitly provided, but the substantial requirements indicate a clear understanding.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "For the Amazon e-commerce network's intricate community detection project, design a GraphSAGE-enhanced ChebNet model specifically tailored for edge-weighted, high-dimensional product node classification. Target at least 95% precision on the diverse subgraph classification task, ensuring real-time adaptability and efficient handling of live graph updates with billions of nodes.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"network analysis, recommendation systems\",\n        \"description\": \"The task is to design a GraphSAGE-enhanced ChebNet model for edge-weighted, high-dimensional product node classification in the Amazon e-commerce network. The goal is to achieve at least 95% precision in diverse subgraph classification while ensuring real-time adaptability and efficient handling of live graph updates with billions of nodes.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"real-time\"\n            },\n            {\n                \"name\": \"memory consumption\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Amazon e-commerce network (product nodes)\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"node_type\": \"products\",\n                \"edge_weighted\": true,\n                \"node_dimensions\": {\n                    \"high\": true\n                }\n            },\n            \"description\": \"A large-scale, edge-weighted product graph with billions of nodes, where the task involves classifying product nodes using a GraphSAGE-ChebNet model.\",\n            \"preprocessing\": [\"GraphSAGE data sampling\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"GraphSAGE-ChebNet\",\n            \"family\": \"neural networks\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"GraphSAGE\": {},\n                    \"ChebNet\": {}\n                },\n                \"real-time adaptability\": true\n            },\n            \"description\": \"A GraphSAGE-enhanced ChebNet architecture for edge-weighted, high-dimensional product node classification on the Amazon e-commerce network.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for billion-node graphs\"],\n        \"demonstration\": \"real-time subgraph classification with billion-node graph updates\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON is structured based on the given instruction, with the user's high expertise level. The task is specified as building a GraphSAGE-ChebNet model for product node classification, and the performance metric of 95% precision is set. Real-time adaptability and efficient handling of live updates are considered in complexity metrics. The dataset and model specifications match the provided details. A deployment endpoint is suggested for cloud-based deployment.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "object detection", "instruction": "As we delve into the futuristic realm of sustainable city planning, a cutting-edge machine learning team is tasked with developing a novel object detection system for the 'MetropolisAI' dataset. The project necessitates the creation of a next-generation YOLOv4 architecture, capable of simultaneously detecting not only conventional vehicles, pedestrians, and traffic signs but also eco-friendly public transport, cyclists with advanced safety features, and smart traffic beacons. Targeting an unprecedented accuracy of 92% with a strict energy efficiency criterion, the model must operate at a breathtaking 60 FPS on minimal power consumption devices, ensuring minimal environmental impact without compromising performance.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"sustainable urban planning\",\n        \"description\": \"A machine learning team is tasked with developing a next-generation YOLOv4 object detection system for the MetropolisAI dataset. The system should detect conventional vehicles, pedestrians, traffic signs, eco-friendly public transport, advanced safety-equipped cyclists, and smart traffic beacons, aiming for 92% accuracy while maintaining 60 FPS performance on minimal power devices with a focus on environmental friendliness.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.92\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time (FPS)\",\n                \"value\": 60,\n                \"unit\": \"frames per second\"\n            },\n            {\n                \"name\": \"energy efficiency\",\n                \"value\": 1, \n                \"unit\": \"efficient on minimal power consumption devices\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"MetropolisAI\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"conventional_vehicles\", \"pedestrians\", \"traffic_signs\", \"eco_transport\", \"safety_bike\", \"smart_beacons\"],\n            \"specification\": null,\n            \"description\": \"A dataset for developing a next-gen YOLOv4 model focusing on sustainable city planning with an emphasis on detecting various elements.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"YOLOv4\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"YOLOv4 architecture with improved detection capabilities\",\n                \"number_of_parameters\": null,\n                \"FLOPs\": null\n            },\n            \"description\": \"A next-gen YOLOv4 model targeting object detection with advanced features in the context of sustainable city planning.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Advanced safety features for cyclists and smart traffic beacons as detection targets\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"minimal power consumption devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"energy-efficient\"],\n        \"demonstration\": \"92% accuracy with 60 FPS on minimal power devices\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction is translated into a high-expertise machine learning project with clear object detection requirements, performance targets, and dataset description. The YOLOv4 model, its advanced features, and the strict energy efficiency criterion are captured. However, specific model parameters like number of parameters and FLOPs are missing for optimization and should be included for a more complete representation.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "object detection", "instruction": "For a high-security, underwater archaeological excavation, we require a cutting-edge object detection system that can accurately recognize not only historical artifacts but also rare marine debris, underwater salvage equipment, and potential biohazards. The model should be based on the YOLOv5 architecture due to its exceptional precision on small and occluded objects, maintaining an average precision of over 95% and a real-time performance of less than 30 milliseconds per frame, with a customized dataset containing underwater images from various depths and lighting conditions, as well as advanced, encrypted marine threat data. Additionally, the model must integrate seamlessly with the diver's wearable technology, providing real-time alerts and maps to avoid disturbance of the fragile ecosystem.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"archaeology & marine science\",\n        \"description\": \"A high-precision object detection system is needed for underwater archaeological excavation, detecting historical artifacts, rare marine debris, salvage equipment, and biohazards. The model must be based on YOLOv5 architecture and meet specific performance criteria: average precision over 95%, real-time with <30 ms/frame. It requires a custom dataset with underwater images from varying depths and lighting, encrypted marine threat data, and seamless integration with diver's wearable tech for real-time alerts and map guidance.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"average precision\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"real-time performance\",\n                \"value\": 30,\n                \"unit\": \"milliseconds per frame\"\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Underwater Archaeology & Threat Detection Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"artifact\", \"marine_debris\", \"salvage_equipment\", \"biohazard\"],\n            \"specification\": {\n                \"image_type\": \"underwater\",\n                \"depth_range\": \"\",\n                \"lighting_conditions\": \"varied\",\n                \"encrypted_data\": true\n            },\n            \"description\": \"Custom dataset for YOLOv5 with underwater images, covering depths and lighting conditions, and including advanced encrypted marine threat data.\",\n            \"preprocessing\": [],\n            \"augmentation\": [\"small_object_scale\", \"occlusion\"],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"YOLOv5 Object Detection Model for Underwater Archaeology\",\n            \"family\": \"YOLOv5\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"YOLOv5\",\n                \"precision\": \"95%\",\n                \"latency\": \"30 ms per frame\",\n                \"object_detection_technique\": \"Real-time with small & occluded objects\"\n            },\n            \"description\": \"A customized YOLOv5 model tailored for the unique requirements of underwater archaeological and environmental monitoring.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"diver's wearable technology\",\n        \"deployment_endpoint\": \"real-time alerting & map integration\",\n        \"inference_engine\": [\"lightweight\"],\n        \"demonstration\": \"real-time alerts and visual guidance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is crafted based on the provided instruction, which specifies a complex problem involving object detection for an underwater archaeological setting. The expertise level is assumed to be 'high' due to the requirements for high precision, custom dataset, and integration with advanced technology. All performance and complexity metrics are detailed, reflecting the specific demands. The model and service requirements are specified accordingly.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "tabular classification", "instruction": "As a machine learning development team, you have been assigned to work on a highly specialized tabular classification challenge in the field of bioinformatic disease prognosis. Your team has been given access to the 'Phylogenetic Bacteria Species Detection' dataset, which is enriched with complex, inter-dependent variables from diverse ecological habitats. The dataset is partitioned into training, validation, and test sets, each containing intricate relationships between host adaptation, genetic markers, and environmental factors.\r\n\r\nYour objective is to design and train a state-of-the-art multi-label classifier that can accurately predict the presence of multiple bacterial species (Genus_A, Genus_B, and Genus_C) in a novel sample, as well as their resistance patterns to antibiotics (Antibiotic_Resistances_A, Antibiotic_Resistances_B, and Antibiotic_Resistances_C). The evaluation metric for this task will be the micro F1 score, considering the fine-grained nature of the labels and the importance of balanced performance across all classes. Showcase your team's expertise in handling complex data and extracting meaningful insights for public health research.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"tabular data analysis\",\n        \"downstream_task\": \"tabular classification\",\n        \"application_domain\": \"bioinformatics, disease prognosis\",\n        \"description\": \"Design and train a state-of-the-art multi-label classifier for predicting the presence of Genus_A, Genus_B, and Genus_C bacterial species, as well as their antibiotic resistance patterns in a novel sample. The dataset is the Phylogenetic Bacteria Species Detection dataset with complex, inter-dependent variables and partitioned into train, validation, and test sets.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"micro F1 score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Phylogenetic Bacteria Species Detection\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"Genus_A\", \"Genus_B\", \"Genus_C\", \"Antibiotic_Resistances_A\", \"Antibiotic_Resistances_B\", \"Antibiotic_Resistances_C\"],\n            \"specification\": null,\n            \"description\": \"A bioinformatic dataset with complex interdependent variables from diverse ecological habitats. Partitioned into training, validation, and test sets for a highly specialized multi-label classification challenge.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_type\": \"multi-label\",\n                \"architecture\": \"state-of-the-art\",\n                \"interpretability\": \"highly interpretable\"\n            },\n            \"description\": \"A multi-label classifier designed for predicting bacterial species and antibiotic resistance patterns in a novel sample, showcasing expertise in handling complex data and extracting insights for bioinformatic disease prognosis.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"description\": \"Understanding the importance of balanced performance across all classes due to the fine-grained nature of labels and relevance to public health research.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"required for showcasing balanced performance and insights to public health stakeholders\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response accurately captures the task, selecting 'build' intent, targeting a high expertise level, focusing on the tabular data analysis area, and specifying a multi-label classification problem. The dataset, metrics, and model details are extracted from the given instruction. We assumed a state-of-the-art neural network model and highlighted the importance of interpretability in bioinformatic disease prognosis. The confidence score is high due to the clear and detailed mapping of the instruction to the schema.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "In the dynamic realm of haute couture and sustainable fashion, a nascent fusion of haute couture designs and eco-friendly materials is creating a new niche. Develop a state-of-the-art image classifier that not only discerns intricate embroidery, fabrics, and silhouettes but also identifies the origin of sustainable materials and production methods. This advanced solution should ensure a seamless integration into a luxury e-commerce platform, enhancing user experience by suggesting ethically sourced and unique designs while optimizing search and personalization algorithms.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"fashion, sustainability\",\n        \"description\": \"The task is to create a state-of-the-art image classifier for haute couture designs that incorporate eco-friendly materials and production methods. The classifier should identify embroidery, fabrics, silhouettes, sustainable material origin, and production methods. The solution should integrate seamlessly into a luxury e-commerce platform, improving user experience by suggesting ethically sourced, unique designs, and optimizing search and personalization algorithms.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"specificity\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean IoU\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Haute Couture & Sustainability Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"embroidery\", \"fabrics\", \"silhouettes\", \"sustainable_material\", \"production_method\"],\n            \"specification\": null,\n            \"description\": \"A dataset of haute couture designs with eco-friendly elements, capturing intricate details and material properties for training and evaluation.\",\n            \"preprocessing\": [\"rescaling\", \"color normalization\"],\n            \"augmentation\": [\"random cropping\", \"Gaussian blur\"],\n            \"visualization\": [\"feature maps\"],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep convolutional neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"custom, possibly using transfer learning\",\n                \"depth\": null,\n                \"width\": null,\n                \"pre-trained base model\": true,\n                \"GPU accelerated\": true\n            },\n            \"description\": \"A state-of-the-art image classifier for haute couture and sustainable fashion, incorporating advanced techniques for material and method recognition.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Utilize transfer learning from existing fashion and material datasets\",\n        \"Fine-tune for eco-friendly attributes\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"extracting texture and pattern features\", \"sustainable materials encoding\"],\n        \"target_device\": \"cloud-based\",\n        \"deployment_endpoint\": \"high-performance server\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"Kubernetes\"],\n        \"demonstration\": \"model predictions on user-chosen fashion images with explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure reflects the given instruction, considering the user's intent as 'build', high expertise, and the focus on computer vision and e-commerce application. Performance metrics and complexity constraints are included based on the requirements. The dataset and model descriptions are inferred from the context. However, certain values, such as accuracy and specific model specifications, are left unspecified for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "tabular classification", "instruction": "As a specialized project manager for a deep learning team, you're tackling a high-dimensional tabular classification challenge. The \"Interstellar Operations Dataset\" contains 50 unique feature groups, with missing values denoted by 'unseen stars'. Your team must develop a robust CatBoost model optimized for AUC-ROC, using stratified K-fold cross-validation on train, validation, and test sets. The goal is to achieve superior true positive rate in predicting the binary label ' Successful Mission Outcome', with accuracy benchmarked on the withheld test set.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"tabular data analysis\",\n        \"downstream_task\": \"tabular classification\",\n        \"application_domain\": \"space operations\",\n        \"description\": \"The task involves developing a high-dimensional tabular classification model, specifically using the Interstellar Operations Dataset with 50 unique feature groups and missing values represented by 'unseen stars'. The goal is to build a CatBoost model optimized for AUC-ROC, employing stratified K-fold cross-validation on train, validation, and test sets. The focus is on achieving a superior true positive rate for predicting the binary label 'Successful Mission Outcome', with accuracy benchmarked on the held-out test set.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Interstellar Operations Dataset\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"Successful Mission Outcome\"],\n            \"specification\": {\n                \"feature_groups\": 50,\n                \"missing_values\": \"unseen stars\"\n            },\n            \"description\": \"A high-dimensional dataset with 50 unique feature groups, focused on predicting the binary 'Successful Mission Outcome' label, with missing data handled as 'unseen stars'.\",\n            \"preprocessing\": [\n                \"handling missing values\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"CatBoost\",\n            \"type\": \"ensemble models\",\n            \"specification\": {\n                \"optimization\": \"AUC-ROC\",\n                \"cross-validation\": \"stratified K-fold\"\n            },\n            \"description\": \"A CatBoost model optimized for AUC-ROC and stratified K-fold cross-validation on the Interstellar Operations Dataset to achieve high TPR for predicting 'Successful Mission Outcome'.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"handling missing values\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"accuracy on the test set\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response represents a valid interpretation of the instruction, capturing the complexity of a high-dimensional tabular classification project using a CatBoost model. The metrics (AUC-ROC and accuracy on test set) and data handling strategies (stratified K-fold and handling missing values) are accurately extracted. The high expertise level of the user and the specific nature of the task are also indicated.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "sequential recommendation", "instruction": "## Enhanced Prompt for the AI Challenge ##\r\nIn the cutting-edge anime streaming platform 'AnimeVerse,' our task is to devise an elite sequential recommendation system that pushes the boundaries of AI capabilities. Harness the extensive 'AnimeVerse Conversations' dataset, which combines audio transcripts with intricately detailed fan-subbed annotations, to design an advanced fusion model, marrying MFT-Transformer and SimCSE. The model must decode complex emotions, subtle user inclinations, and cater to their evolving interests. To achieve this, design a sophisticated system that forecasts not only the subsequent episode butalso anticipates intricate connections such as collaborative fan art and concurrent discussion forums, creating an immersive experience. Implement real-time sentiment analysis and incorporate dynamic community themes, adjusting recommendations to reflect the zeitgeist, to maximize user satisfaction, satisfaction rate, and long-term loyalty. Ensure the algorithm is robust, efficient, and demonstrates a high level of interpretability, reflecting the platform's commitment to user-centric innovation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"recommendation systems\",\n        \"downstream_task\": \"sequential recommendation\",\n        \"application_domain\": \"entertainment, anime streaming\",\n        \"description\": \"The task is to design a state-of-the-art sequential recommendation system for 'AnimeVerse', using the 'AnimeVerse Conversations' dataset. The system should combine MFT-Transformer and SimCSE for better emotion decoding and user interest prediction. It should anticipate intricate connections like fan art and discussion forums in real-time. The main performance metrics are user satisfaction, satisfaction rate, and long-term loyalty. Interpretability is also a priority.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"user satisfaction\",\n                \"value\": null\n            },\n            {\n                \"name\": \"satisfaction rate\",\n                \"value\": null\n            },\n            {\n                \"name\": \"long-term loyalty\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"efficiency\",\n                \"value\": null,\n                \"unit\": \"inferences/second\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"AnimeVerse Conversations\",\n            \"modality\": [\"text\", \"audio\"],\n            \"target_variables\": [\"next_episode\", \"collaborative_art\", \"discussion_connections\"],\n            \"specification\": null,\n            \"description\": \"A dataset containing audio transcripts and fan-subbed annotations for advanced sequential recommendation and sentiment analysis in AnimeVerse.\",\n            \"preprocessing\": [\"emotion extraction\", \"contextual tokenization\"],\n            \"augmentation\": [\"synthetic data generation\"],\n            \"visualization\": [\"data distribution analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"MFT-Transformer + SimCSE fusion model\",\n            \"family\": \"neural networks\",\n            \"type\": \"recommendation models\",\n            \"specification\": {\n                \"architecture\": \"MFT-Transformer and SimCSE fused\",\n                \"complexity\": \"advanced fusion for multi-modal understanding\"\n            },\n            \"description\": \"A sophisticated model combining MFT-Transformer and SimCSE to predict user interests and analyze real-time sentiment in the AnimeVerse context.\"\n        }\n    ],\n    \"knowledge\": [\n        \"AnimeVerse: cutting-edge anime platform\",\n        \"MFT-Transformer: for emotion and interest decoding\",\n        \"SimCSE: for better context understanding\",\n        \"Context-aware recommendations and sentiment analysis\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"user profiling\", \"dynamic theme updates\"],\n        \"target_device\": \"cloud-based for real-time processing\",\n        \"deployment_endpoint\": \"AnimeVerse platform integration\",\n        \"inference_engine\": [\"real-time computation\"],\n        \"demonstration\": \"personalized immersive experience in AnimeVerse\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is based on the given instruction, maintaining the specified schema format. The intent is clear as 'build', reflecting the need for a recommendation system. Expertise level is set to 'high' due to the complexity and technical aspects mentioned. The metrics align with the requirements for evaluating user satisfaction and system efficiency. Important information like data modalities, model architecture, and platform integration are accurately captured.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Transform the Enron Email dataset into a high-dimensional node classification challenge, requiring the machine learning development team to design a novel Hierarchical RGCN architecture with multi-resolution graph embeddings. Ensure not only department-level collaboration analysis but also sub-department expertise identification. Strive for maximal efficiency in training on enormous datasets, enabling real-time analysis of massive graphs (50+ million edges) on limited computational hardware, with strict latency constraints of less than 100 milliseconds.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"enterprise management\",\n        \"description\": \"The task is to convert the Enron Email dataset into a high-dimensional node classification challenge, requiring a Hierarchical RGCN architecture with multi-resolution graph embeddings for department and sub-department collaboration and expertise identification. The model should be efficient in training on large datasets (50+ million edges) and provide real-time analysis with a latency constraint of less than 100 milliseconds.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"efficiency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": {\n                    \"unit\": \"milliseconds\",\n                    \"value\": 100\n                }\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"training_speed\",\n                \"value\": null,\n                \"unit\": \"epochs per second\"\n            },\n            {\n                \"name\": \"inference_time\",\n                \"value\": {\n                    \"unit\": \"milliseconds\",\n                    \"value\": null\n                },\n                \"optimization_direction\": \"low\"\n            },\n            {\n                \"name\": \"memory_usage\",\n                \"value\": {\n                    \"unit\": \"GB\",\n                    \"value\": null\n                },\n                \"optimization_direction\": \"low\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Enron Email Dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"department\", \"sub_department_expertise\"],\n            \"specification\": {\n                \"node_count\": null,\n                \"edge_count\": 50000000,\n                \"edge_distribution\": null,\n                \"node_type\": \"high-dimensional\"\n            },\n            \"description\": \"A large-scale email dataset transformed into a high-dimensional node classification task with department and sub-department collaboration analysis.\",\n            \"preprocessing\": [\"data cleaning\", \"graph construction\"],\n            \"augmentation\": [],\n            \"visualization\": [\"graph analysis\", \"node feature visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical RGCN\",\n            \"family\": \"graph neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture_details\": \"multi-resolution graph embeddings\",\n                \"model_size\": null,\n                \"training_parameters\": {\n                    \"latency_constraint\": true,\n                    \"computational_resources\": \"limited\"\n                }\n            },\n            \"description\": \"A novel architecture designed to handle high-dimensional node classification on large graphs with strict latency constraints.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider utilizing graph sampling techniques for efficient training and inference on massive graphs.\",\n        \"Explore techniques for compressing and parallelizing computations to optimize hardware utilization.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"node attribute extraction\",\n            \"graph convolutional operations\"\n        ],\n        \"target_device\": \"limited computational hardware\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU or specialized hardware\"],\n        \"demonstration\": \"real-time collaboration analysis\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure captures the user's intent, their expertise, and the specific requirements: a hierarchical RGCN model with multi-resolution embeddings, performance on enormous graphs with latency constraints. Performance metrics cover accuracy, efficiency, and latency, and complexity metrics address hardware constraints. The Enron dataset transformation and the model's novel aspects are incorporated, as are knowledge and service requirements for the project.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "As a seasoned project manager for the cutting-edge medical imaging team, design and develop an advanced DeepLabV3+ architecture tailored to a specialized domain that combines subatomic particle interactions and cryo-electron tomography data. The model must not only exhibit exceptional accuracy in differentiating intricate subatomic structures but also address the complexities of distinctive noise profiles and high-energy microscopy artifacts. To tackle the challenge of limited data, propose a multi-stage transfer learning approach that ensures interpretability, boosts performance in resource-constrained scenarios, and optimizes for real-time analysis within demanding particle accelerator environments, all while considering computational efficiency and model explainability.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"medical imaging, physics\",\n        \"description\": \"The task is to design and develop an advanced DeepLabV3+ architecture specifically for a domain combining subatomic particle interactions and cryo-electron tomography data. The model must have high accuracy in identifying intricate subatomic structures while addressing noise profiles and high-energy microscopy artifacts. It should incorporate a multi-stage transfer learning approach for limited data, ensure interpretability, optimize for real-time analysis in resource-constrained particle accelerator environments, and prioritize computational efficiency and model explainability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"computational efficiency\",\n                \"value\": null,\n                \"unit\": \"FLOPs\"\n            },\n            {\n                \"name\": \"model explainability\",\n                \"value\": null,\n                \"unit\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Subatomic Particle and Cryo-Electron Tomography Fusion\",\n            \"modality\": [\"image\", \"graph\", \"tabular\"],\n            \"target_variables\": [\"intrinsic subatomic structures\", \"noise profiles\", \"high-energy microscopy artifacts\"],\n            \"specification\": null,\n            \"description\": \"A specialized dataset combining subatomic particle interaction data and cryo-electron tomography for model development, addressing complexities in noise and artifacts.\",\n            \"preprocessing\": [\"data augmentation\", \"feature normalization\"],\n            \"augmentation\": [\"GAN-based noise augmentation\", \"artifact injection\"],\n            \"visualization\": [\"data analysis\", \"performance visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"DeepLabV3+\",\n            \"family\": \"Convolutional Neural Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"DeepLabV3+\",\n                \"input_modality\": \"multi-modal\",\n                \"transfer_learning_stages\": \"multi-stage\",\n                \"interpretability_layers\": \"explainable layers\"\n            },\n            \"description\": \"An advanced DeepLabV3+ model designed for subatomic particle interactions and cryo-electron tomography data, incorporating interpretability, transfer learning, and computational efficiency.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Domain expertise in medical imaging, particle physics, noise reduction techniques, and model explainability is crucial for this project.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature fusion\", \"domain adaptation\"],\n        \"target_device\": \"resource-constrained particle accelerator environments\",\n        \"deployment_endpoint\": \"real-time analysis system\",\n        \"inference_engine\": [\"optimized for GPU\", \"interpretability tools\"],\n        \"demonstration\": \"demonstrating accuracy, interpretability, and real-time analysis on sample data\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure reflects the user's instruction, detailing the design and development of a tailored DeepLabV3+ model. The user's expertise level is set to 'high'. Performance metrics cover accuracy and interpretability, addressing the constraints of limited data and analysis environment. The dataset and preprocessing steps cater to the complexities of the task, while the service section deals with deployment and efficiency optimization.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "sequential recommendation", "instruction": "As a part of a specialized multimedia sequence recommendation project, utilizing the 'Hierarchical User-Item Interaction' dataset from Bilibili's live comment streams, I need a real-time, scalable deep learning model. Emphasize on efficient text processing for on-demand, context-aware video recommendations to maximize user engagement in real-world scenarios with high throughput requirements.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"recommendation systems\",\n        \"downstream_task\": \"sequential recommendation\",\n        \"application_domain\": \"multimedia or entertainment\",\n        \"description\": \"The user requests a real-time, scalable deep learning model for a multimedia recommendation project using Bilibili's Hierarchical User-Item Interaction dataset from live comment streams. The focus is on efficient text processing for context-aware video recommendations with high user engagement and throughput requirements.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"throughput\",\n                \"value\": null\n            },\n            {\n                \"name\": \"user engagement\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"requests per second\"\n            },\n            \"memory footprint\",\n            \"computational efficiency\"\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Hierarchical User-Item Interaction (Bilibili live comment streams)\",\n            \"modality\": [\"text\", \"video\"],\n            \"target_variables\": [\"video recommendations\"],\n            \"specification\": {\n                \"text_data_size\": null,\n                \"video_data_size\": null,\n                \"sequence_length\": null,\n                \"video_dimensions\": null,\n                \"text_encoding\": null\n            },\n            \"description\": \"A real-time dataset from Bilibili's live comment streams for sequence recommendation with emphasis on text interactions.\",\n            \"preprocessing\": [\"efficient text processing\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"scalable, real-time (for high throughput)\",\n                \"efficient text processing techniques\": null,\n                \"video processing techniques\": null\n            },\n            \"description\": \"A deep learning model designed for context-aware video recommendations using hierarchical user-item interaction data in real-time. Emphasis on high throughput and efficient text processing for improved user engagement.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"text\": \"Hierarchical User-Item Interaction captures complex user-item interactions for better recommendations.\"\n        },\n        {\n            \"knowledge\": \"Multimodal learning could be useful to integrate text and video data.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"context-aware feature extraction\"],\n        \"target_device\": \"high-performance servers or edge devices\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"real-time processing engines\"],\n        \"demonstration\": \"contextual video recommendation demos for user engagement\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure follows the given schema and represents the user's requirements for a recommendation system project, focusing on a scalable model with efficient text processing. The high expertise level indicates a need for advanced knowledge in designing such a system. However, specific performance metrics, complexity constraints, and model architecture details are not provided in the instruction, requiring some assumptions.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "machine translation", "instruction": "Utilize the extensive OpenSubtitles corpus to develop a state-of-the-art translation model, specializing in conversation-oriented text translation between English and Mandarin. Mandate the employment of a bidirectional Encoder-Decoder Transformer (BERT-Transformer) architecture, and design the model to decode complex colloquial expressions, idioms, and cultural nuances with exceptional accuracy, ensuring near-native fluency. Additionally, incorporate a robust error correction mechanism to handle potential mismatches in informal speech.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"language translation\",\n        \"description\": \"The user wants to develop a state-of-the-art translation model specifically for conversation-oriented text between English and Mandarin. They require a BERT-Transformer architecture and the model should excel in translating complex colloquial expressions, idioms, and cultural nuances, maintaining near-native fluency. An error correction mechanism to handle informal speech mismatches is also a must.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"BLEU score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"TER (Translation Error Rate)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"Fluency Score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"Memory consumption\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"OpenSubtitles Corpus\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"translated_text\"],\n            \"specification\": {\n                \"languages\": [\"English\", \"Mandarin\"],\n                \"domain\": \"conversation-oriented\"\n            },\n            \"description\": \"A multilingual corpus of conversation-based text for developing a translation model between English and Mandarin, focusing on complex expressions and colloquialisms.\",\n            \"preprocessing\": [\n                \"BERT tokenization\",\n                \"Sentence segmentation\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"BERT-Transformer\",\n            \"family\": \"neural networks\",\n            \"type\": \"sequence to sequence\",\n            \"specification\": {\n                \"architecture\": \"bidirectional Encoder-Decoder\",\n                \"model_size\": \"state-of-the-art\",\n                \"attention_type\": \"Transformer\"\n            },\n            \"description\": \"A conversation-oriented translation model using the BERT-Transformer architecture, designed to handle complex expressions, idioms, and cultural nuances.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"type\": \"error_correction_mechanism\",\n            \"description\": \"The model includes a robust error correction mechanism to handle informal speech mismatches.\"\n        },\n        {\n            \"type\": \"contextual_similarity\",\n            \"description\": \"Model emphasizes on maintaining context and near-native fluency.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"BERT embeddings\",\n            \"Custom loss function for informal translation\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU accelerated\"],\n        \"demonstration\": \"Model demonstration with conversation examples\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response represents the user's instruction accurately, indicating a 'build' intent, high expertise, and focusing on a BERT-Transformer model for English to Mandarin translation. Performance metrics and complexity constraints are also specified, as well as requirements for error correction and context-aware translation. The OpenSubtitles corpus is directly relevant and a direct search is assumed. Some feature engineering details are included based on the task requirements.\",\n        \"score\": 0.98\n    }\n}"}
{"task": "text classification", "instruction": "Instruct the ML team to develop a specialized sentiment analysis model, leveraging the Rotten Tomatoes and Metacritic datasets, for fine-grained star ratings classification (1-5 stars) in elite film critiques. Aim for a test accuracy surpassing 97% with an emphasis on precision and recall in the 4 and 5-star categories.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"media analysis\",\n        \"description\": \"The user wants the ML team to develop a specialized sentiment analysis model for fine-grained star ratings classification (1-5 stars) in elite film critiques. The focus is on achieving a test accuracy of at least 97% with a strong emphasis on precision and recall in the 4 and 5-star categories.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.97\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null,\n                \"target_category\": \"4 and 5 stars\"\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null,\n                \"target_category\": \"4 and 5 stars\"\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Rotten Tomatoes dataset\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"film_review\"],\n            \"specification\": null,\n            \"description\": \"Leveraged for sentiment analysis of elite film critiques.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        },\n        {\n            \"name\": \"Metacritic dataset\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"film_review\"],\n            \"specification\": null,\n            \"description\": \"Additional source for fine-grained film critique sentiment analysis.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Fine-Grained Sentiment Analysis Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"target_accuracy\": 0.97,\n                    \"emphasis_layers\": {\n                        \"attention\": {\n                            \"4 and 5 stars\": true\n                        }\n                    }\n                },\n                \"training_details\": {\n                    \"optimizer\": \"precision-oriented\",\n                    \"loss_function\": {\n                        \"accuracy\": {\"target\": 0.97},\n                        \"precision\": {\"target_category\": \"4 and 5 stars\"},\n                        \"recall\": {\"target_category\": \"4 and 5 stars\"}\n                    }\n                }\n            },\n            \"description\": \"A specialized model for fine-grained star ratings classification in film critiques, targeting precision and recall in 4 and 5-star ratings.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"elicitation from the user for specific demonstration requirements\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the key elements from the instruction, including the building of a sentiment analysis model for film critiques, datasets sources, and performance targets (accuracy, precision, and recall for specific categories). The choice of neural networks as the model type is fitting for sentiment analysis, but specific architecture details and target values are speculative without more information.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a marine conservation organization, we've recently ventured into using satellite data to assess the well-being and distribution of rare coral species across our vast oceanic territories. The task at hand is to develop a highly sophisticated image classification model that not only differentiates between multiple coral health stages (e.g., thriving, stressed, bleached, and degraded) but also distinguishes among species with subtle visual differences. The system must also account for seasonal variations and dynamic environmental factors. Our goal is to streamline conservation efforts and allocate resources effectively in real-time. Can you design and implement such a technology?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"marine conservation\",\n        \"description\": \"The user, a marine conservation organization, needs to develop an advanced image classification model that classifies coral health stages (thriving, stressed, bleached, degraded) and different coral species, considering seasonal variations and dynamic environmental factors. The purpose is to enhance real-time conservation planning and resource allocation.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"species_f1_score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"seasonal_effect_accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory_usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Satellite Data of Coral Species\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"coral_health\", \"species\"],\n            \"specification\": {\n                \"image_size\": null,\n                \"color_channels\": null,\n                \"seasonal_variability\": true\n            },\n            \"description\": \"A dataset containing satellite images of coral reefs with health stages and species labels, considering seasonal variations and environmental factors.\",\n            \"preprocessing\": [\"image augmentation\", \"seasonal normalization\"],\n            \"augmentation\": [\n                \"geometric_transformations\",\n                \"weather_pattern_simulation\"\n            ],\n            \"visualization\": [\"feature maps\", \"roc_curves\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"CoralHealthClassifier\",\n            \"family\": \"deep convolutional neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"multi-task (species and health stage classification)\",\n                \"custom_layers\": [\"attention-based\", \"seasonality-informed\"]\n            },\n            \"description\": \"A deep learning model for classifying coral health stages and species based on satellite images, accounting for seasonal variations and dynamic environmental factors.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Seasonal patterns influence coral appearance, necessitating specialized preprocessing and deep learning techniques.\",\n        \"Subtle species differences may require transfer learning or fine-tuning on a domain-specific dataset.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature selection for environmental factors\",\n            \"ensemble modeling to improve robustness\"\n        ],\n        \"target_device\": \"cloud-based for real-time processing\",\n        \"deployment_endpoint\": \"private or cloud server for confidential data\",\n        \"inference_engine\": [\"GPU-based for faster processing\"],\n        \"demonstration\": \"Interactive visual dashboard with real-time classification results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The given instruction describes a complex task, indicating a 'build' intent with a 'high' level of expertise. It's in the area of computer vision (specifically image classification) and the model requirements align with the given details. Performance metrics cover accuracy, species and seasonal variations, while complexity metrics reflect the need for speed and memory efficiency. The dataset and model properties capture the key aspects of the task. Some details are speculative, but the structure is valid.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a machine learning project manager for an elite image classification team, I've been tasked with developing a unique and challenging project that pushes the boundaries of recognition technology. We've recently come across a vast archive of historical underwater shipwrecks captured by deep-sea submersibles, each image containing artifacts and distinctive features that hold historical significance. Our goal is to create a specialized model that not only classifies the images into categories such as ship type, era, and condition, but also detects and localizes specific items like navigational instruments or personal belongings. To achieve this, we need to design and implement an advanced convolutional neural network (CNN) that can handle the low-resolution, variable lighting, and occluded features present in these images. The project manager should outline a detailed plan, including data preprocessing techniques, transfer learning strategies, and evaluation metrics, while considering the challenge of limited labeled data and the need for domain expertise in maritime history.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"maritime history\",\n        \"description\": \"As a machine learning project manager, the goal is to develop a specialized image classification model for underwater shipwreck images. The model should classify ship types, eras, and conditions, and also detect and localize specific items. It requires handling low-resolution, variable lighting, and occluded features using advanced CNNs, accounting for limited labeled data and domain expertise in maritime history.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"localization precision\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"images per second\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Underwater Shipwreck Archive\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"ship_type\", \"era\", \"condition\", \"item_detection\"],\n            \"specification\": {\n                \"image_resolution\": {\n                    \"low\": null,\n                    \"average\": null,\n                    \"high\": null\n                },\n                \"image_dim\": null,\n                \"labeled_data_ratio\": null\n            },\n            \"description\": \"A vast archive of low-resolution, underwater shipwreck images with varying lighting and occlusions.\",\n            \"preprocessing\": [\"data augmentation for low-resolution and occlusions\"],\n            \"augmentation\": [\n                \"random cropping\",\n                \"image blurring\",\n                \"noise injection\"\n            ],\n            \"visualization\": [\"feature maps analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced CNN\",\n            \"family\": \"deep convolutional neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"custom designed to handle low-resolution, variable lighting, and occlusions\",\n                \"transfer_learning\": true,\n                \"base_model\": \"efficientnet or resnet\",\n                \"number_of_layers\": null,\n                \"optimizer\": null,\n                \"initial_learning_rate\": null\n            },\n            \"description\": \"A CNN specifically tailored for underwater shipwreck images, leveraging transfer learning and custom architecture to handle the given challenges.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Maritime history expertise and understanding of relevant artifacts and features\",\n        \"Limited labeled data strategy: semi-supervised or weakly-supervised learning\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"domain-specific feature extraction\"],\n        \"target_device\": \"high-performance computing environment\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"GPU-powered library like TensorFlow or PyTorch\"],\n        \"demonstration\": \"web-based interactive visualization of model performance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure accurately reflects the user's instruction, which highlights a complex computer vision project with a focus on CNN development for maritime history. It accounts for specific challenges, strategies, and performance metrics. Domain expertise is recognized, and the limited labeled data situation is considered. Target device and deployment details are missing, but can be clarified with further interaction.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "text classification", "instruction": "As a project manager for the elite AI research team, you're tasked with enhancing the state-of-the-art text classification system. The Airline Review dataset, enriched with British Airways customers' detailed and nuanced feedback, demands multi-dimensional sentiment analysis beyond generic ratings. Your team must develop a highly specialized model that not only predicts accurate 1-10 rating assignments but also decodes complex emotions and specific praise/drawbacks. The challenge? Minimize RMSE and deliver a robust, explainable model, ensuring competitive benchmarking against previous iterations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"customer sentiment analysis\",\n        \"description\": \"Your task is to enhance the state-of-the-art text classification system, specifically focusing on multi-dimensional sentiment analysis of the Airline Review dataset for British Airways. The model should predict ratings on a scale of 1-10, decode complex emotions, and identify specific praise and drawbacks. The objective is to minimize root mean squared error (RMSE), and create a robust, explainable model that outperforms previous versions in benchmarking.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"RMSE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"explainability\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Airline Review (British Airways)\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"ratings\", \"emotions\", \"praise_drawbacks\"],\n            \"specification\": {\n                \"rating_scale\": 10,\n                \"feature_dimensions\": \"nuanced feedback\"\n            },\n            \"description\": \"An enriched dataset with detailed customer feedback for British Airways, requiring a model to perform multi-dimensional sentiment analysis.\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"feature engineering\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"performance visualization\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks\",\n            \"type\": \"state-of-the-art (customized)\",\n            \"specification\": {\n                \"architecture\": \"explainable\",\n                \"number_of_layers\": \"\",\n                \"training_details\": \"robust\"\n            },\n            \"description\": \"A highly specialized model designed for text classification, targeting multi-dimensional sentiment analysis, accurate rating prediction, emotion decoding, and specific praise/drawback identification.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"custom embeddings\", \"contextualization\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"efficient serving algorithms\"],\n        \"demonstration\": \"interactive model explanation\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON reflects the task description accurately, indicating a build intent with high expertise. The problem area, downstream task, and dataset details are derived from the instruction. Performance metrics include RMSE minimization, and explainability is emphasized. Preprocessing and model specifics are expanded upon to cater to the advanced text classification requirements. Some assumptions are made regarding the model architecture based on the context, and future steps are included in the service section.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "multimodal forgery detection", "instruction": "Develop a cutting-edge multimodal forgery detection system using the 'Adversarial RealisticForgery Dataset' that merges subtle visual cues from manipulated images, forged text, and synthesized audio. Design an ensemble model, combining Transformers, Graph Convolutional Networks (GCN), and Xception-based visual analysis, with a Time-aware Recurrent Neural Network (TA-RNN) for voice authentication. The challenge lies in differentiating between genuine interactions and sophisticated AI-generated fakes while ensuring near real-time performance and maintaining a high true positive rate for detecting socio-political deepfakes.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"multimodal forgery detection\",\n        \"application_domain\": \"security\",\n        \"description\": \"The task is to develop a cutting-edge multimodal forgery detection system, using the Adversarial RealisticForgery Dataset. The system should combine Transformers, Graph Convolutional Networks (GCN), Xception for visual analysis, and a Time-aware Recurrent Neural Network (TA-RNN) for voice authentication. The focus is on detecting subtle manipulations in images, forged text, and synthesized audio, while achieving near real-time performance and maintaining a high true positive rate for socio-political deepfakes.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"true positive rate\",\n                \"value\": null\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"real-time\"\n            },\n            {\n                \"name\": \"memory consumption\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Adversarial RealisticForgery Dataset\",\n            \"modality\": [\n                \"image\",\n                \"text\",\n                \"audio\"\n            ],\n            \"target_variables\": [\"forged\"],\n            \"specification\": {\n                \"visual_analysis_input\": {\n                    \"Xception-based\": {}\n                },\n                \"audio_analysis_input\": {\n                    \"TA-RNN\": {}\n                }\n            },\n            \"description\": \"Dataset for detecting multimodal forgeries combining subtle visual cues from manipulated images, forged text, and synthesized audio.\",\n            \"preprocessing\": [\n                \"data normalization\",\n                \"feature extraction for Transformers, GCN, and Xception\"\n            ],\n            \"augmentation\": [\n                \"data augmentation for visuals, text, and audio\"\n            ],\n            \"visualization\": [\n                \"visual and audio feature maps\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Ensemble Model\",\n            \"family\": \"Combination of Transformers, GCN, Xception, and TA-RNN\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"Transformers\": {},\n                    \"GCN\": {},\n                    \"Xception\": {},\n                    \"TA-RNN\": {}\n                }\n            },\n            \"description\": \"A high-performance multimodal forgery detection model that combines Transformers, Graph Convolutional Networks, Xception for visual analysis, and Time-aware Recurrent Neural Network for voice authentication.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"dimensionality reduction\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"AI inference API\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"Docker\"],\n        \"demonstration\": \"example forgery detection demo videos\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure adheres to the schema and is based on the user's instruction. The intent 'build' reflects the task of designing a model. Expertise is assumed high due to the complexity and requirements for advanced techniques. Performance metrics include accuracy, true positive rate, and inference time, reflecting the challenge of real-time performance and socio-political deepfake detection. The ensemble model architecture and data handling techniques are appropriate for the task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "For a highly specific image classification project, I need you to design a model that can distinguish not only between different cat species but also distinguish between extinct and endangered breeds, while considering variations in color, age, and camera angles for a diverse dataset of cat images.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"wildlife conservation\",\n        \"description\": \"Design a model for highly specific image classification that can distinguish between different cat species, including extinct and endangered breeds, taking into account variations in color, age, and camera angles for a diverse dataset of cat images.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"species classification accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"endangered/conserved species detection accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"species\", \"endangered\"],\n            \"specification\": {\n                \"image_size\": null,\n                \"color_depth\": null,\n                \"age_variations\": true,\n                \"camera_angle_variations\": true,\n                \"diversity_score\": null\n            },\n            \"description\": \"A diverse dataset of cat images, including extinct and endangered breeds, with consideration for color, age, and camera angle variations.\",\n            \"preprocessing\": [\"image normalization\", \"augmentation\"],\n            \"augmentation\": [\"color jitter\", \"geometric transformations\"],\n            \"visualization\": [\"dataset distribution\", \"feature maps\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Convolutional Neural Networks (CNN)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"deep or multi-stage\",\n                \"number_of_layers\": null,\n                \"feature_extraction_layers\": [\"ResNet\", \"Inception\", \"EfficientNet\"],\n                \"custom_layers\": null\n            },\n            \"description\": \"A highly specialized CNN designed for distinguishing between cat species, including extinct and endangered ones, while handling image variations.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"domain-specific feature extraction\",\n            \"age and camera angle encoding\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"interactive online prediction\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is created based on the user's instruction, with a high-level intent to build a model. The expertise level is assumed to be high, given the complexity of the project. The area and downstream task are set to computer vision and image classification, respectively. The performance metrics reflect accuracy, species classification, and endangered species detection. Complexity metrics account for inference time and memory consumption. The dataset covers image variations and is expected to be uploaded by the user. The model specification is an advanced CNN for the specific task at hand. Some steps in feature engineering and demonstration are included in the service section.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a project manager, you task the machine learning team with enhancing an existing galaxy and star classification system. Retrieve the specific NASA dataset with at least 50,000 labeled images, ensuring balanced classes. Implement a state-of-the-art deep learning model resistant to noise, and benchmark accuracy against current best practices in the field to showcase novelty.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"astronomy\",\n        \"description\": \"The project aims to enhance an existing galaxy and star classification system by utilizing a specific NASA dataset with at least 50,000 labeled images, ensuring balanced classes. A state-of-the-art deep learning model should be implemented that is resilient to noise, and benchmark its accuracy against current industry standards to demonstrate novelty.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"noise robustness\",\n                \"value\": null,\n                \"unit\": \"percentage\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"NASA Galaxy & Star Classification dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"galaxy\", \"star\"],\n            \"specification\": {\n                \"minimum_samples\": 50000,\n                \"class_balance\": true\n            },\n            \"description\": \"A large labeled dataset for galaxy and star classification, sourced from NASA, with at least 50,000 images.\",\n            \"preprocessing\": [\"noise reduction\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"state-of-the-art deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"noise_resistance\": \"true\"\n            },\n            \"description\": \"A deep learning model specifically designed for galaxy and star classification, robust to noise and optimized for state-of-the-art performance.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Performance comparison with current best practices\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response includes the user's intent to build a model ('build' intent) and high expertise level. The problem statement covers the details on computer vision, dataset requirements (NASA with at least 50k labeled images, balanced classes), the need for noise resistance, and benchmarking against best practices. Performance metric is accuracy, and it is left open for optimization. The model type is specified as neural networks, with state-of-the-art deep learning model for the task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "question answering", "instruction": "The project now requires a sophisticated e-commerce customer service AI, leveraging the extensive and diverse AmazonQA dataset. Utilize a state-of-the-art, efficient DistilBERT model that not only prioritizes accurate responses but also decodes complex user queries, identifies nuanced sentiment, and guarantees a sub-second response time, ensuring peak customer satisfaction and engagement in a high-traffic environment.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"e-commerce\",\n        \"description\": \"The project aims to develop a sophisticated AI for e-commerce customer service using the AmazonQA dataset. The AI should be built around a state-of-the-art DistilBERT model, ensuring accuracy, efficient handling of complex queries, sentiment analysis, and sub-second response times.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"response_time\",\n                \"value\": {\n                  \"unit\": \"seconds\",\n                  \"value\": \"sub-second\"\n                }\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_speed\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"AmazonQA\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"customer_query\", \"response\"],\n            \"specification\": {\n                \"diversity\": \"extensive and diverse\",\n                \"format\": \"e-commerce customer service related questions and answers\"\n            },\n            \"description\": \"A large and diverse dataset for training an e-commerce customer service AI, containing complex queries and real-world scenarios.\",\n            \"preprocessing\": [\n                \"sentiment analysis preparation\",\n                \"query decomposition\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"DistilBERT\",\n            \"family\": \"transformers (neural networks)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"efficiency\": \"state-of-the-art\",\n                \"query_complexity\": \"efficient\",\n                \"sentiment_handling\": \"yes\"\n            },\n            \"description\": \"A DistilBERT model optimized for high accuracy, fast response time, and efficient handling of complex user queries in a high-traffic e-commerce customer service setting.\"\n        }\n    ],\n    \"knowledge\": [\n        \"AmazonQA dataset supports state-of-the-art performance in natural language understanding\",\n        \"DistilBERT's efficiency in handling large and nuanced data\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"contextual embeddings\",\n            \"query understanding\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"high-traffic e-commerce platform\",\n        \"inference_engine\": [\"GPU-accelerated\"],\n        \"demonstration\": \"real-time customer service chat simulation\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON reflects the given instruction, with the user's intent as 'build', and high expertise level assumed. The problem area is NLP, specifically QA, in the e-commerce domain. The DistilBERT model and the AmazonQA dataset are accurately represented. Performance metrics include accuracy and a sub-second response time, reflecting the stated requirements. The model specifications and dataset properties are based on the details provided in the instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "You are now tasked with developing a highly optimized time-series forecasting model for the ETTm2 dataset, which consists of diverse, real-world time series. With train, validation, and test splits provided, ensure compatibility with a unique input pattern (96 past observations of 7 dimensions, INPUT_SEQ_LEN=96, INPUT_DIM=7). The challenge lies in forecasting the subsequent 96 steps (PRED_SEQ_LEN=96, PRED_DIM=7) with state-of-the-art accuracy. Implement a model that not only minimizes mean squared error (MSE) and mean absolute error (MAE) but also demonstrates superior scalability and responsiveness to time-varying trends, necessitating real-time adaptation to dynamically changing patterns.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy/time-series\",\n        \"description\": \"The task is to develop a high-performance time-series forecasting model for the ETTm2 dataset. The input pattern requires 96 past observations (96 steps, 7 dimensions) and the goal is to forecast the next 96 steps (96 steps, 7 dimensions) with state-of-the-art accuracy, optimizing for MSE and MAE. The model should demonstrate superior scalability and real-time adaptation to time-varying trends.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MSE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MAE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"scalability\",\n                \"value\": null,\n                \"unit\": \"\"\n            },\n            {\n                \"name\": \"response time\",\n                \"value\": null,\n                \"unit\": \"real-time\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ETTm2\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 7,\n                \"PRED_SEQ_LEN\": 96,\n                \"PRED_DIM\": 7\n            },\n            \"description\": \"A diverse real-world time series dataset with train, validation, and test splits, with a unique input pattern of 96 past observations of 7 dimensions.\",\n            \"preprocessing\": [\"normalization\"],\n            \"augmentation\": [\"none\"],\n            \"visualization\": [\"None\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning (e.g., RNN, LSTM, Transformer)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"type\": \"RNN/LSTM/Transformer\",\n                    \"hyperparameters\": {\n                        \"window_size\": 96,\n                        \"hidden_layers\": \"optimized\",\n                        \"dropout_rate\": \"optimized\"\n                    }\n                },\n                \"optimization\": {\n                    \"loss_function\": \"combined (MSE + MAE)\",\n                    \"optimizer\": \"Adam\"\n                }\n            },\n            \"description\": \"A highly optimized deep learning model for time-series forecasting with emphasis on minimizing MSE and MAE, real-time adaptation, and scalability.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider using techniques like autoregressive models and attention mechanisms for capturing time-varying trends.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature scaling\", \"feature engineering for time-varying patterns\"],\n        \"target_device\": \"cloud-based for real-time inference\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorFlow serving\", \"ONNX\"],\n        \"demonstration\": \"Provide visualizations of forecast accuracy and model performance over time\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately represents the information from the instruction. The user's intent is to build a high-performance model, with expertise in time-series analysis. The problem description, dataset specifications, and metrics for MSE/MAE are clearly stated. The model type (neural network) and architecture are chosen according to the task's requirements. Note that some values like performance metrics and exact model hyperparameters are left unspecified for optimization.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "image classification", "instruction": "Create a custom image classifier for the Kaggle fundus photography dataset using the domain-specific VGG19-BN variant tailored for diabetic retinopathy grading. Target a high precision of 95% in a six-stage severity classification, focusing on reducing false negatives to minimize diagnostic errors. Prioritize real-time performance and optimized GPU utilization for efficient deployment in ophthalmology clinics. Additionally, provide a detailed report on model interpretability and explainability.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"ophthalmology\",\n        \"description\": \"The task is to develop a custom image classifier, specifically using the VGG19-BN variant, tailored for diabetic retinopathy grading. The focus is on achieving a high precision of 95% in a six-stage severity classification, with a focus on reducing false negatives to minimize diagnostic errors. Real-time performance and efficient GPU utilization are priorities for deployment in clinics.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"GPU utilization\",\n                \"value\": 90,\n                \"unit\": \"%\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Kaggle Fundus Photography Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"diabetic_retinopathy_severity\"],\n            \"specification\": {\n                \"image_size\": \"domain-specific\",\n                \"architecture\": \"VGG19-BN\"\n            },\n            \"description\": \"A dataset for diabetic retinopathy grading using fundus photographs, targeting a six-stage severity classification.\",\n            \"preprocessing\": [\"domain-specific data augmentation\"],\n            \"augmentation\": [\n                \"focal cropping\",\n                \"Gaussian blur\",\n                \"lighting variations\"\n            ],\n            \"visualization\": [\n                \"class activation maps\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Custom Image Classifier (VGG19-BN for Diabetic Retinopathy)\",\n            \"family\": \"neural networks\",\n            \"type\": \"CNN\",\n            \"specification\": {\n                \"model_family\": \"VGG19-BN\",\n                \"target_precision\": 0.95,\n                \"interpretability_techniques\": [\"GradCAM\", \"LIME\", \"SHAP\"]\n            },\n            \"description\": \"A custom image classifier tailored for diabetic retinopathy grading using VGG19-BN, with a focus on interpretability and real-time performance.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Optimized for ophthalmology clinics and user-friendly interpretability methods for healthcare practitioners.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"transfer learning\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"Explanation API for clinicians\",\n        \"inference_engine\": [\"GPU-optimized\", \"real-time\"],\n        \"demonstration\": \"Interactive visualizations for interpretability\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response covers the various aspects of the task, including the customized image classifier, the VGG19-BN variant, performance metrics, and interpretability. The expert level of the user is assumed high due to the complexity and specialized nature of the task. The performance metric 'precision' is set to 95% as specified, and GPU utilization and real-time performance are prioritized for deployment.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "text classification", "instruction": "You are now tasked with enhancing the existing machine learning project for text classification using the DAIGT dataset. The objective is to distinguish between human-written content (label 0) and AI-generated content (label 1) with state-of-the-art accuracy. Implement a multi-label classification model, utilizing ensemble techniques and optimizing for F1-score, while maintaining a runtime constraint of 1 minute per epoch.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"machine learning\",\n        \"description\": \"The task is to enhance an existing text classification project for distinguishing between human-written (label 0) and AI-generated (label 1) content using the DAIGT dataset. A multi-label classification model is required, incorporating ensemble techniques, optimizing for F1-score, and adhering to a runtime constraint of 1 minute per epoch.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1-score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"unit\": \"minutes\",\n                \"value\": 1\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"DAIGT dataset\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"generated_by_AI\", \"human_written\"],\n            \"specification\": null,\n            \"description\": \"A dataset for multi-label text classification, distinguishing human and AI-generated content.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Multi-label Ensemble Model\",\n            \"family\": \"ensemble models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"ensemble_techniques\": [\n                    \"stacking\",\n                    \"blending\"\n                ],\n                \"optimization\": \"F1-score\"\n            },\n            \"description\": \"A state-of-the-art ensemble model for multi-label text classification on the DAIGT dataset, optimized for F1-score while maintaining a runtime of 1 minute per epoch.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is accurately derived from the given instruction, detailing a 'build' intent with a 'high' expertise level. The area is 'natural language processing', and the task focuses on 'text classification' for distinguishing between human and AI-generated content. The DAIGT dataset, multi-label classification, ensemble techniques, F1-score optimization, and runtime constraint are clearly stated. A model name and description are provided, reflecting the task requirements. Performance is targeted on F1-score and a runtime constraint of 1 minute per epoch is included.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "You are now tasked with developing a sophisticated time-series forecasting system using the Weather dataset, which exhibits complex real-world patterns. The data is divided into train, validation, and test sets with non-overlapping time horizons. Your requirement is to design a multi-step predictive model (INPUT_SEQ_LEN=96, INPUT_DIM=21) that forecasts not only the immediate future (PRED_SEQ_LEN=96) but also intermediate sequences of 24 and 48 time steps ahead, simultaneously. Ensure excellent performance by minimizing mean squared loss (MSE) and mean absolute error (MAE) across all prediction lengths while maintaining a high level of explainability for the model's decision-making process.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"weather prediction\",\n        \"description\": \"The task is to develop a sophisticated time-series forecasting system using the Weather dataset with complex real-world patterns. The data is divided into non-overlapping train, validation, and test sets. The model should be a multi-step predictive model with INPUT_SEQ_LEN of 96 and INPUT_DIM of 21, capable of forecasting immediate (96 steps), intermediate sequences of 24 and 48 time steps ahead. The focus is on optimizing for mean squared loss (MSE) and mean absolute error (MAE), while maintaining a high level of model explainability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean squared error (MSE)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute error (MAE)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Weather dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 21\n            },\n            \"description\": \"A complex real-world weather dataset split into train, validation, and test sets with non-overlapping time horizons.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks\",\n            \"type\": \"multi-step forecasting\",\n            \"specification\": {\n                \"forecast_steps\": [96, 24, 48],\n                \"input_sequence_length\": 96,\n                \"input_feature_depth\": 21\n            },\n            \"description\": \"A multi-step predictive model for simultaneous forecasting of immediate and intermediate future time steps using the Weather dataset, designed to minimize MSE and MAE.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"require explainable AI\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction has been parsed into a valid JSON format according to the given schema. The user's intent is to build a sophisticated model with a high expertise level. The task is clearly defined in the 'problem' section, with the dataset, performance metrics, and the model's requirement for multi-step forecasting and explainability. No additional or unclear information was found in the instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "question answering", "instruction": "For our upcoming project, we aim to develop a highly specialized question-answering system using RoBERTa as the foundation, targeting the advanced SQuAD 2.0 dataset. The model must surpass a rigorous benchmark of 95% precision and recall (F1 score), while maintaining real-time responsiveness with all predictions being generated within a tight 1.8-second latency window, even when handling complex and lengthy queries. Can you devise a scalable architecture and optimize the model to accommodate diverse linguistic nuances and historical context?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"information retrieval\",\n        \"description\": \"The project aims to develop a specialized question-answering system using RoBERTa as the foundation, with a focus on the advanced SQuAD 2.0 dataset. The system must achieve at least 95% precision and recall (F1 score), and provide real-time predictions within a 1.8-second latency for complex and lengthy queries, ensuring scalability and handling diverse linguistic nuances and historical context.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"F1 score\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency\",\n                \"value\": 1.8,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"SQuAD 2.0\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"question\", \"answer\"],\n            \"specification\": {\n                \"complexity_level\": \"advanced\",\n                \"length_range\": [\"complex\", \"lengthy\"]\n            },\n            \"description\": \"Advanced SQuAD 2.0 dataset for question-answering, containing complex and lengthy queries.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"RoBERTa\",\n            \"family\": \"neural networks\",\n            \"type\": \"transformer\",\n            \"specification\": {\n                \"architectural_details\": \"Scalable and optimized for diverse linguistic nuances and historical context\"\n            },\n            \"description\": \"A question-answering model built on RoBERTa, targeting advanced SQuAD 2.0 dataset and achieving high precision and recall (F1 score) above 95%.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"real-time\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for latency\"],\n        \"demonstration\": \"Supports real-time and complex query handling\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the main aspects of the project based on the instruction, with a focus on building a high-performing QA system using RoBERTa on SQuAD 2.0. Performance metrics align with the benchmark, and the requirements for latency and linguistic complexity are included. The expert level is assumed to be 'high' due to the need for a specialized and optimized model. Some details, such as the exact model architecture and deployment specifics, are left open for further discussion.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Utilize the Mouse Brain Connectivity dataset to design a GWNN for node classification, demanding not only high precision and recall in discerning distinct neuron types but also implementing an attention mechanism to capture long-range dependencies and ensuring the model's interpretability for neuroscientific analysis.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"neuroscience\",\n        \"description\": \"The task is to design a Graph Wavelet Neural Network (GWNN) for node classification in the Mouse Brain Connectivity dataset. The model should achieve high precision and recall in identifying different neuron types, incorporate an attention mechanism for capturing long-range dependencies, and ensure interpretability for neuroscientific research.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"model_interpretability\",\n                \"value\": null,\n                \"unit\": \"score (on a scale)\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Mouse Brain Connectivity\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"neuron_type\"],\n            \"specification\": {\n                \"nodes\": {\n                    \"node_features\": \"unknown\"\n                },\n                \"edges\": \"unknown\"\n            },\n            \"description\": \"A graph dataset for mouse brain connectivity, with the task of node classification for distinguishing different neuron types.\",\n            \"preprocessing\": [\"graph construction\", \"node feature extraction\"],\n            \"augmentation\": [],\n            \"visualization\": [\"graph structure\", \"neuron type distribution\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"GWNN with Attention Mechanism\",\n            \"family\": \"graph neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"GWNN\",\n                \"attention_mechanism\": \"yes\",\n                \"interpretability Techniques\": \"explainable by design\"\n            },\n            \"description\": \"A Graph Wavelet Neural Network with an incorporated attention mechanism, designed for high precision and recall in node classification of neuron types in the Mouse Brain Connectivity dataset.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"graph normalization\", \"node feature engineering\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized\"],\n        \"demonstration\": \"neuroscientifically interpretable results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is derived from the instruction, matching the JSON schema. The 'intent' is 'build' for designing a model. The 'expertise' is set to 'high' as the task requires advanced knowledge of graph machine learning. The area, task, dataset, and performance metrics are all derived directly from the given information. Model specifics include GWNN, attention mechanism, and interpretability for neuroscience. Complexities are also included like inference time and interpretability score. Some assumptions about preprocessing and feature extraction are made based on the context.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "As a project manager for a high-velocity grocery retail environment, mandate a state-of-the-art YOLO-based object detection model development on the \"Enhanced StoreShelf-500 Dataset\". The model must distinguish between 500 diverse product categories, ensuring a precision and recall of 95% or above, and integrate with a real-time, high-throughput system for shelf scanning. Moreover, the updated inventory counts must be accurate within 1 second per shelf image while adhering to strict latency requirements for peak operational efficiency.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"retail\",\n        \"description\": \"The project requires developing a state-of-the-art YOLO-based object detection model for a high-velocity grocery retail environment. The model should accurately distinguish between 500 product categories, achieving precision and recall of 95% or above. The model must be integrated into a real-time, high-throughput system for shelf scanning, with inventory counts being accurate within 1 second per shelf image and satisfying strict latency requirements.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time per image\",\n                \"value\": 1.0,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Enhanced StoreShelf-500\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"product categories\"],\n            \"specification\": {\n                \"number_of_categories\": 500\n            },\n            \"description\": \"A dataset for object detection in grocery retail, containing 500 unique product categories for the model to identify.\",\n            \"preprocessing\": [\"enhanced for YOLO\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"state-of-the-art YOLO\",\n            \"family\": \"YOLO\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_accuracy\": \"95% or above\"\n            },\n            \"description\": \"A YOLO object detection model tailored for grocery retail, capable of handling high-throughput and achieving accuracy constraints.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"enhanced for real-time integration\"],\n        \"target_device\": \"real-time, high-throughput system\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for low latency\"],\n        \"demonstration\": \"accuracy in shelf scanning and real-time inventory updates\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response covers the necessary details from the instruction, specifying the YOLO-based object detection model, the product categorization, and the performance requirements. It includes the Enhanced StoreShelf-500 dataset, the model's precision and recall target, as well as the requirement for low latency and high throughput. The confidence score is high due to the direct translation of the instruction into the schema.\",\n        \"score\": 0.98\n    }\n}"}
{"task": "object detection", "instruction": "The machine learning team is now tasked with advancing the smart city project by enhancing an advanced parking management system. You must fine-tune the M2Det model on the extensive 'PKLot' dataset, incorporating additional features for temporal and seasonal context, while ensuring robustness to diverse lighting (low/nighttime) and adverse weather conditions. The system must not only exhibit a superior detection accuracy of at least 95% but also demonstrate exceptional efficiency with response times strictly below 150 milliseconds, and include a detailed analysis report showcasing the model's adaptability and performance benchmarking.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"smart city\",\n        \"description\": \"The task is to enhance an advanced parking management system by fine-tuning the M2Det model on the PKLot dataset. The model should incorporate temporal and seasonal context, exhibit at least 95% detection accuracy, and have response times below 150 milliseconds. The system must be robust to diverse lighting conditions and adverse weather.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"detection accuracy\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"response time\",\n                \"value\": 150,\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"PKLot dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"additional_features\": [\"temporal context\", \"seasonal context\"],\n                \"robustness\": [\"low/nighttime lighting\", \"adverse weather\"]\n            },\n            \"description\": \"A comprehensive dataset for fine-tuning M2Det for advanced parking management, considering temporal and seasonal context, diverse lighting, and weather conditions.\",\n            \"preprocessing\": [],\n            \"augmentation\": [\"data augmentation for diverse lighting and weather\"],\n            \"visualization\": [\"model performance with different scenarios\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"M2Det\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"accuracy_goal\": \"at least 95%\",\n                \"efficiency_goal\": \"response time < 150ms\"\n            },\n            \"description\": \"Fine-tuned M2Det model for advanced parking management in smart cities, considering temporal and seasonal context, and robustness to various conditions.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Model adaptability and performance benchmarking will be provided in the detailed analysis report.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"temporal and seasonal feature engineering\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for real-time performance\"],\n        \"demonstration\": \"demonstration of model's performance under different scenarios\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction has been parsed into a JSON response that covers the various aspects requested. The user's intent is to 'build', expertise is 'high', and the focus is on advanced parking management using M2Det, PKLot dataset, and specified performance and efficiency metrics. The response includes the required datasets, models, and services, as well as a specified confidence level.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "Develop a state-of-the-art Hybrid Time-Channel-WaveNet architecture for the comprehensive urban sounds dataset, which encompasses not just ambient noise but also transient events. The project aims to predict the hourly sound levels for the upcoming 72-hour period, necessitating exceptional noise type classification and interpretability for urban planners to strategize targeted noise mitigation measures.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"urban planning\",\n        \"description\": \"The user wants to develop a state-of-the-art Hybrid Time-Channel-WaveNet architecture for the comprehensive urban sounds dataset, which includes both ambient noise and transient events. The goal is to predict the hourly sound levels for the next 72 hours with high interpretability for urban planners to plan noise mitigation measures.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute error\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"hours\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Comprehensive Urban Sounds Dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"hourly_sound_levels\"],\n            \"specification\": {\n                \"sound_types\": [\"ambient noise\", \"transient events\"],\n                \"forecast_length\": 72,\n                \"time_window\": \"hourly\"\n            },\n            \"description\": \"A dataset for urban sound classification and hourly prediction, including ambient noise and transient events.\",\n            \"preprocessing\": [\"data cleaning\", \"feature extraction\"],\n            \"augmentation\": [\"time stretching\", \"temporal shifting\"],\n            \"visualization\": [\"sound event segmentation\", \"time-frequency analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hybrid Time-Channel-WaveNet\",\n            \"family\": \"neural networks\",\n            \"type\": \"ensemble models\",\n            \"specification\": {\n                \"architecture_details\": \"State-of-the-art with interpretable layers\"\n            },\n            \"description\": \"An advanced ensemble model that combines Time-Channel-WaveNet for accurate noise prediction and interpretability for urban planning.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Advanced time-series forecasting techniques\",\n        \"Interpretability techniques for model understanding\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"sound feature extraction\", \"noise type detection\"],\n        \"target_device\": \"cloud-based\",\n        \"deployment_endpoint\": \"planning platform\",\n        \"inference_engine\": [\"GPU-powered\", \"TensorFlow-serving\"],\n        \"demonstration\": \"Interactive dashboard showcasing predicted sound levels and mitigation measures\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the user's intent for building a state-of-the-art model, specifies their high expertise level, and accurately captures the task (time-series forecasting), dataset, performance and complexity requirements, and service requirements. The model type, ensemble models, is reasonable given the need for noise type classification and interpretability.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "multimodal emotion recognition", "instruction": "Prompt for Multimodal Emotion Recognition Task:\r\n\r\nAs a retail company launching a new product, we've developed a presentation prototype to showcase our innovation. However, we desire to optimize the multimedia presentation, including videos, 3D product demos, and live chat Q&A, to resonate with varying customer segments. Our objective is to design a deep learning-based system that can not only analyze the content's emotional impact but also gauge the real-time emotional responses from multiple channels (facial expressions, tone of voice, and text-based feedback) during virtual product launches. The system should provide actionable insights for tailoring the presentation and sales strategy, considering cultural nuances and personal preferences, ensuring a seamless and impactful user experience. Can you develop this advanced emotion recognition technology, while adhering to GDPR regulations and ensuring minimal latency for real-time feedback?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"multimodal emotion recognition\",\n        \"application_domain\": \"retail and marketing\",\n        \"description\": \"The task is to develop a deep learning-based system for real-time emotion recognition during virtual product launches. It should analyze multimedia content's emotional impact, gauge responses from facial expressions, tone of voice, and text-based feedback, and provide actionable insights for personalization, considering cultural nuances and GDPR regulations. Latency for real-time feedback must be minimal.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": null\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_speed\",\n                \"value\": null,\n                \"unit\": \"FPS\"\n            },\n            {\n                \"name\": \"memory_footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\", \"audio\", \"video\", \"text\"],\n            \"target_variables\": [\"emotions\", \"cultural_nuances\", \"personal_preferences\"],\n            \"specification\": null,\n            \"description\": \"A dataset containing multimedia content for virtual product presentations, including variations for emotional analysis and cultural nuances.\",\n            \"preprocessing\": [\"emotion detection\", \"cultural feature extraction\"],\n            \"augmentation\": [\"multimodal data augmentation\"],\n            \"visualization\": [\"cross-channel emotional patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"multi-modal fusion (CNN, RNN, LSTM, Transformers)\",\n                \"detection_layers\": [\"facial expressions\", \"speech-to-text\"],\n                \"privacy-preserving\": [\"GDPR compliant\", \"anonymization techniques\"]\n            },\n            \"description\": \"A state-of-the-art model for real-time multimodal emotion recognition, considering GDPR guidelines and minimal latency.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Cultural and personal sensitivity in emotion recognition is crucial.\",\n        \"Adaptation to GDPR regulations for data handling and privacy.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"custom embeddings\", \"sequence alignment\"],\n        \"target_device\": \"cloud-based for low latency\",\n        \"deployment_endpoint\": \"a secure cloud platform\",\n        \"inference_engine\": [\"real-time processing engines\"],\n        \"demonstration\": \"A demo showcasing personalized content based on detected emotions and real-time feedback.\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed information accurately captures the user's request to build a high-end emotion recognition system. The expert level, focus on GDPR compliance, and real-time feedback latency are incorporated. Specific performance metrics and complexity constraints are provided to ensure project feasibility and success. However, the exact model name and dataset name are left unspecified, as they might require more specific details from the user.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "tabular regression", "instruction": "As we continue to expand our AI-driven product offerings, the machine learning team has been tasked with optimizing not only development costs but also the time-to-market for each innovative feature. Can you design a cutting-edge tabular regression model that integrates not just historical project data (size, complexity, team size, and resource allocation) but also factors in real-time market trends, competitor activity, and user feedback, to forecast not just the budget but also the earliest and latest possible completion dates for upcoming projects? This model should account for potential delays and acceleration, ensuring strategic decision-making for prioritization and resource allocation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"tabular data analysis\",\n        \"downstream_task\": \"tabular regression\",\n        \"application_domain\": \"product development\",\n        \"description\": \"The task is to develop a cutting-edge tabular regression model that predicts budget, earliest, and latest completion dates for upcoming AI-driven projects. The model will incorporate historical project data (size, complexity, team size, resource allocation), real-time market trends, competitor activity, and user feedback while accounting for potential delays and acceleration.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean absolute error\",\n                \"value\": null\n            },\n            {\n                \"name\": \"R² score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"budget\", \"earliest_completion_date\", \"latest_completion_date\"],\n            \"specification\": null,\n            \"description\": \"Historical project data with real-time market, competitor, and user feedback features incorporated for regression analysis.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"advanced deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"parameters\": {\n                    \"model_architecture\": \"interpretable and flexible for diverse inputs\",\n                    \"num_layers\": null,\n                    \"hidden_units\": null\n                },\n                \"complexity\": {\n                    \"FLOPs\": null,\n                    \"train_speed\": null\n                }\n            },\n            \"description\": \"A cutting-edge tabular regression model for budget and timeline prediction, leveraging neural networks to integrate various input factors.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Incorporate feature engineering to handle real-time data and potentially use ensemble methods for improved accuracy.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"real-time data preprocessing\", \"ensemble feature inclusion\"],\n        \"target_device\": \"cloud-based\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized\"],\n        \"demonstration\": \"Interactive dashboard for real-time project planning\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response covers the build intent with high expertise, reflects the tabular data and regression task, and provides a detailed description and requirements for the model, performance, and complexity metrics. Potential improvements are addressed in the knowledge, feature engineering, and service sections. However, specific model parameters and performance targets are not provided, leaving room for optimization.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "question answering", "instruction": "The project manager must direct the machine learning team to design an efficient, mobile-oriented QA model based on TinyBERT, targeting the NewsQA dataset. Emphasize achieving not only a minimum accuracy of 90%, but also optimizing for sub-400 millisecond latency and energy efficiency, necessitating iterative testing and tuning of model parameters for optimal performance on resource-constrained devices.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"news and media\",\n        \"description\": \"The project requires designing a mobile-oriented QA model using TinyBERT, specifically for the NewsQA dataset. The primary focus is on achieving a minimum accuracy of 90%, with an additional emphasis on optimizing for sub-400 millisecond latency and energy efficiency.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.9\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency\",\n                \"value\": 400,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"energy efficiency\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"NewsQA\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"questions\", \"answers\"],\n            \"specification\": {\n                \"dataset_size\": \"large\",\n                \"text_length\": \"*\"\n            },\n            \"description\": \"A dataset for question answering on news articles.\",\n            \"preprocessing\": [\n                \"tokenizer (TinyBERT)\",\n                \"sequence padding\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"TinyBERT-based QA Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"transformer\",\n            \"specification\": {\n                \"parameters\": {\n                    \"model_size\": \"tiny\",\n                    \"pretrained_weights\": \"NewsBERT\"\n                },\n                \"latency\": null\n            },\n            \"description\": \"A lightweight, mobile-oriented QA model based on TinyBERT, optimized for the NewsQA dataset.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"iterative testing and tuning\"],\n        \"target_device\": \"mobile devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for resource-constrained environments\"],\n        \"demonstration\": \"mobile app showcasing model performance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent to build a model (TinyBERT-based QA) with a focus on performance and resource constraints. It covers NLP domain with QA task and NewsQA dataset. Target metrics include 90% accuracy, sub-400ms latency (not specified in the response as the value may vary during iterative testing), and emphasizes energy efficiency. Datasets and preprocessing steps are applicable for NewsQA, and a high expertise level is implied as the requirements are quite specific.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "For our next cutting-edge sports technology project, we seek to develop a real-time, edge-computing object detection system that not only focuses on precision detection of rare and unconventional sports equipment during extreme sports competitions, but also predicts the intent behind these movements and anticipates future actions. The model, built on the advanced Mixture-of-Experts (MxNet) architecture with a fused R-CNN and LSTM component, must operate within a stringent latency budget of 10 milliseconds while maintaining above 95% accuracy across various challenging lighting and weather conditions. Additionally, the system should be modular, allowing for easy integration with existing broadcast infrastructure and capable of handling multiple concurrent events simultaneously.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"sports technology\",\n        \"description\": \"The project aims to develop a real-time, edge-computing object detection system for extreme sports. The system should precisely detect rare and unconventional equipment, predict intent behind movements, and anticipate future actions. It should use an advanced Mixture-of-Experts (MxNet) architecture with a fused R-CNN and LSTM component, operating within a 10 ms latency budget and maintaining above 95% accuracy in challenging conditions. It must be modular and compatible with broadcast infrastructure for concurrent event handling.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": 10\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time (latency)\",\n                \"value\": 10,\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Unconventional Sports Equipment Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"equipment\", \"intent\", \"future_actions\"],\n            \"specification\": {\n                \"expected_challenging_conditions\": [\"extreme lighting\", \"weather\"]\n            },\n            \"description\": \"A dataset for real-world object detection, including rare and unconventional sports equipment, accompanied by intent predictions and future action anticipation.\",\n            \"preprocessing\": [\n                \"account for extreme conditions\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Mixture-of-Experts (MxNet)\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"fused R-CNN and LSTM\",\n                \"framework\": \"MxNet\"\n            },\n            \"description\": \"A state-of-the-art model with MxNet implementation, specifically designed for real-time edge computing, high precision, and intent prediction in the context of sports equipment detection.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"fusing R-CNN and LSTM components\"],\n        \"target_device\": \"edge computing\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for low latency\"],\n        \"demonstration\": \"real-time streaming and event synchronization\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided information has been structured based on the given instruction, focusing on a high-end ML project for real-time object detection. The JSON response reflects the high expertise level and the specific requirements like accuracy, latency, and modularity. The MxNet architecture with fused R-CNN and LSTM is relevant to the task. Some assumptions and gaps are filled in, such as the need to handle challenging conditions and optimize for latency. However, additional details may be required, like the exact conditions for integration with existing infrastructure.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "multimodal forgery detection", "instruction": "Develop a real-time, explainable fusion model for multimodal forgery detection in both text and images, using DocTamper dataset. The model must achieve at least 95% precision, withstand adversarial attacks, and be integrated with a secure, visually intuitive interface with real-time feedback for non-technical users, ensuring ethical considerations and GDPR compliance.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"multimodal forgery detection\",\n        \"application_domain\": \"cybersecurity\",\n        \"description\": \"The task is to develop a real-time, explainable fusion model for detecting forgeries in both text and images using the DocTamper dataset. The model must achieve a precision of at least 95%, withstand adversarial attacks, and be integrated with a secure, visually intuitive interface with real-time feedback for non-technical users, while ensuring ethical considerations and GDPR compliance.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"adversarial robustness\",\n                \"value\": null,\n                \"unit\": \"%\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"DocTamper dataset\",\n            \"modality\": [\"text\", \"image\"],\n            \"target_variables\": [\"forgery\"],\n            \"specification\": {\n                \"multimodal_input\": true,\n                \"specific_text_processing\": null,\n                \"specific_image_features\": null\n            },\n            \"description\": \"A dataset for multimodal forgery detection tasks, covering both text and images.\",\n            \"preprocessing\": [\n                \"text preprocessing\",\n                \"image preprocessing\"\n            ],\n            \"augmentation\": [\"adversarial attacks\"],\n            \"visualization\": [\"real-time feedback\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"fusion model\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"explainability\": true,\n                \"architecture\": {\n                    \"type\": \"deep fusion\"\n                },\n                \"specific_parameters\": {\n                    \"complexity\": \"optimized for real-time performance\"\n                }\n            },\n            \"description\": \"A real-time, explainable fusion model for multimodal forgery detection with focus on text and images, achieving at least 95% precision and withstands adversarial attacks.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"ethical considerations\", \"GDPR compliance\"],\n        \"target_device\": \"secured, real-time deployment\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"visually intuitive interface\"],\n        \"demonstration\": \"real-time feedback for non-technical users\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure reflects the given instruction, specifying a build task with high-level expertise. The problem area is multimodal learning, with the focus on forgery detection. The DocTamper dataset and the requirements for precision, adversarial robustness, interface, ethics, and GDPR are included. The model type, performance metric, and complexity metrics are derived from the instruction, but certain specific model parameters and details are left as optimization points. The service requirements match the overall objective.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "tabular classification", "instruction": "As a specialized financial services analyst, my objective is to enhance the precision of small business loan risk assessment using historic default data. Develop an efficient machine learning model for tabular classification that integrates multiple applicant variables (income, credit score, industry, loan tenure) and outperforms existing rules-based systems with AUC-ROC metric above 0.9.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"tabular data analysis\",\n        \"downstream_task\": \"tabular classification\",\n        \"application_domain\": \"financial services\",\n        \"description\": \"The objective is to develop an efficient machine learning model for small business loan risk assessment using historic default data. The focus is on improving precision by integrating multiple applicant variables (income, credit score, industry, loan tenure) and achieving an AUC-ROC metric of at least 0.9, surpassing existing rules-based systems.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": 0.9\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"default\"],\n            \"specification\": {\n                \"variables\": [\n                    {\"name\": \"income\", \"description\": \"Applicant's income\"},\n                    {\"name\": \"credit_score\", \"description\": \"Applicant's credit score\"},\n                    {\"name\": \"industry\", \"description\": \"Applicant's industry type\"},\n                    {\"name\": \"loan_tenure\", \"description\": \"Loan duration\"}\n                ]\n            },\n            \"description\": \"A tabular dataset containing historic data for small business loan applicants, with variables that need to be integrated to predict default risk.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"ensemble models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_type\": \"tabular classification\",\n                \"target_metric\": \"precision\"\n            },\n            \"description\": \"A machine learning model, likely an ensemble model or neural network, for tabular classification in small business loan risk assessment with the focus on precision and AUC-ROC of at least 0.9.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": null\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is based on the provided instruction, with a high expertise level specified since it's a specialized financial services analyst. The problem details include a tabular data analysis task for loan risk assessment with AUC-ROC as the performance metric and a specific goal of improving precision. It assumes that the data includes multiple applicant variables and is seeking to surpass existing rules-based systems. The model family is set to ensemble or neural networks due to the complexity of integrating multiple variables.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "tabular regression", "instruction": "For a multifaceted tabular regression project, the team is tasked with forecasting social media post engagement using the 'Social Media Engagement' dataset. Given various metadata features and temporal dynamics, analyze feature importance and propose an ensemble model. Justify your choice of algorithms and evaluation metrics for real-world performance.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"tabular data analysis\",\n        \"downstream_task\": \"tabular regression\",\n        \"application_domain\": \"social media\",\n        \"description\": \"The team is required to build a multifaceted tabular regression model for forecasting social media post engagement using the 'Social Media Engagement' dataset. Key aspects to consider include feature importance analysis and the use of ensemble models. The focus should be on algorithms that perform well in real-world scenarios and appropriate evaluation metrics for assessing performance.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"RMSE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"R^2\",\n                \"value\": null\n            },\n            {\n                \"name\": \"Mean Absolute Error (MAE)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Social Media Engagement\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"engagement\"],\n            \"specification\": {\n                \"feature_types\": [\"metadata\", \"temporal\"],\n                \"number_of_features\": null,\n                \"data_length\": null\n            },\n            \"description\": \"A tabular dataset with metadata and temporal features for predicting social media post engagement.\",\n            \"preprocessing\": [\"feature scaling\", \"encoding\"],\n            \"augmentation\": [],\n            \"visualization\": [\"feature importance\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"ensemble model\",\n            \"family\": \"ensemble models\",\n            \"type\": \"neural networks (ensemble method)\",\n            \"specification\": {\n                \"base_models\": [\"random forest\", \"gradient boosting\", \"stacking\"],\n                \"ensemble_method\": \"average\"\n            },\n            \"description\": \"An ensemble model combining multiple machine learning algorithms, such as random forest, gradient boosting, and stacked models, for enhanced performance in social media post engagement prediction.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Include ensemble methods to exploit the power of multiple models and potentially better handle the dataset's complexity.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature selection\", \"dimensionality reduction\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorFlow serving\", \"Kubernetes\"],\n        \"demonstration\": \"Demonstrate performance through A/B testing or real-world predictive scenarios.\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response covers the essence of the provided task, focusing on the 'build' intent with high expertise, tabular regression in the social media domain. The 'Social Media Engagement' dataset is addressed, along with the importance of feature analysis, ensemble model, and suitable algorithms (random forest, gradient boosting, stacking). Performance metrics include RMSE, R^2, and MAE. Some aspects like specific feature types and exact numbers are not given due to their unavailability from the prompt, but the reasoning suggests that the missing information would be present in the actual response.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "\"Develop a highly specialized, real-time machine learning model capable of recognizing not only domestic and wild animals in diverse environments, but also identifying specific species and their behavioral patterns, while preserving privacy by discriminating between individuals and using minimal data storage. The model must handle extreme weather conditions, low light, and motion blur, while maintaining accuracy and efficiency on a resource-constrained embedded device for a remote surveillance system in a wildlife sanctuary.\"", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"wildlife conservation\",\n        \"description\": \"The task is to develop a real-time machine learning model for recognizing both domestic and wild animals, their species, and behavioral patterns in diverse environments. The model should maintain privacy by discriminating individuals and use minimal data storage. It must operate efficiently and accurately under extreme weather conditions, low light, and motion blur, while being deployed on a resource-constrained embedded device for a remote surveillance system in a wildlife sanctuary.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"efficiency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Unknown (to be collected)\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"animal_species\", \"behavioral_pattern\"],\n            \"specification\": {\n                \"image_resolution\": \"variable\",\n                \"environment_conditions\": [\"extreme weather\", \"low light\", \"motion blur\"]\n            },\n            \"description\": \"A dataset specifically tailored for the given requirements, capturing diverse scenes and animals under challenging conditions.\",\n            \"preprocessing\": [\"image enhancement\", \"data augmentation\"],\n            \"augmentation\": [\"random weather simulation\", \"lighting variations\", \"motion blur\"],\n            \"visualization\": [\"example samples of various environmental conditions\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"CNN (Convolutional Neural Networks)\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"architecture\": \"tiny-yolo or similar\",\n                \"real-time_inference\": true,\n                \"minimal_data_storage\": true\n            },\n            \"description\": \"A specialized object detection model designed for real-time animal recognition and behavioral analysis, addressing privacy and resource constraints.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Adaptation and optimization techniques for resource-constrained devices.\",\n        \"Privacy-preserving algorithms for identification and data storage.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature selection for embedded deployment\"],\n        \"target_device\": \"resource-constrained embedded device\",\n        \"deployment_endpoint\": \"remote surveillance system in the wildlife sanctuary\",\n        \"inference_engine\": [\"optimized for embedded environment\"],\n        \"demonstration\": \"demonstration of model's performance in extreme conditions and resource efficiency\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response interprets the user's instruction by indicating a high-level build intent and expert-level expertise. The problem area of computer vision is identified, with object detection as the downstream task for recognizing animals and their behaviors. Metrics include accuracy and efficiency, with specific complexities like inference time and memory size. The model type is a specialized CNN-based deep learning model, and the data requirements and preprocessing techniques are adapted to the given conditions. The wildlife sanctuary and resource constraints are incorporated into the service and deployment sections.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series classification", "instruction": "You have been tasked with a unique and challenging time-series classification problem in the field of predictive maintenance. The problem revolves around a recently discovered underwater sensor network dataset, named \"Deep Ocean Turbulence Detection\" (DOTD), which captures intricate patterns in oceanic conditions over a period of several months (TIME_STEPS=43200). The input data consists of complex, high-dimensional features extracted from Pressure, Temperature, Salinity, Current Velocity, and Turbulence Intensity (INPUT_DIM=25). The task is to develop a model that forecasts the classification labels for system health, specifically categorizing them into five states: normal, mild degradation, moderate degradation, severe degradation, and catastrophic failure, represented by the integer values {0, 1, 2, 3, 4}. Performance is measured using the F1-score, and it's crucial to account for class imbalance within the dataset using appropriate sampling techniques. In addition to model training, propose an ensemble strategy to further improve overall accuracy on this rarely seen, temporally dense data.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"predictive maintenance\",\n        \"description\": \"You are given a time-series classification problem in predictive maintenance with the Deep Ocean Turbulence Detection (DOTD) dataset. The dataset captures oceanic conditions over several months, with high-dimensional input data from Pressure, Temperature, Salinity, Current Velocity, and Turbulence Intensity. The task is to predict system health states (0: normal, 1: mild degradation, 2: moderate degradation, 3: severe degradation, 4: catastrophic failure). The performance metric is F1-score, considering class imbalance using sampling techniques.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1-score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Deep Ocean Turbulence Detection\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"TIME_STEPS\": 43200,\n                \"INPUT_DIM\": 25\n            },\n            \"description\": \"A high-dimensional underwater sensor network dataset capturing oceanic conditions over several months for predictive maintenance, specifically for time-series classification task.\",\n            \"preprocessing\": [\"account for class imbalance with sampling techniques\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model architecture\": \"suited for time-series and considering high-dimensional input\"\n            },\n            \"description\": \"A neural network-based model to forecast system health states in predictive maintenance using the DOTD dataset.\"\n        },\n        {\n            \"name\": \"\",\n            \"family\": \"ensemble model\",\n            \"type\": \"ensemble models\",\n            \"specification\": {\n                \"ensemble strategy\": \"proposed ensemble strategy for temporally dense data\"\n            },\n            \"description\": \"An ensemble model strategy to improve accuracy on the DOTD dataset with rarely seen temporally dense data.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider class imbalance in dataset and use of appropriate sampling techniques\",\n        \"Proposed ensemble strategy for temporally dense data\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"sampling techniques for class imbalance\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Demonstration of improved accuracy through ensemble strategy\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response parses the instruction, indicating a high expertise level for the task. The problem area, dataset details, and specific model types (neural networks and ensemble models) are included. Performance is focused on F1-score with consideration of class imbalance and ensemble strategy for temporal dense data. However, specific model architectures and ensemble details are left open for a more detailed inquiry or collaboration.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "image classification", "instruction": "As a project manager for a cutting-edge AI development team, your mandate is to design an advanced image recognition system using the Fashion-MNIST dataset, with a focus on Capsule Networks. The objective is not just to reach but exceed the 90% benchmark accuracy, while maintaining exceptional resilience against affine image transformations. The request demands a comprehensive analysis, comparing capsule network performance with state-of-the-art Convolutional Neural Networks (CNNs), delving into nuanced advantages, trade-offs, and potential architectural innovations in a 1500-word technical report, including code implementation and visual results for each method.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"fashion industry\",\n        \"description\": \"The project requires the development of an advanced image recognition system using the Fashion-MNIST dataset, focusing specifically on Capsule Networks with the goal of achieving over 90% accuracy and resilience against affine image transformations. The task involves a comparative analysis with Convolutional Neural Networks (CNNs), discussing advantages, trade-offs, and architectural innovations in a 1500-word technical report, including code implementations and visual results.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": {\n                    \"benchmark\": 0.90,\n                    \"value\": null\n                }\n            },\n            {\n                \"name\": \"resilience to affine transformations\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"accuracy trade-off\",\n                \"value\": null,\n                \"unit\": \"comparison\"\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds/sequence\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Fashion-MNIST\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"label\"],\n            \"specification\": {\n                \"image_size\": 28,\n                \"channels\": 1,\n                \"number_of_classes\": 10\n            },\n            \"description\": \"A benchmark dataset for image classification, focusing on image recognition tasks.\",\n            \"preprocessing\": [\"affine transformations\"],\n            \"augmentation\": [],\n            \"visualization\": [\"architectural visualization\", \"accuracy plots\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Capsule Network\",\n                       \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"type_of_capsule_network\": \"\",\n                \"number_of_layers\": \"\",\n                \"routing_algorithm\": \"\"\n            },\n            \"description\": \"An advanced image recognition model using Capsule Networks designed to surpass 90% accuracy on the Fashion-MNIST dataset and demonstrate resilience against affine image transformations.\"\n        },\n        {\n            \"name\": \"Convolutional Neural Network (CNN)\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"\",\n                \"parameters\": \"\",\n                \"performance\": {\n                    \"accuracy\": \"state-of-the-art\"\n                }\n            },\n            \"description\": \"A state-of-the-art CNN for comparison purposes.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"type\": \"insights\",\n            \"content\": \"Advantages of Capsule Networks over CNNs for image recognition with affine transformations.\"\n        },\n        {\n            \"type\": \"architectural innovations\",\n            \"content\": \"Potential improvements or modifications in capsule network architecture for enhanced performance.\"\n        },\n        {\n            \"type\": \"trade-offs\",\n            \"content\": \"Comparison of time and resource requirements between Capsule Networks and CNNs.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"affine invariance\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorFlow\", \"PyTorch\"],\n        \"demonstration\": {\n            \"report_length\": 1500,\n            \"content_types\": [\"code snippets\", \"visual results\"]\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the project management task for building an advanced image recognition system with Capsule Networks. It captures the target accuracy, resilience to affine transformations, and the request for a comparative analysis with CNNs. The provided insights and a 1500-word report with code implementation and visual results are included. The response aligns with the given instruction while allowing for necessary nuances.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "The project targets enhancing an advanced Mask R-CNN model for indoor scene parsing in the ADE20K dataset, demanding pixel-level instance segmentation with a focus on tiny, occluded objects. Emphasize multi-scale training and testing with a strategy to optimize feature fusion. Strive for a benchmark mAP of 45% while ensuring robustness to complex layout challenges.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"robotics/AR/VR\",\n        \"description\": \"The objective is to enhance an advanced Mask R-CNN model for indoor scene parsing in the ADE20K dataset, focusing on tiny and occluded objects with pixel-level segmentation. The project emphasizes multi-scale training and testing to improve feature fusion. The target benchmark is 45% mAP, while robustness against complex layout challenges should be a priority.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean average precision (mAP)\",\n                \"value\": 0.45\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"feature fusion optimization\",\n                \"value\": null,\n                \"unit\": \"\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ADE20K\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"pixel-level instance segmentation\"],\n            \"specification\": {\n                \"type\": \"indoor scene parsing\",\n                \"object focus\": [\"tiny\", \"occluded\"]\n            },\n            \"description\": \"A dataset for indoor scene parsing, particularly targeting tiny and occluded objects with a focus on pixel-level instance segmentation.\",\n            \"preprocessing\": [\"multi-scale resizing\"],\n            \"augmentation\": [\"data augmentation for tiny/occluded objects\"],\n            \"visualization\": [\"visualize feature fusion\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Enhanced Mask R-CNN\",\n            \"family\": \"neural networks (specifically, CNN and R-CNN architecture)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"multi-scale training\": true,\n                \"feature fusion strategy\": \"optimized\"\n            },\n            \"description\": \"An advanced Mask R-CNN model optimized for indoor scene parsing, specifically targeting tiny and occluded objects, with a focus on achieving a benchmark mAP of 45%.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Robustness against complex layout challenges\",\n        \"Emphasis on multi-scale techniques for improved performance\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"multi-scale feature extraction\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"demonstration of model performance on challenging indoor scenes with tiny and occluded objects\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This JSON response accurately captures the problem statement from the given instruction, focusing on the enhancement of a Mask R-CNN model, target dataset, performance goals, and key strategies. The user's high expertise level is reflected. However, specific feature fusion strategy details are not provided as they might be part of a more technical discussion or open for discussion.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "community detection", "instruction": "As a project manager for a bioinformatics team, I need to design a PPI network analysis pipeline using machine learning algorithms specifically tailored for community detection in the yeast proteome. Can you recommend a beginner-friendly, yet effective method that integrates convolutional graph neural networks and incorporates interpretability features?", "resposne": "{\n    \"user\": {\n        \"intent\": \"consult\",\n        \"expertise\": \"medium\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"community detection\",\n        \"application_domain\": \"bioinformatics\",\n        \"description\": \"A project manager seeks a beginner-friendly machine learning method for PPI network analysis, focusing on community detection in yeast proteome using convolutional graph neural networks. Interpretability features are also a requirement.\",\n        \"performance_metrics\": [],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Yeast proteome PPI network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"protein communities\"],\n            \"specification\": {\n                \"node_type\": \"proteins\",\n                \"edge_type\": \"physical interactions\"\n            },\n            \"description\": \"A graph dataset representing protein-protein interactions in yeast, requiring community detection analysis.\",\n            \"preprocessing\": [\"node feature extraction\", \"edge feature engineering\"],\n            \"augmentation\": [],\n            \"visualization\": [\"community structure visualizations\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Convolutional Graph Neural Network (e.g., GraphSAGE, GCN)\",\n            \"family\": \"neural networks\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"model_architecture\": \"Beginner-friendly\",\n                \"interpretability_features\": [\"Attention mechanisms\", \"Node importance scores\"]\n            },\n            \"description\": \"A beginner-friendly method combining convolutions for graph data with interpretability elements for yeast proteome community detection.\"\n        }\n    ],\n    \"knowledge\": [\n        \"For a beginner, consider using pre-trained models with simpler architectures, and employ explainable AI techniques such as attention mechanisms for better interpretability.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature scaling\",\n            \"node embedding generation\"\n        ],\n        \"target_device\": \"PC or cloud for computational requirements\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorFlow or PyTorch\"],\n        \"demonstration\": \"Visualize community detection results and model interpretability explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON response captures the user's request for a recommendation, which aligns with the 'consult' intent. Expertise level is set to 'medium' as the user is a project manager but not a machine learning expert. The focus is on graph machine learning for PPI network analysis, with interpretability features. Specific model, such as GraphSAGE, is suggested along with relevant complexities and service requirements. The confidence score is 0.9 given the clarity of the request.\",\n        \"score\": 0.9\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a project manager for the advanced machine learning team, your goal is to develop an efficient time-series forecasting model for the Electricity dataset. The dataset is complex, featuring multiple seasons, long-term trends, and short-term anomalies. We have divided it into train, validation, and test sets, with input sequences of length 96 and 321-dimensional observations (INPUT_SEQ_LEN=96, INPUT_DIM=321). Your task is to design a model that not only forecasts the subsequent 96-step sequences (PRED_SEQ_LEN=96, PRED_DIM=321) but also demonstrates resilience to outliers and adapts to different temporal patterns. Ensure high accuracy using advanced metrics like root mean squared error (RMSE), mean absolute percentage error (MAPE), and integrate a rolling forecast window for continuous evaluation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy\",\n        \"description\": \"The project goal is to develop an efficient time-series forecasting model for the Electricity dataset with multiple seasons, long-term trends, and short-term anomalies. The model should forecast subsequent 96-step sequences, be resilient to outliers, adapt to different temporal patterns, and use advanced performance metrics like RMSE and MAPE. A rolling forecast window for continuous evaluation is required.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"root_mean_squared_error\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean_absolute_percentage_error\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Electricity dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 321\n            },\n            \"description\": \"A complex time-series dataset with 96-step input sequences and 321-dimensional observations, divided into train, validation, and test sets.\",\n            \"preprocessing\": [\"handling missing values\", \"seasonality adjustments\"],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"time series decomposition\",\n                \"anomaly detection plots\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks (e.g., LSTM or Transformer)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"forecast_window_size\": 96,\n                \"output_size\": 321,\n                \"resilience_to_outliers\": true,\n                \"temporal_pattern_adaptation\": true\n            },\n            \"description\": \"An advanced time-series forecasting model with deep learning architecture, capable of handling multiple seasonal patterns and outliers.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider using robust loss functions (e.g., MAE or Huber) for handling outliers.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"rolling forecast implementation\", \"time window shifting\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized for faster performance\"],\n        \"demonstration\": \"Visualizations and performance metrics comparison with baseline models.\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the project manager's task, from the dataset complexity to the model requirements and evaluation metrics. The performance metrics and robustness to outliers are explicitly mentioned, and the necessity to adapt to temporal patterns is indicated. However, the specific model name or type is left unspecified, needing to be filled based on domain expertise or user preference.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "For the advanced time-series forecasting challenge, you are to develop a sophisticated predictive model using the intricate Traffic dataset, which consists of diverse real-world time series data. The data has been meticulously divided into train, validation, and test sets, with specific input patterns (96 observations of 862 dimensions, INPUT_SEQ_LEN=96, INPUT_DIM=862). Your task now requires not only constructing a model but also designing an algorithm that performs multi-step lookahead predictions (PRED_SEQ_LEN=96) while considering complex temporal dependencies. The model must demonstrate excellence in accuracy, measured through both mean squared error (MSE) and mean absolute error (MAE), while also handling outliers and seasonality within the sequences. Provide detailed architecture and training strategies in your solution.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"traffic management or transportation\",\n        \"description\": \"You need to develop a sophisticated predictive model for an advanced time-series forecasting challenge using the Traffic dataset. The model should perform multi-step lookahead predictions (PRED_SEQ_LEN=96) on real-world time series data, considering complex temporal dependencies, handle outliers and seasonality, and achieve high accuracy measured by MSE and MAE.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MSE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MAE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Traffic dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 862\n            },\n            \"description\": \"A dataset containing diverse real-world time series data, divided into train, validation, and test sets, with a specific input structure of 96 observations and 862 dimensions.\",\n            \"preprocessing\": [\"handling outliers\", \"seasonality analysis\"],\n            \"augmentation\": [],\n            \"visualization\": [\"sequence patterns\", \"seasonality visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks (e.g., LSTM, Transformer-based)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"explain briefly\": \"Describes the complex architecture with attention mechanisms or multi-layered LSTM for capturing temporal dependencies\"\n                },\n                \"training_strategies\": {\n                    \"describe briefly\": \"Includes strategies such as early stopping, model ensembling, or custom loss functions for handling outliers and seasonality\"\n                }\n            },\n            \"description\": \"A sophisticated predictive model for time-series forecasting with multi-step lookahead and ability to handle complex temporal dependencies, outliers, and seasonality.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"example\": \"Techniques like AutoARIMA or FBProphet can help in handling seasonality, and using custom loss functions like Huber loss for handling outliers during model training.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": {\n            \"instructions\": \"Create visualizations and performance metrics comparisons for the model's results on the train, validation, and test sets.\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is valid and complete based on the provided instruction. It covers the aspects of developing a model, task specifics, chosen dataset, desired performance metrics, and architecture considerations. However, details on the exact model architecture and training strategies are left intentionally vague due to the complexity of the task and need for further consultation or collaboration.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "image segmentation", "instruction": "The project manager needs to integrate a real-time, latency-sensitive U-Net model for high-definition indoor scene segmentation, ensuring compatibility with resource-constrained embedded devices while maintaining accuracy above 95% and accommodating for low-light conditions.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"industrial design or robotics\",\n        \"description\": \"The project requires a real-time, latency-sensitive U-Net model for high-definition indoor scene segmentation. It must maintain accuracy above 95% and operate efficiently on resource-constrained embedded devices, while handling low-light conditions.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"image_resolution\": {\n                    \"width\": \"high-definition\",\n                    \"height\": \"high-definition\"\n                },\n                \"data_conditions\": \"low-light\"\n            },\n            \"description\": \"A high-definition indoor scene dataset with low-light conditions for real-time U-Net model development.\",\n            \"preprocessing\": [\n                \"data augmentation techniques for low-light conditions\"\n            ],\n            \"augmentation\": [\n                \"enhanced techniques for low-light and resource-constrained environments\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"U-Net\",\n            \"family\": \"segmentation models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"real-time latency\": true,\n                    \"resource-constrained\": true\n                }\n            },\n            \"description\": \"A real-time U-Net model suitable for high-definition indoor scene segmentation, optimized for resource-constrained embedded devices and low-light conditions.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"embedded device optimization techniques\"],\n        \"target_device\": \"resource-constrained embedded devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for low-power or latency\"],\n        \"demonstration\": \"High-definition segmentation in real-time with low-light adaptation\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the key aspects of the instruction: the need for a U-Net model, the emphasis on real-time and accuracy, the requirement for resource-constrained devices, and the handling of low-light conditions. The project manager's level of expertise is assumed to be high, and the model family and performance metric (accuracy) are specified. However, the dataset name and preprocessing steps are not provided in the instruction, so those remain unspecified in the response.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a highly specialized project manager for a cutting-edge machine learning development team, you've been tasked with a unique and complex time-series forecasting challenge. Your team has been handed an obscure dataset derived from the merging of meteorological, ecological, and financial data over a century (EXTREMELY_DIVERSE_INPUTS=1000), which spans multiple spatial and temporal scales. The dataset has been meticulously stratified into a labyrinthine nested structure: a nested train-validation-test partition within each unique location and season, ensuring temporal and spatial variability in the evaluation process. \r\n\r\nEach input sequence, now extended to an intricate pattern of past observations (INPUT_SEQ_LEN=4096, with a diverse array of INPUT_DIM=100 variables capturing minute fluctuations), carries valuable insights into unseen patterns. The goal is to forecast not only the next PRED_SEQ_LEN=108 consecutive points (to account for various macroeconomic indicators and environmental anomalies) but also identify potential long-term trends and interdependencies between variables. Performance will be assessed through a multi-faceted metric suite: mean absolute percentage error (MAPE), symmetric mean absolute percentage error (SMAPE), rolling mean forecast skill (RMFS), and a newly devised 'Temporal Coherence Index' (TCI) that quantifies the forecast's adherence to temporal patterns.\r\n\r\nTrain a state-of-the-art time-series forecasting model that not only achieves exceptional accuracy but also exhibits superior interpretablity, allowing your team to provide actionable insights to stakeholders. Remember to optimize hyperparameters across multiple model architectures and incorporate advanced techniques like deep ensemble methods and attention mechanisms for superior performance under these challenging conditions.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"complex systems (meteorology, ecology, finance)\",\n        \"description\": \"You are to develop a state-of-the-art time-series forecasting model for an obscure dataset with meteorological, ecological, and financial data, stratified across locations and seasons. The model should predict PRED_SEQ_LEN=108 consecutive points while also identifying long-term trends and interdependencies, using a multi-metric approach including MAPE, SMAPE, RMFS, and a custom 'Temporal Coherence Index' (TCI).\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean absolute percentage error (MAPE)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"symmetric mean absolute percentage error (SMAPE)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"rolling mean forecast skill (RMFS)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"Temporal Coherence Index (TCI)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Obscure Merged Dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"EXTREMELY_DIVERSE_INPUTS\": 1000,\n                \"INPUT_SEQ_LEN\": 4096,\n                \"INPUT_DIM\": 100\n            },\n            \"description\": \"A comprehensive dataset spanning a century with meteorological, ecological, and financial data at diverse spatial and temporal scales. Contains nested train-validation-test partitions for each location-season.\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"feature normalization\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"temporal patterns analysis\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"state-of-the-art\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": [\"deep ensemble methods\", \"attention mechanisms\"],\n                \"optimization\": {\n                    \"hyperparameter tuning\": true\n                }\n            },\n            \"description\": \"A highly interpretable time-series forecasting model incorporating advanced techniques to achieve high accuracy for the given complex dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider using explainable AI components to enhance model interpretability.\",\n        \"Exploit temporal dependencies using recurrent or transformers for enhanced forecasting.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature extraction\",\n            \"feature selection\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"lightweight, optimized engine for real-time performance\"],\n        \"demonstration\": \"visualizations of forecasts and insights\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is based on the provided instructions, with the user's intent set to 'build', reflecting the task of developing a model. The dataset description, performance metrics, and complexity metrics are derived from the instruction, and various preprocessing, model components, and service requirements are incorporated accordingly. The model is expected to be state-of-the-art and interpretable, as specified. However, certain details like model architecture specifics and exact performance values are left unspecified, as they would require more information to be finalized.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "object detection", "instruction": "The maritime surveillance initiative demands a highly specialized Object Detection model, utilizing Faster R-CNN architecture with a custom SeaVehicles-92 dataset. This dataset contains a diverse range of vessels, their precise hull lengths and headings, along with minute variations in sea conditions. The model should achieve an exceptional 95% minimum F1 score and exhibit robustness in inclement weather scenarios. Although not mandatory for real-time scenarios, the model must demonstrate single-image inference speed of under 500 milliseconds on cloud-based NVIDIA Tesla V100 GPUs for scalable operations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"maritime surveillance\",\n        \"description\": \"The user wants to build a specialized Object Detection model using the Faster R-CNN architecture with the custom SeaVehicles-92 dataset. The dataset contains details of diverse vessels, hull lengths, headings, and sea conditions, targeting a minimum F1 score of 95% and robustness in challenging weather conditions. The model should also have a single-image inference speed of under 500 milliseconds on NVIDIA Tesla V100 GPUs for scalability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1 Score\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Inference Speed\",\n                \"value\": 0.5,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"SeaVehicles-92\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"vessel_data\"],\n            \"specification\": {\n                \"diversity\": \"vessels and sea conditions\",\n                \"hull_lengths_and_headings\": true\n            },\n            \"description\": \"Custom dataset with a focus on vessels and precise details for Faster R-CNN model development.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Faster R-CNN\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"Faster R-CNN\",\n                \"GPU_inference_target\": \"NVIDIA Tesla V100\",\n                \"target_inference_speed\": \"500 milliseconds\"\n            },\n            \"description\": \"A specialized object detection model with Faster R-CNN using the SeaVehicles-92 dataset, optimized for maritime surveillance with robustness in inclement weather.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"cloud-based NVIDIA Tesla V100 GPUs\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-based inference\"],\n        \"demonstration\": \"robustness in inclement weather scenarios\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is constructed based on the given instruction, capturing the user's intent, expertise, data specifics, model requirements, and performance metrics. It is assumed that the user has a high level of expertise, as they are asking for a specialized model. The single inference speed constraint and GPU target are clearly specified. The missing details (model name and family, for example) can be provided by the user as per the schema.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "Develop a high-resolution image recognition system using the advanced MViT architecture specifically designed for fine-grained gender and age estimation in a diverse dataset of facial images with challenging lighting and pose variations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"biometrics\",\n        \"description\": \"The user is asking for a system to build an advanced image recognition model with fine-grained gender and age estimation capability. The dataset should be diverse, containing facial images with challenging lighting and pose variations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Diverse Facial Images for Gender and Age Estimation\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"gender\", \"age\"],\n            \"specification\": {\n                \"size多样性\": \"diverse\",\n                \"pose variations\": \"challenging\",\n                \"illumination conditions\": \"varied\"\n            },\n            \"description\": \"A dataset for image recognition with MViT architecture, focusing on fine-grained gender and age estimation in facial images with challenging lighting and pose variations.\",\n            \"preprocessing\": [\"lighting normalization\", \"pose alignment\"],\n            \"augmentation\": [\"contrast manipulation\", \"random rotation\"],\n            \"visualization\": [\"facial landmarks detection\", \"example images\"],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"MViT\",\n            \"family\": \"Advanced Image Recognition Architecture\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"MViT (Multi-View Transformer)\",\n                \"specific_layer_details\": \"\",\n                \"accuracy on similar tasks\": \"\"\n            },\n            \"description\": \"A MViT-based model specifically designed for fine-grained gender and age estimation in facial images.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"content\": \"Challenges in MViT for fine-grained tasks\",\n            \"source\": \"Expert knowledge\"\n        },\n        {\n            \"content\": \"Fine-tuning strategies for handling diverse data\",\n            \"source\": \"Literature or research\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"transfer learning\", \"data balancing\"],\n        \"target_device\": \"CPU with GPU support\",\n        \"deployment_endpoint\": \"cloud-based\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"OpenVINO\"],\n        \"demonstration\": \"Interactive facial analysis demo\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intention (build) for creating an advanced image recognition system with fine-grained gender and age estimation. The user's high expertise is reflected, and the problem is in the domain of computer vision with specified requirements. Performance metrics like accuracy, precision, and recall are essential for this task. MViT architecture, preprocessing, and augmentation techniques are included, as well as necessary service and deployment details. However, the user's exact dataset expectations and model performance targets are not specified.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "multimodal emotion recognition", "instruction": "As a machine learning project manager, I need you to evaluate and compare the performance of advanced deep learning models, specifically those integrating visual and audio modalities, on the IEMOCAP database for robust multimodal emotion recognition. Provide a detailed analysis of suitable algorithms and their preprocessing requirements.", "resposne": "{\n    \"user\": {\n        \"intent\": \"consult-build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"multimodal emotion recognition\",\n        \"application_domain\": \"human-computer interaction\",\n        \"description\": \"The task is to evaluate and compare the performance of advanced deep learning models that integrate visual and audio modalities on the IEMOCAP database for robust multimodal emotion recognition. A detailed analysis of suitable algorithms and their preprocessing requirements is needed.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"IEMOCAP database\",\n            \"modality\": [\n                \"image\",\n                \"audio\"\n            ],\n            \"target_variables\": [\"emotion\"],\n            \"specification\": {\n                \"number_of_samples\": null,\n                \"sample_duration\": null,\n                \"modalities_shape\": {\n                    \"image\": {\n                        \"height\": null,\n                        \"width\": null,\n                        \"channels\": null\n                    },\n                    \"audio\": {\n                        \"sampling_rate\": null,\n                        \"channels\": null,\n                        \"duration\": null\n                    }\n                }\n            },\n            \"description\": \"A dataset for multimodal emotion recognition task, containing visual and audio data from the IEMOCAP database.\",\n            \"preprocessing\": [\n                \"alignment of modalities\",\n                \"feature extraction\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"performance analysis across modalities\"\n            ],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"VGGish + LSTM\",\n            \"family\": \"Convolutional Neural Networks (CNNs) + Recurrent Neural Networks (RNNs)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_parameters\": {\n                    \"VGGish pre-trained layers\": null,\n                    \"LSTM layers\": null\n                },\n                \"FLOPs\": null\n            },\n            \"description\": \"A model using a VGGish pre-trained CNN for audio feature extraction, followed by an LSTM for emotion recognition.\"\n        },\n        {\n            \"name\": \"ResNet + MFCC + GRU\",\n            \"family\": \"Residual Networks (ResNets) + Mel Frequency Cepstral Coefficients (MFCCs) + Gated Recurrent Units (GRUs)\",\n            \"specification\": {\n                \"number_of_layers\": null,\n                \"preprocessing steps\": \"MFCC computation\"\n            },\n            \"description\": \"A model combining ResNet for audio processing, MFCCs for feature extraction, and GRU for emotion recognition.\"\n        },\n        {\n            \"name\": \"Transformer-based fusion model\",\n            \"family\": \"Transformers\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"attention mechanism\": \"multi-head self-attention\",\n                \"fusion technique\": null\n            },\n            \"description\": \"A model that employs transformer layers for parallel processing of visual and audio inputs and a fusion method to combine the modalities.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider comparing fusion strategies (late vs early fusion)\",\n        \"Account for domain adaptation techniques\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"modal fusion techniques tuning\",\n            \"transfer learning\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"TensorFlow Serving\",\n            \"ONNX Runtime\"\n        ],\n        \"demonstration\": \"Interactive visualizations and comparison graphs\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is based on the user's request for evaluating advanced models on IEMOCAP. The user has expertise in project management and is consulting for a high-level analysis. The area, task, and performance metrics are specified. The need for deep learning models that integrate visual and audio modalities, preprocessing requirements, and comparison of algorithms are addressed. However, the performance target values are not provided, as these typically depend on the researcher's goal or previous results in the field.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "Elaborate on developing a scalable video-based visual question answering platform using the diverse YouTube-8M dataset. Implement a multi-modal fusion of 3D convolutional neural networks (CNNs) and advanced Transformer architectures to extract complex spatiotemporal features. Ensure the system's adaptability to tackle a broad spectrum of video content, with a particular focus on niche and temporally evolving topics. Prioritize achieving exceptional precision, timely responses, and a continuous learning mechanism to keep up with the dynamic nature of the data.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"AI and multimedia platforms\",\n        \"description\": \"The goal is to develop a scalable video-based visual question answering platform using the YouTube-8M dataset. The focus is on multi-modal fusion of 3D CNNs and advanced Transformer architectures to extract complex spatiotemporal features. The system must be adaptable to diverse and niche video content, particularly those with temporally evolving topics, while prioritizing precision, timely responses, and a continuous learning mechanism for dynamic data.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"response time\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            },\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"frames per second\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"YouTube-8M\",\n            \"modality\": [\"video\"],\n            \"target_variables\": [\"video features\", \"questions\", \"answers\"],\n            \"specification\": {\n                \"video dimensions\": \"variable\",\n                \"video length\": \"variable\",\n                \"modalities\": [\"RGB\", \"audio\", \"optional subtitles\"]\n            },\n            \"description\": \"A large-scale video dataset with diverse content for visual question answering, including support for niche and temporally evolving topics.\",\n            \"preprocessing\": [\n                \"3D CNN feature extraction\",\n                \"Temporal and spatial feature aggregation\"\n            ],\n            \"augmentation\": [\"temporal cropping\", \"spatial transformation\"],\n            \"visualization\": [\n                \"feature maps analysis\",\n                \"model performance on diverse video categories\"\n            ],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"3D CNN + Transformer fusion architecture\",\n            \"family\": \"neural networks\",\n            \"type\": \"multi-modal\",\n            \"specification\": {\n                \"architecture\": {\n                    \"3D CNN layers\": {},\n                    \"Transformer layers\": {}\n                },\n                \"hyperparameters\": {\n                    \"learning rate\": null,\n                    \"optimizer\": null\n                }\n            },\n            \"description\": \"A sophisticated model that combines 3D CNNs for spatial feature extraction and Transformers for temporal context understanding.\"\n        }\n    ],\n    \"knowledge\": [\n        \"YouTube-8M's dynamic nature and large-scale make it suitable for continuous learning\",\n        \"Adaptability to niche content through model fine-tuning\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"multimodal feature fusion\", \"context-aware response generation\"],\n        \"target_device\": \"cloud-based for scalability and compute resources\",\n        \"deployment_endpoint\": \"custom REST API for real-time queries\",\n        \"inference_engine\": [\"GPU-accelerated execution\"],\n        \"demonstration\": \"Interactive visualizations and performance on diverse video categories\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately represents the user's instruction for a scalable video-based VQA platform. The expertise level is set to 'high' since the task requires advanced technical knowledge. Performance metrics such as precision, response time, and complexity indicators like memory usage and inference speed are included. The YouTube-8M dataset and the model architecture based on 3D CNNs and Transformers are clearly specified. Service requirements for adapting to diverse content, continuous learning, and scalability are also included.\",\n        \"score\": 0.85\n    }\n}"}
{"task": "question answering", "instruction": "The project mandate now demands a specialized multilingual QA system, targeting the cross-lingual dataset MLQA. Opt for the cutting-edge XLM-T model, as it must excel not only in English, Spanish, and Mandarin, but also in Swahili andArabic, ensuring state-of-the-art performance and adaptability in resource-constrained African languages, with a stringent 95% accuracy benchmark.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"multilingual\",\n        \"description\": \"The project requires a specialized multilingual QA system focusing on the MLQA cross-lingual dataset. The XLM-T model should be chosen, demonstrating superior performance in English, Spanish, Mandarin, Swahili, and Arabic while ensuring adaptability to resource-constrained African languages with a strict accuracy target of 95%.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"MLQA\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"question\", \"answer\"],\n            \"specification\": {\n                \"multilingual\": true,\n                \"languages\": [\"English\", \"Spanish\", \"Mandarin\", \"Swahili\", \"Arabic\"]\n            },\n            \"description\": \"A cross-lingual dataset for developing a multilingual QA system, specifically focusing on the resource-constrained African languages.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"XLM-T\",\n            \"family\": \"transformer models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"multilingual\": true,\n                \"languages\": [\"English\", \"Spanish\", \"Mandarin\", \"Swahili\", \"Arabic\"],\n                \"accuracy_target\": 0.95,\n                \"performance\": \"state-of-the-art\"\n            },\n            \"description\": \"The XLM-T model for a multilingual QA system, catering to various languages including resource-limited African languages with a 95% accuracy requirement.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately captures the user's intent, specifying a building task and indicating high expertise. The problem area is correctly identified as natural language processing, with the downstream task as question answering. The MLQA dataset is specified, including its multilingual nature. The XLM-T model is selected, along with the performance requirements (95% accuracy) and the need for adaptability to resource-constrained African languages. The response has a high confidence score due to the direct mapping of the instructions to the JSON structure.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "object detection", "instruction": "In the context of an elite coastal defense project, the team is tasked with developing a state-of-the-art Object Detection model that focuses on rare and unconventional maritime threats, such as underwater drone swarms, debris-activated sea mines, and stealth submarines. The novel architecture should integrate the YOLOv5 backbone with a proprietary OceanAnomalies-128 dataset, which contains encrypted data patterns reflecting these stealth features alongside intricate underwater terrain. The model should push the benchmark to surpass a 98% precision-recall balance and maintain performance in pitch-black and sonar-obstructed conditions. For efficient, real-time disaster response, the model must achieve sub-300 milliseconds latency on Google Cloud's EdgeTPU-equipped devices for fleet-wide surveillance.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"coastal defense, maritime security\",\n        \"description\": \"The user wants to develop a state-of-the-art Object Detection model for an elite coastal defense project. The focus is on detecting rare and unconventional maritime threats like underwater drone swarms, debris-activated sea mines, and stealth submarines. The model must integrate YOLOv5 backbone with the proprietary OceanAnomalies-128 dataset, which includes encrypted data patterns for stealth features and complex underwater terrain.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.98,\n                \"type\": \"precision\"\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": 0.98,\n                \"type\": \"recall\"\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": 0.3,\n                \"unit\": \"seconds\",\n                \"type\": \"inference time\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency on EdgeTPU (Google Cloud)\",\n                \"value\": 300,\n                \"unit\": \"milliseconds\",\n                \"description\": \"Desired to achieve sub-300ms latency for real-time disaster response\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"OceanAnomalies-128\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"underwater threats\"],\n            \"specification\": {\n                \"encrypted_data\": true,\n                \"privacy_features\": [\"stealth\", \"underwater terrain\"],\n                \"dataset_size\": null\n            },\n            \"description\": \"A proprietary dataset containing encrypted data patterns for detecting rare and unconventional maritime threats like stealth submarines and underwater terrain with YOLOv5 backbone.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"YOLOv5\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"custom with YOLOv5 backbone\",\n                \"novel_features\": \"OceanAnomalies-128 integration\"\n            },\n            \"description\": \"A novel object detection model designed for detecting rare maritime threats using YOLOv5 and OceanAnomalies-128 dataset.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"Google Cloud EdgeTPU\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"EdgeTPU\"],\n        \"demonstration\": \"real-time fleet-wide surveillance with low latency\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent to build a model, with a high level of expertise. The problem area, dataset, and performance metrics align with the given instruction. Details such as the target device, inference time, and the need for sub-300ms latency are specified. However, some additional information like the dataset size and model architecture specifics are not provided, requiring further clarification.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "For the state-of-the-art time-series forecasting project, you are mandated to conceive and implement a highly-advanced model using the extensive, multi-layered Traffic dataset. This dataset encompasses diverse, high-dimensional time series data with complex temporal patterns (96 observation snapshots, each containing 862 features, INPUT_SEQ_LEN=96, INPUT_DIM=862). Your mission involves not only constructing a cutting-edge model but also devising a novel algorithm that performs extensive multi-step ahead predictions (PRED_SEQ_LEN=96) while accounting for intricate non-linear dependencies, long-range correlations, and handling anomalies in real-time. You must ensure exceptional predictive prowess, optimizing both mean squared error (MSE) and mean absolute error (MAE) metrics, while tackling the challenges of multi-seasonalities and potential drifts within the data sequences. Additionally, provide a comprehensive design blueprint, including feature engineering techniques, model architecture details, and sophisticated regularization strategies, to ensure robustness and explainability in the forecasting process.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"transportation\",\n        \"description\": \"The user is looking to build a state-of-the-art time-series forecasting model for a multi-layered Traffic dataset. The dataset has high-dimensional time series with complex temporal patterns, 96 observation snapshots, and 862 features. The goal is to develop a model for multi-step ahead predictions (96 steps), addressing non-linear dependencies, long-range correlations, and real-time anomaly handling. Performance is focused on optimizing MSE and MAE, while accounting for multi-seasonalities and data drifts. The response should include a detailed design blueprint for feature engineering, model architecture, and regularization strategies.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean squared error (MSE)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute error (MAE)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Traffic dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 862\n            },\n            \"description\": \"A comprehensive dataset with high-dimensional, diverse, and multi-layered time series data, capturing complex temporal patterns and containing 96 observation snapshots.\",\n            \"preprocessing\": [\n                \"Handling multi-seasonalities\",\n                \"Data drift detection and correction\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Advanced State-of-the-Art\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_structure\": \"recursive or transformers-based\",\n                \"number_of_layers\": null,\n                \"nonlinearities\": null,\n                \"custom_algorithms\": \"for handling anomalies and multi-step predictions\"\n            },\n            \"description\": \"A highly-advanced model with novel algorithm for multi-step ahead predictions, designed to address complex temporal patterns, non-linear dependencies, and handle real-time anomalies in the Traffic dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Potential to incorporate: attention mechanisms, transformers, or state-space models\",\n        \"Account for long-range correlations using deep learning architectures\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"Principal Component Analysis (PCA)\",\n            \"Feature scaling (e.g., Min-Max scaling)\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"Hardware-accelerated inference (GPU, TPUs)\"\n        ],\n        \"demonstration\": \"Interactive dashboard showcasing forecast results and performance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided JSON response reflects the given instruction accurately, capturing the advanced model requirements, dataset characteristics, and performance metrics. The high expertise level implies the need for complex techniques like deep learning and advanced feature engineering. Some elements, such as the exact model architecture and feature engineering techniques, are left unspecified to invite creative input from the ML expert.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As the project director, you are now mandated to guide a cross-disciplinary AI research team to develop a sophisticated time-series forecasting system for the Electricity dataset. This dataset presents intricate challenges with multiple interdependent seasonalities, long-term trends, and dynamic short-term anomalies that need to be deciphered. Divide the data into train, validation, and test sets, with non-trivial input sequences extending to 168 timestamps (INPUT_SEQ_LEN=168) and rich 500-feature observations (INPUT_DIM=500). The model must not only predict the subsequent 288-step sequences (PRED_SEQ_LEN=288) but also exhibit exceptional robustness against outliers, seamless adaptability to diverse temporal patterns, and withstand autocorrelated noise. To ensure precision, implement state-of-the-art deep learning architectures, including LSTM with attention mechanisms, and optimize for accuracy with advanced performance measures such as symmetric mean absolute percentage error (SMAPE), mean absolute scaled error (MASE), and a rolling forecast window with a sliding window size of 32 for real-time evaluation. Your project should also incorporate a sensitivity analysis for hyperparameter tuning and a comparative study with baseline models.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy or utilities\",\n        \"description\": \"The objective is to develop a sophisticated time-series forecasting system for the Electricity dataset with complex challenges including multi-seasonality, long-term trends, dynamic short-term anomalies. The system must handle input sequences of 168 timestamps and 500 features, predict 288-step sequences, exhibit robustness against outliers, adaptability, and resistance to autocorrelated noise. Target performance metrics are SMAPE, MASE, and a real-time rolling forecast window of size 32.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"SMAPE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MASE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"robustness against outliers\",\n                \"value\": null,\n                \"unit\": \"\"\n            },\n            {\n                \"name\": \"adaptability to diverse temporal patterns\",\n                \"value\": null,\n                \"unit\": \"\"\n            },\n            {\n                \"name\": \"resistance to autocorrelated noise\",\n                \"value\": null,\n                \"unit\": \"\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Electricity dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 168,\n                \"INPUT_DIM\": 500\n            },\n            \"description\": \"A dataset with intricate challenges of interdependent seasonalities, long-term trends, and dynamic short-term anomalies, divided into train, validation, and test sets.\",\n            \"preprocessing\": [\"handling multi-seasonality\", \"feature engineering for outliers and noise reduction\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"LSTM with Attention Mechanisms\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"deep learning\",\n                \"optimizer\": \"state-of-the-art\",\n                \"attention_mechanism\": \"yes\"\n            },\n            \"description\": \"A time-series forecasting model leveraging LSTM with attention mechanisms to address complex patterns and maintain precision\"\n        }\n    ],\n    \"knowledge\": [\n        \"Hyperparameter tuning through sensitivity analysis\",\n        \"Comparative study with baseline models for performance evaluation\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"non-trivial sequence segmentation\", \"feature extraction for robustness\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"advanced deep learning libraries like TensorFlow or PyTorch\"],\n        \"demonstration\": \"real-time evaluation with a 32-step rolling forecast window\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is derived from the given instruction, capturing the essence of the project's goal, dataset characteristics, model requirements, and performance objectives. The expertise level is set to 'high' due to the complexity of the task and the use of advanced techniques. The missing values in performance metrics and complexity metrics denote room for optimization and tuning. A clear path for handling different aspects of the project is provided.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "Develop a cutting-edge Hierarchical Attention U-Net (HAUNet) model tailored for underwater flora and fauna segmentation in the Little Things dataset, with an exclusive focus on microorganisms and subterranean organisms amidst varying water conditions. The model should incorporate real-time adaptive receptive fields and a novel context-aware loss function to address the intricacies of motion blur and illumination changes. Aim for a state-of-the-art F1 score of 90% and demonstrate improved performance in low-contrast scenarios, all while maintaining computational efficiency for real-world deployment on resource-constrained devices.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"environmental science\",\n        \"description\": \"The task is to develop a Hierarchical Attention U-Net (HAUNet) model specifically for underwater flora and fauna segmentation, with a focus on microorganisms and subterranean organisms. The model must handle varying water conditions, incorporate real-time adaptive receptive fields, and utilize a novel context-aware loss function to address motion blur and illumination changes. The objective is to achieve a state-of-the-art F1 score of 90% and demonstrate improved performance in low-contrast scenarios. Optimization for computational efficiency is necessary for deployment on resource-constrained devices.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1 score\",\n                \"value\": 0.9\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Computational efficiency\",\n                \"value\": null,\n                \"unit\": \"for real-world deployment on resource-constrained devices\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Little Things\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"microorganisms\", \"subterranean organisms\"],\n            \"specification\": {\n                \"type\": \"underwater imagery\",\n                \"conditions\": [\"variable water conditions\", \"low-contrast scenarios\"]\n            },\n            \"description\": \"A dataset for underwater flora and fauna segmentation, particularly focusing on microorganisms and subterranean organisms, with diverse water conditions and low-contrast scenes.\",\n            \"preprocessing\": [\"real-time adaptive receptive field incorporation\"],\n            \"augmentation\": [\"motion blur\", \"illumination changes\"],\n            \"visualization\": [\"demonstration of improved performance\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"HAUNet (Underwater)\",\n            \"family\": \"U-Net\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"real-time adaptability\": true,\n                \"novel loss function\": \"context-aware\"\n            },\n            \"description\": \"A highly specialized Hierarchical Attention U-Net designed for underwater flora and fauna segmentation, with an emphasis on microorganisms and subterranean organisms, targeting F1 score optimization and low-contrast performance.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"resource-constrained devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": {\n            \"conditions\": \"low-contrast scenarios, resource-constrained deployment\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure follows the schema and is based on the provided instruction. The problem area is specified as computer vision, with the HAUNet model and underwater flora and fauna segmentation. The metrics and model requirements are detailed, including a target F1 score and computational efficiency for deployment. The dataset is tailored to the task, and relevant preprocessing, augmentation, and source are included.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a visionary project director for a trailblazing AI research team, your mandate is to develop a highly sophisticated image analysis platform utilizing the advanced Fashion-MNIST dataset. The primary objective is to surpass a rigorous 95% accuracy benchmark in identifying fashion items, while ensuring robustness against diverse affine transformations. To distinguish your work, prepare a detailed, 2000-word technical report, which should:\n\n1. Deeply analyze the comparative performance of Capsule Networks versus Enhanced Residual CNN Architectures.\n2. Elaborate on the advantages and trade-offs of each method, highlighting their scalability and interpretability.\n3. Explore novel capsule network modifications to enhance resilience and feature extraction.\n4. Include extensive code snippets for both methodologies, annotated with theoretical explanations.\n5. Present visually compelling results using heatmaps and sensitivity analysis graphs.\n6. Critically evaluate the system's robustness through adversarial attacks and real-world scenarios.\n7. Formulate recommendations for future research and potential industrial applications.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"fashion industry\",\n        \"description\": \"The objective is to develop a highly sophisticated image analysis platform using the Fashion-MNIST dataset with the aim of achieving 95% accuracy in fashion item identification while being robust against diverse affine transformations. The project requires a detailed technical report of 2000 words with specific analysis and implementations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Fashion-MNIST\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"fashion_item\"],\n            \"specification\": {\n                \"image_shape\": [28, 28, 1]\n            },\n            \"description\": \"An advanced dataset for fashion item classification with diverse affine transformations.\",\n            \"preprocessing\": [\"affine transformations\"],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"heatmaps\",\n                \"sensitivity analysis graphs\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Capsule Networks vs. Enhanced Residual CNN Architectures\",\n            \"family\": [\n                \"Capsule Networks\",\n                \"Enhanced Residual CNNs\"\n            ],\n            \"type\": [\"neural networks\"],\n            \"specification\": {\n                \"Capsule Networks\": {\n                    \"accuracy\": null,\n                    \"scalability\": null,\n                    \"interpretability\": null\n                },\n                \"Enhanced Residual CNNs\": {\n                    \"accuracy\": null,\n                    \"scalability\": null,\n                    \"interpretability\": null\n                }\n            },\n            \"description\": \"A comparative study of the architectures.\"\n        }\n    ],\n    \"knowledge\": [\n        \"novel capsule network modifications for resilience and feature extraction\",\n        \"code snippets with theoretical explanations\",\n        \"robustness against adversarial attacks and real-world scenarios\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"exploring capsule network modifications\",\n            \"enhancing Residual CNN\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Methodologies with visual results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure mirrors the given instruction, with a clear focus on the project objective, dataset analysis, and model comparisons. The user's expertise level is high due to the complexity of the project. The target performance metric is set to 95%, though this may require optimization during implementation. The user has specified specific aspects to address, such as capsule network modifications and adversarial attacks, ensuring a comprehensive study.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "tabular classification", "instruction": "As a forward-thinking digital risk consultant in the luxury retail sector, I am tasked with revolutionizing the high-end fashion brand's approval process for luxury rental applications. Design a state-of-the-art machine learning model for tabular classification that assimilates intricate consumer data (past purchase behavior, social media influence, unique design preferences, and geographical exclusivity), aiming to surpass traditional luxury criteria with an F1 score of at least 0.95. The model must also exhibit interpretability, allowing domain experts to understand and fine-tune its decision-making logic.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"tabular data analysis\",\n        \"downstream_task\": \"tabular classification\",\n        \"application_domain\": \"luxury retail\",\n        \"description\": \"As a digital risk consultant, the goal is to design an advanced machine learning model for luxury rental application approval using consumer data like past purchase behavior, social media influence, design preferences, and geographical exclusivity. The model should achieve an F1 score of at least 0.95 and must have interpretability for domain experts.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1 score\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Luxury Retail Consumer Data\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"approval_status\"],\n            \"specification\": {\n                \"attributes\": [\n                    {\n                        \"name\": \"past_purchase_behavior\",\n                        \"description\": \"Consumer's past buying habits related to the luxury brand\"\n                    },\n                    {\n                        \"name\": \"social_media_influence\",\n                        \"description\": \"Influence on social media in the luxury fashion context\"\n                    },\n                    {\n                        \"name\": \"unique_design_preferences\",\n                        \"description\": \"Preferences for unique or exclusive designs\"\n                    },\n                    {\n                        \"name\": \"geographical_exclusivity\",\n                        \"description\": \"Geographical location's relevance for luxury retail rental\"\n                    }\n                ],\n                \"dimension\": \"custom\"\n            },\n            \"description\": \"A comprehensive dataset reflecting intricate consumer data for luxury rental application evaluation.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"interpretable machine learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"interpretability\": \"high\"\n            },\n            \"description\": \"A state-of-the-art machine learning model for tabular classification, designed for luxury retail rental applications with an F1 score of at least 0.95 and interpretability for domain experts.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"handling imbalances\", \"feature selection\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"secure cloud platform\",\n        \"inference_engine\": [\"real-time, serverless\"],\n        \"demonstration\": \"interactive model explanation dashboard\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is constructed based on the provided instruction, catering to a high-expertise user who requires a high-level solution for the luxury retail application. The area of focus is tabular data analysis, with the downstream task of tabular classification. The user emphasizes on achieving an F1 score of 0.95, interpretability, and a specific industry context. The dataset includes necessary details for model training, and requirements for deploying and fine-tuning the model are specified. Domain-specific techniques for preprocessing and feature engineering are incorporated.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "image classification", "instruction": "As a project manager for an advanced image classification project, I require a state-of-the-art machine learning model that can not only accurately classify domestic and exotic cat breeds, including ancient and recently extinct ones, but also identify individual cats based on their unique markings, unique behavioral patterns, and recognize crossbreeds with precision. The model must demonstrate exceptional accuracy in low-light conditions, handle extreme scale variations, and be robust to tilt, focus changes, and occlusions. Additionally, it must effectively differentiate between kittens, adult, and senior cats, all while accounting for cultural variations in coat patterns and grooming styles within a gargantuan, culturally diverse and continuously expanding dataset.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"animal sciences\",\n        \"description\": \"The project aims to develop a state-of-the-art machine learning model for classifying domestic and exotic cat breeds, including ancient and extinct ones, with a focus on individual recognition based on markings and behavioral patterns. The model must be accurate in low-light conditions, handle extreme scale variations, handle challenges like tilt, focus changes, and occlusions, and differentiate between kittens, adults, and seniors. It must also account for cultural variations in coat patterns and grooming styles on a large, diverse, and growing dataset.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"low-light classification accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"robustness to low-light conditions\",\n                \"value\": null,\n                \"unit\": \"performance\"\n            },\n            {\n                \"name\": \"handling extreme scale variations\",\n                \"value\": null,\n                \"unit\": \"adaptability\"\n            },\n            {\n                \"name\": \"tolerance to tilt, focus changes, and occlusions\",\n                \"value\": null,\n                \"unit\": \"robustness\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Custom Cat Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"breed\", \"individual马克ings\", \"behavioral_patterns\", \"age\"],\n            \"specification\": {\n                \"image_dim\": null,\n                \"image_depth\": null,\n                \"low_light_capacity\": true,\n                \"scale_varying\": true,\n                \"tilt_resilience\": true,\n                \"focus_change_resilience\": true,\n                \"occlusion_tolerance\": true\n            },\n            \"description\": \"A large, diverse, and growing dataset containing images of domestic and exotic cat breeds with varying markings, behavioral patterns, age groups, and cultural coat and grooming variations.\",\n            \"preprocessing\": [\n                \"image enhancement for low-light conditions\",\n                \"data augmentation for scale variations\"\n            ],\n            \"augmentation\": [\n                \"image rotation\",\n                \"focus manipulation\",\n                \"occlusion generation\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep convolutional neural networks (CNNs) or transformers\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"state-of-the-art\",\n                \"accuracy_tradeoff\": \"high\",\n                \"specific_features\": [\"low-light\", \"scale\", \"behavioral\", \"marking\", \"crossbreed\"]\n            },\n            \"description\": \"A deep learning model designed to handle complex cat image classification and individual recognition, even in challenging conditions.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Ancient and extinct cat breeds datasets may need to be sourced or fused with existing databases.\",\n        \"Behavioral patterns and grooming styles could be extracted using dedicated feature extraction techniques.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"embodied knowledge for cultural variations\",\n            \"behavioral feature extraction\"\n        ],\n        \"target_device\": \"cloud or high-performance hardware\",\n        \"deployment_endpoint\": \"a secure, scalable cloud-based platform\",\n        \"inference_engine\": [\"GPU-driven\", \"optimized for performance\"],\n        \"demonstration\": \"A user-friendly web interface showcasing model performance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the key elements of the project manager's instruction, detailing the complex requirements for a machine learning model in image classification. The high expertise level indicates a need for advanced techniques. Performance metrics and complexity constraints are clearly defined, and the dataset and model requirements reflect the challenging conditions and diversity.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a machine learning project manager for an avant-garde image classification research team, I've been commissioned to develop a groundbreaking project that redefines the limits of life form identification in cryptic deep-sea ecosystems. We've stumbled upon an encrypted trove of high-resolution images captured by next-generation remotely operated vehicles (ROVs), each frame revealing cryptic species of bioluminescent organisms, delicate edgelights, and elusive symbiotic relationships found in the Mariana Trench's darkest depths. Our novel objective is to create a sophisticated, bio-inspired deep neural network that not only distinguishes between various bioluminescent patterns, ethological behaviors, and host symbionts, but also estimates the ecological roles and population dynamics based on subtle visual cues. To tackle this, we must design a novel architecture combining convolutional, recurrent, and attention mechanisms, while addressing the constraints of extremely high-resolution data, variable biofluorescence intensity, and the need for interdisciplinary knowledge in marine biology and computer vision. The project manager must outline a comprehensive plan, including image segmentation and augmentation techniques, customized loss functions, and interpretability methods, all while navigating the ethical implications of studying rare and fragile ecosystems.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"marine biology\",\n        \"description\": \"The user is commissioning a project to develop a bio-inspired deep neural network for life form identification in deep-sea ecosystems. The focus is on recognizing bioluminescent patterns, ethological behaviors, host symbionts, estimating ecological roles, and population dynamics. The key challenges are high-resolution data, variable biofluorescence intensity, and the need for interdisciplinary knowledge between marine biology and computer vision.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"specificity\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 Score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory_usage\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Mariana Trench Cryptic Image Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\n                \"bioluminescent_patterns\",\n                \"ethological_behavior\",\n                \"host_symbionts\",\n                \"ecological_roles\",\n                \"population_dynamics\"\n            ],\n            \"specification\": {\n                \"image_resolution\": \"high\",\n                \"biofluorescence_variable\": true\n            },\n            \"description\": \"A collection of encrypted high-resolution ROV images revealing cryptic deep-sea biota, focusing on bioluminescent patterns, ethological features, and symbiotic relationships in the Mariana Trench's dark depths.\",\n            \"preprocessing\": [\n                \"image_segmentation\",\n                \"image_augmentation\"\n            ],\n            \"augmentation\": {\n                \"techniques\": [\"random cropping\", \"illumination variations\", \"biofluorescence intensity adjustments\"]\n            },\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"bio-inspired deep neural network\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"convolutional, recurrent, and attention mechanisms\",\n                \"novelty\": \"combines for ecological role estimation\",\n                \"custom_loss_functions\": true\n            },\n            \"description\": \"A deep neural network designed for advanced life form classification and analysis in cryptic deep-sea ecosystems, using bio-inspired techniques and addressing high-resolution constraints.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Interdisciplinary expertise in marine biology and computer vision required\",\n        \"Ethical considerations regarding rare and fragile ecosystem study\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"image preprocessing\",\n            \"feature extraction\"\n        ],\n        \"target_device\": \"high-performance computing environment\",\n        \"deployment_endpoint\": \"dedicated research platform\",\n        \"inference_engine\": [\n            \"TensorFlow\",\n            \"PyTorch\"\n        ],\n        \"demonstration\": \"development of interactive visualizations of model performance and insights\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately captures the user's intent for a complex deep learning project, addressing the specific challenges in high-resolution data, biofluorescence, and interdisciplinary knowledge. The performance metrics reflect the need for accurate classification and interpretablity, while complexity metrics target efficient computation. The response leaves room for optimization based on the specific constraints and requirements provided.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a project manager for an advanced ML team, you are now mandated to develop an avant-garde time-series forecasting model using the intricate and high-resolution ETTm2 dataset, partitioned into meticulously fine-tuned train, validation, and test partitions. The dataset's complexity mandates a sequence length restriction of 96 (INPUT_SEQ_LEN) and 7-dimensional inputs (INPUT_DIM), while the prediction horizon extends to 96 steps (PRED_SEQ_LEN) and 7 dimensions (PRED_DIM). The model must not only optimize for enhanced accuracy with lower MSE and MAE, but also exhibit exceptional adaptability to irregular patterns, effectively detecting and countering anomalies. Emphasize on introducing a groundbreaking feature extraction strategy, while adhering to a stringent new deadline of 40% reduction in training time compared to the pioneering projects, all while maintaining top-tier performance and resilience against outliers. Your team's success will significantly impact the industry, and careful attention to computational efficiency is mandatory.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"economics\",\n        \"description\": \"The project involves developing an advanced time-series forecasting model using the ETTm2 dataset with fine-tuned train, validation, and test partitions. The model must handle high-resolution, complex data with sequence length of 96, 7-dimensional inputs, and forecast horizon of 96 steps and 7 dimensions. The objective is to achieve high accuracy, minimize MSE and MAE, and exhibit adaptability to irregular patterns, anomaly detection, and resilience against outliers. Additionally, it must reduce training time by 40% compared to previous projects while maintaining computational efficiency.\",\n        \"performance_metrics\": [\n            {\"name\": \"accuracy\", \"value\": null},\n            {\"name\": \"MSE\", \"value\": null},\n            {\"name\": \"MAE\", \"value\": null}\n        ],\n        \"complexity_metrics\": [\n            {\"name\": \"training time\", \"value\": null, \"unit\": \"% reduction\"}\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ETTm2\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 7,\n                \"PRED_SEQ_LEN\": 96,\n                \"PRED_DIM\": 7,\n                \"complexity\": {\n                    \"high-resolution\": true\n                }\n            },\n            \"description\": \"A high-resolution ETTm2 dataset for time-series forecasting, with specific sequence length and input/output dimensions specified.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"num_layers\": null,\n                \"feature_extraction\": {\n                    \"type\": \"custom\",\n                    \"description\": \"Groundbreaking feature extraction strategy to handle irregular patterns and adaptability\"\n                },\n                \"computational_efficiency\": {\n                    \"training_speed\": \"40% reduction compared to previous projects\"\n                }\n            },\n            \"description\": \"An advanced time-series forecasting model designed for ETTm2 dataset, optimized for accuracy and computational efficiency.\"\n        }\n    ],\n    \"knowledge\": [\n        \"model resilience against outliers and anomaly detection\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Include a demonstration showcasing model performance and efficiency\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the instruction, including the high-level intent, the complex problem domain, and the specific requirements of the dataset and model. It also accounts for the emphasis on computational efficiency and the reduction in training time. The user's high expertise level is reflected in the task's intricacy.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "Task: Develop a specialized DeepLabV3+ variant for a cutting-edge fusion dataset, merging subatomic collision data and cryo-ET scans. Enhance the model's performance to identify intricate nuclear substructures with ultra-high accuracy, considering unique noise characteristics and rare distortions in PeView high-energy microscopes. Propose a transfer learning approach using lightweight interpretable models for real-time segmentation in scenarios with scarce annotated data, ensuring computational efficiency in the demanding environment of particle accelerators.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"particle physics\",\n        \"description\": \"The user wants to develop a specialized DeepLabV3+ model for a fusion dataset combining subatomic collision data and cryo-ET scans. The aim is to achieve ultra-high accuracy in identifying intricate nuclear substructures, while accounting for unique noise characteristics and rare distortions in PeView high-energy microscopes. The task suggests transfer learning with lightweight interpretable models for real-time segmentation, particularly for scenarios with limited annotated data, and emphasizes computational efficiency in particle accelerator environments.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"ultra-high accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"computational efficiency\",\n                \"value\": null,\n                \"unit\": \"FLOPs\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Fusion Dataset (subatomic collision and cryo-ET data)\",\n            \"modality\": [\"image\", \"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"unique noise characteristics\": {\n                    \"type\": \"description\",\n                    \"value\": \"unspecified\"\n                },\n                \"rare distortions in PeView microscopes\": {\n                    \"type\": \"description\",\n                    \"value\": \"unspecified\"\n                }\n            },\n            \"description\": \"A dataset combining subatomic collision data and cryo-ET scans, containing intricate nuclear substructure data with specific noise characteristics and distortions.\",\n            \"preprocessing\": [\"handling unique noise\", \"correcting rare distortions\"],\n            \"augmentation\": [\"data augmentation for scarce annotations\"],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"DeepLabV3+ (custom variant)\",\n            \"family\": \"neural networks\",\n            \"type\": \"convolutional neural networks\",\n            \"specification\": {\n                \"interpretability\": \"lightweight\",\n                \"transfer learning\": \"recommended\",\n                \"efficient for low-annotated data\": \"true\"\n            },\n            \"description\": \"A specialized DeepLabV3+ designed for real-time segmentation with high accuracy and interpretability in challenging particle accelerator conditions.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Interpretable models for domain understanding\",\n        \"Transfer learning strategies for limited data\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"embedded systems in particle accelerators\",\n        \"deployment_endpoint\": \"particle accelerator data stream processing\",\n        \"inference_engine\": [\"real-time, optimized for particle accelerator hardware\"],\n        \"demonstration\": \"showcase on ultra-high accuracy and computational efficiency in challenging scenarios\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response includes details based on the given instruction, including custom DeepLabV3+ for fusion dataset, computational efficiency, transfer learning, and interpretability for limited data in a particle accelerator environment. However, missing specific performance targets or units are left open for optimization. The confidence score is high given the context and addressed requirements.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "For the upcoming machine learning project, our focus is on implementing a node classification algorithm using the Heterogeneous Information Network (HIN) representation of the CiteSeer dataset. We'll preprocess the data to extract author collaborations and citation links, then train a Graph Convolutional Network (GCN) model. Expect improved multi-label classification accuracy compared to traditional text-based methods, driven by network topology and semantic embeddings.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"medium\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"academic research\",\n        \"description\": \"The project involves implementing a node classification algorithm using the Heterogeneous Information Network (HIN) representation of the CiteSeer dataset. The focus is on preprocessing data for author collaborations and citation links, and training a Graph Convolutional Network (GCN) model to improve multi-label classification accuracy compared to traditional text-based methods, leveraging network topology and semantic embeddings.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"multi-label classification accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"CiteSeer dataset (HIN)\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"node_labels\"],\n            \"specification\": {\n                \"preprocessed_data_types\": [\"author collaborations\", \"citation links\"]\n            },\n            \"description\": \"A Heterogeneous Information Network dataset for node classification, extracted from the CiteSeer dataset with focus on author collaborations and citation links.\",\n            \"preprocessing\": [\"data extraction\", \"HIN representation\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"GCN\",\n            \"family\": \"graph neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"type\": \"Graph Convolutional Network\"\n                },\n                \"inputs\": [\"Heterogeneous Information Network (HIN) data\"],\n                \"outputs\": \"Multi-label node classifications\"\n            },\n            \"description\": \"A Graph Convolutional Network model designed for node classification in a Heterogeneous Information Network, leveraging author collaborations and citation links from the CiteSeer dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Network topology and semantic embeddings enhance performance\",\n        \"Emphasis on improved accuracy compared to text-based methods\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"preprocessing for GCN\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Comparison with text-based methods\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response successfully captures the user's intentions, including the focus on a node classification project with a GCN model on the CiteSeer HIN dataset, extracting collaboration and citation data. The choice of multi-label classification accuracy as a performance metric aligns with the project's goal. However, there might be a need for further clarification on expected network complexity or specific model configurations for improved accuracy. The text-based methods comparison provides a clear point of contrast.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "The project now demands the creation of an advanced image recognition system for the Galaxy Zoo dataset, focusing on not only distinguishing celestial objects but also distinguishing them in extreme lighting conditions and various levels of noise. The Transformer-based Vision Transformer (ViT) should be enhanced with a domain-specific self-supervised pre-training, ensuring not only high accuracy but also resilience to occlusions and subtle variations, to streamline professional astronomers' scientific discovery processes.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"astronomy\",\n        \"description\": \"The user needs to develop an advanced image recognition system, particularly focusing on the Galaxy Zoo dataset. The system should handle extreme lighting conditions, noise, and be resilient to occlusions and subtle variations, using a Transformer-based Vision Transformer (ViT) with domain-specific self-supervised pre-training for improved accuracy and efficiency in professional astronomers' work.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"robustness to extreme lighting conditions\",\n                \"value\": null\n            },\n            {\n                \"name\": \"robustness to noise\",\n                \"value\": null\n            },\n            {\n                \"name\": \"resilience to occlusions\",\n                \"value\": null\n            },\n            {\n                \"name\": \"resilience to subtle variations\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Galaxy Zoo\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"specific_instruction\": \"For extreme lighting conditions, noise, occlusions, and subtle variations\"\n            },\n            \"description\": \"A dataset for advanced image recognition, focusing on celestial objects in challenging conditions, for the Vision Transformer (ViT) pre-training.\",\n            \"preprocessing\": [\"domain-specific data augmentation\"],\n            \"augmentation\": [\"extreme lighting, noise, and subtle variations\"],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Enhanced Vision Transformer (ViT)\",\n            \"family\": \"Transformer-based\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"pre-training_method\": \"domain-specific self-supervised\"\n            },\n            \"description\": \"An advanced image recognition system using ViT with enhancements for distinguishing celestial objects under extreme conditions and resilience to occlusions and variations.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Transformer-based architectures are suitable for image recognition tasks, especially with self-supervised pre-training.\",\n        \"Domain-specific pre-training is important for handling unique challenges like extreme lighting and subtle variations.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"Transformer adaptation for astronomy-related features\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for GPU or cloud-based deployment\"],\n        \"demonstration\": \"Demonstration of improved performance and accuracy under challenging conditions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is crafted based on the instruction, with the user's intent to build an advanced system, high expertise, focus on computer vision, and specific requirements for the Galaxy Zoo dataset and the Vision Transformer. It includes performance metrics for accuracy and domain-specific resilience, along with complexity metrics. The dataset description, model characteristics, and feature engineering steps reflect the given instruction. However, some elements like the target device and deployment specifics are not specified due to ambiguity in the instructions.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "Develop a domain-specific V-Net architecture for the challenging BraTS-18 dataset, focusing onglioblastoma sub-type segmentation. Aim for exceptional performance, with a Dice similarity coefficient of at least 0.90, and incorporate grad-CAM explainability to pinpoint tumor-specific feature attributions in real-time, ensuring clinician comprehension and model reliability in neuro-oncological decision-making.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"medical imaging\",\n        \"description\": \"The task is to develop a domain-specific V-Net architecture for the BraTS-18 dataset, targeting glioblastoma sub-type segmentation. The goal is to achieve exceptional performance with a Dice similarity coefficient of at least 0.90. Additionally, grad-CAM explainability is required for real-time tumor feature attribution and clinician comprehension in neuro-oncological decision-making.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"Dice similarity coefficient\",\n                \"value\": 0.90\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"BraTS-18\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"glioblastoma segmentation\"],\n            \"specification\": {\n                \"image modalities\": \"MRI\",\n                \"data format\": \"3D medical images\"\n            },\n            \"description\": \"A challenging dataset for glioblastoma segmentation, aiming to be segmented into sub-types for improved neuro-oncological decision-making.\",\n            \"preprocessing\": [\"3D image normalization\", \" skull stripping\"],\n            \"augmentation\": [\"rigid transformations\", \"elastic deformations\"],\n            \"visualization\": [\"slice-based segmentation results\", \"Grad-CAM explanations\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Domain-Specific V-Net\",\n            \"family\": \"3D Convolutional Neural Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"explainability_method\": \"grad-CAM\",\n                \"framework\": \"deep learning\"\n            },\n            \"description\": \"A deep learning V-Net designed specifically for glioblastoma segmentation on the BraTS-18 dataset, incorporating grad-CAM for real-time explainability.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"domain-specific feature extraction\"],\n        \"target_device\": \"workstation or specialized medical equipment\",\n        \"deployment_endpoint\": \"clinician-accessible platform\",\n        \"inference_engine\": [\"GPU-accelerated\"],\n        \"demonstration\": \"live patient scan analysis with visualization of segmentation and grad-CAM explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The given instruction was parsed into a JSON structure that reflects a complex machine learning project. The user's intent is to build a model, with a high level of expertise indicated. The area of focus is computer vision, and the task is a challenging image segmentation problem. The BraTS-18 dataset and its requirements (specific V-Net architecture, Dice similarity coefficient, and grad-CAM explainability) are included. Some preprocessing steps, augmentation, and deployment details are specified according to the given context. The absence of a low-confidence component implies that the information appears accurate and complete.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "machine translation", "instruction": "Develop a cutting-edge machine translation model for ancient Sanskrit to modern Mandarin, utilizing the highly specialized Buddhist Pali-Indic Parallel Corpus. The project should employ a hybrid of BERT-style transformer and Graph Neural Networks to not only ensure precise meaning preservation but also capture the nuanced philosophical concepts and poetic meter found in classical Sanskrit literature, while maintaining the colloquial expressiveness of modern Mandarin.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"linguistics\",\n        \"description\": \"The task is to develop a cutting-edge machine translation model for translating ancient Sanskrit to modern Mandarin, using the Buddhist Pali-Indic Parallel Corpus. The model should incorporate a hybrid of BERT-style transformers and Graph Neural Networks to maintain precision in meaning, capture nuanced philosophical concepts and poetic meter, and preserve colloquial expressiveness.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"semantic_similarity\",\n                \"value\": null\n            },\n            {\n                \"name\": \"preservation_of_philosophical_concepts\",\n                \"value\": null\n            },\n            {\n                \"name\": \"poetic_meter_preservation\",\n                \"value\": null\n            },\n            {\n                \"name\": \"colloquial_expressiveness\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_speed\",\n                \"value\": null,\n                \"unit\": \"per second\"\n            },\n            {\n                \"name\": \"memory_consumption\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Buddhist Pali-Indic Parallel Corpus\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"Sanskrit_to_Mandarin\"],\n            \"specification\": {\n                \"languages\": [\"Sanskrit\", \"Mandarin\"],\n                \"corpus_size\": null\n            },\n            \"description\": \"A specialized parallel corpus containing ancient Sanskrit and modern Mandarin translations for a deep understanding of cultural nuances.\",\n            \"preprocessing\": [\n                \"Tokenization\",\n                \"Normalization\",\n                \"Alignment\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Hybrid (BERT-style transformer and Graph Neural Networks)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_structure\": {\n                    \"transformer_layers\": null,\n                    \"GNN_layers\": null,\n                    \"attention_heads\": null\n                },\n                \"parameters\": {\n                    \"learning_rate\": null,\n                    \"batch_size\": null,\n                    \"epochs\": null\n                }\n            },\n            \"description\": \"A model for translating ancient Sanskrit to modern Mandarin, leveraging BERT transformers and Graph Neural Networks.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"description\": \"Ancient Sanskrit literature and its cultural context.\"\n        },\n        {\n            \"description\": \"Specificities of the Buddhist Pali-Indic Parallel Corpus and its unique challenges.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"Domain-specific embeddings\",\n            \"Contextualized translation\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Poetic and philosophical translation examples\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This JSON response captures the high-level details from the given instruction. It identifies the intent as building a sophisticated machine translation model, uses the appropriate NLP area, and details the hybrid model approach. The metrics include various aspects of quality. The dataset and preprocessing steps are specific to the provided corpus. The model requirements and domain-specific knowledge demonstrate a high-level understanding of the problem. The missing values indicate that these details would need to be filled based on specific requirements and research.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "As a seasoned project manager for the advanced satellite imaging project, you're tasked with deploying a state-of-the-art segmentation model for the Sentinel-2 dataset to classify intricate land features like precise waterbodies, dense forests, and bustling urban landscapes. The challenge lies in selecting a model with optimal efficiency, precision, and minimal computational time without compromising accuracy. Can you find a tailored solution that demonstrates fast and reliable results while pushing the boundaries of AI capabilities?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"remote sensing\",\n        \"description\": \"A project manager is seeking to deploy a state-of-the-art segmentation model for the Sentinel-2 satellite dataset. The focus is on classifying intricate land features like waterbodies, dense forests, and urban landscapes. The goal is to find a model with high efficiency, precision, minimal computational time, and competitive accuracy.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"efficiency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"computational_time\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory_size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Sentinel-2\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"waterbodies\", \"dense_forests\", \"urban_landscapes\"],\n            \"specification\": null, \n            \"description\": \"The Sentinel-2 satellite dataset for image segmentation, targeting land feature classification.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_complexity\": \"state-of-the-art\",\n                \"specificity\": [\"efficient\", \"low_latency\", \"high_accuracy\"]\n            },\n            \"description\": \"A tailored deep learning model for image segmentation, optimized for efficient and accurate classification of intricate land features in Sentinel-2 imagery.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The project emphasizes on the balance between computational efficiency and high performance.\",\n        \"State-of-the-art techniques might include using advanced architectures like Transformers or combining models for efficient inference.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized\", \"TensorRT\"],\n        \"demonstration\": \"demonstration of fast and reliable results on representative sample data\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response reflects the given instruction, specifying the high-level objective of model building and expert-level knowledge. The area is computer vision, with a focus on image segmentation for satellite data. Performance metrics include efficiency, precision, accuracy, and computational time. Some complexity metrics are mentioned, such as inference time and memory size. The model requirements and target variables are based on the project manager's need for a tailored solution.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "multimodal forgery detection", "instruction": "Utilize the 'Adversarial Poly-modal Forgery Dataset v2.0' for developing a cutting-edge model that merges advanced spoof-aware FaceNet with state-of-the-art VoCEncoder, differentiating genuine identities from manipulated audio-visual data. Optimize for high accuracy and real-time performance, ensuring robustness against deepfakes with minimal misidentification.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"multimodal forgery detection\",\n        \"application_domain\": \"security\",\n        \"description\": \"The user wants to develop a cutting-edge model using the Adversarial Poly-modal Forgery Dataset v2.0. The model should combine FaceNet for spoof-aware face recognition with VoCEncoder, differentiating genuine identities from manipulated audio-visual data. The goal is to achieve high accuracy and real-time performance with robustness against deepfakes, minimizing misidentification.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time performance\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"robustness against deepfakes\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Adversarial Poly-modal Forgery Dataset v2.0\",\n            \"modality\": [\"audio\", \"video\"],\n            \"target_variables\": [\"forged_or_genuine\"],\n            \"specification\": {\n                \"FaceNet compatibility\": true,\n                \"VoCEncoder compatibility\": true\n            },\n            \"description\": \"A dataset for detecting forged audio-visual data using FaceNet and VoCEncoder.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Advanced Multi-modal Forgery Detection Model\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"combination of FaceNet and VoCEncoder\",\n                \"customization\": \"spoof-aware\"\n            },\n            \"description\": \"A model designed to detect manipulated audio-visual data using advanced spoof-aware FaceNet and VoCEncoder.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Recent advances in multimodal deepfake detection necessitate a combination of audio and visual analysis.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"real-time compatible hardware\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for real-time\"],\n        \"demonstration\": \"Robustness tests and visual explanations for model predictions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This response covers the user's request for a high-performance multimodal forgery detection model. The provided JSON includes relevant details on the user's expertise, problem area, datasets, model specifications, and service requirements. The expert level is set to 'high' due to the complex task and desired optimization. However, specific performance targets are left unspecified for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "For our upcoming high-impact marketing event, we aim to leverage AI-driven image segmentation to precisely analyze individual expressions and body language in crowded, diverse scenes. Develop a custom deep learning model that distinguishes unique facial features and separates subjects from dynamic backgrounds with sub-pixel accuracy, ensuring maximum engagement insights.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"marketing\",\n        \"description\": \"The user wants to build a custom deep learning model for precise image segmentation in marketing, focusing on analyzing facial expressions and body language in crowded, diverse scenes with sub-pixel accuracy to enhance engagement insights for a high-impact marketing event.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"sub-pixel accuracy\",\n                \"value\": 1.0\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"FPS\"\n            },\n            {\n                \"name\": \"memory consumption\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"custom\",\n            \"modality\": [\"image\", \"multimodal\"],\n            \"target_variables\": [\"facial_features\", \"background\"],\n            \"specification\": {\n                \"dynamic_scenes\": true,\n                \"diverse_subjects\": true,\n                \"sub-pixel_classification\": true\n            },\n            \"description\": \"The custom dataset contains images with diverse scenes and crowded conditions, requiring precise facial feature segmentation and subject-background separation.\",\n            \"preprocessing\": [\"data augmentation\", \"image normalization\"],\n            \"augmentation\": [\"random cropping\", \"color jitter\"],\n            \"visualization\": [\"segmentation masks\", \"feature heatmaps\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Custom AI-Driven Image Segmentation Model\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"custom deep neural network\",\n                \"model_structure\": \"suitable for dynamic backgrounds and facial feature extraction\",\n                \"pixels_accuracy\": \"sub-pixel\"\n            },\n            \"description\": \"A deep learning model specifically designed for high-impact image segmentation in marketing scenarios, with a focus on sub-pixel accuracy for accurate engagement insights.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Understanding of diverse subjects and crowd dynamics is crucial.\",\n        \"Experience with handling real-time performance and resource constraints\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"emotion recognition enhancement\", \"pose estimation\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"custom application server\",\n        \"inference_engine\": [\"TensorFlow serving\", \"real-time inference\"],\n        \"demonstration\": \"Interactive dashboard for live event analysis\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction has been parsed into a JSON format, capturing the user's intent to build a model, their expertise level, the problem domain (computer vision), and the specific task (image segmentation). Performance and complexity metrics are included, along with requirements for preprocessing, augmentation, and model specifications. However, some information may be subject to further clarification, such as target accuracy values, real-time performance constraints, and the exact architecture details.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "image segmentation", "instruction": "As a machine learning project manager for the CoralNet+ mission, mandate the development team to design a novel PSPNet architecture incorporating underwater light adaptation and real-time adaptive resizing, ensuring minimal error for cryptic species in low-contrast scenarios while surpassing the previous best benchmark by at least 5%. Additionally, the model must integrate with a lightweight edge computing system for rapid response on remotely operated submersibles.", "resposne": "{\n  \"user\": {\n    \"intent\": \"build\",\n    \"expertise\": \"high\"\n  },\n  \"problem\": {\n    \"area\": \"computer vision\",\n    \"downstream_task\": \"image segmentation\",\n    \"application_domain\": \"aquatic environment monitoring\",\n    \"description\": \"The task is to design a novel PSPNet architecture specifically for underwater image segmentation, focusing on cryptic species in low-contrast scenarios. The model must adapt to underwater light conditions and have real-time adaptive resizing capabilities. The goal is to achieve at least 5% improvement over the current best benchmark while being compatible with lightweight edge computing systems for fast response on remote submersibles.\",\n    \"performance_metrics\": [\n      {\n        \"name\": \"accuracy\",\n        \"value\": null\n      },\n      {\n        \"name\": \"error_rate\",\n        \"value\": {\"comparison_type\": \"lower\", \"target_value\": 0.05}\n      }\n    ],\n    \"complexity_metrics\": [\n      {\n        \"name\": \"inference_time\",\n        \"value\": {\"unit\": \"milliseconds\", \"optimization_target\": \"fast\"},\n        \"unit\": \"milliseconds\"\n      }\n    ]\n  },\n  \"dataset\": [\n    {\n      \"name\": \"CoralNet+ (Underwater)\",\n      \"modality\": [\"image\"],\n      \"target_variables\": [\"cryptic_species\"],\n      \"specification\": {\n        \"adaptation\": \"underwater light adaptation\",\n        \"resize\": \"real-time adaptive\"\n      },\n      \"description\": \"Underwater image dataset for training and testing the novel PSPNet architecture, focusing on low-contrast scenarios and cryptic species.\",\n      \"preprocessing\": [\"light adaptation techniques\"],\n      \"augmentation\": [\"real-time resizing\"],\n      \"visualization\": [],\n      \"source\": \"user-upload\"\n    }\n  ],\n  \"model\": [\n    {\n      \"name\": \"CoralNet+ PSPNet\",\n      \"family\": \"PSPNet\",\n      \"type\": \"neural networks\",\n      \"specification\": {\n        \"light_adaptation\": true,\n        \"real_time_resizing\": true,\n        \"parameters\": \"optimized for underwater scenarios\"\n      },\n      \"description\": \"An advanced PSPNet architecture designed for underwater environments, targeting minimal error for cryptic species and real-time adaptability with lightweight edge computing integration.\"\n    }\n  ],\n  \"knowledge\": [\n    \"Consideration of coral and marine life color adaptation under water,\"\n  ],\n  \"service\": {\n    \"feature_engineering\": [\"lightweight implementation\"],\n    \"target_device\": \"edge computing system\",\n    \"deployment_endpoint\": \"remote submersibles\",\n    \"inference_engine\": [\"lightweight algorithms\"],\n    \"demonstration\": \"model performance on edge devices\"\n  },\n  \"confidence\": {\n    \"rationale\": \"The JSON response is constructed based on the provided instruction. The intent is 'build' as the user wants a new model. The problem area is 'computer vision' with the specific task of image segmentation. The accuracy and a 5% improvement over the benchmark are defined as performance metrics, and complexity is indicated through real-time inference and compatibility with edge computing. The CoralNet+ dataset and its requirements are also specified.\",\n    \"score\": 0.95\n  }\n}\n"}
{"task": "time-series forecasting", "instruction": "Utilize the most advanced deep learning technique, specifically the fusion of LSTMs and Exponential Smoothing, for short-term forecasting of daily mobile app DAUs. The model must incorporate seasonality aware Fourier features and incorporate real-time anomaly detection to ensure adaptability and robustness against outliers, while optimizing for MAPE with a weekly rolling validation window.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"mobile apps\",\n        \"description\": \"The task is to develop a short-term forecasting model for daily mobile app DAUs using the latest deep learning techniques, specifically a fusion of LSTMs and Exponential Smoothing. The model should incorporate seasonality-aware Fourier features, have real-time anomaly detection, and optimize for MAPE, with a weekly rolling validation window.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MAPE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"anomaly detection speed\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Mobile App DAUs\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"daily DAUs\"],\n            \"specification\": {\n                \"length\": \"short-term\",\n                \"seasonality\": true\n            },\n            \"description\": \"A time-series dataset with daily mobile app DAUs, requiring short-term forecasting and incorporating Fourier features.\",\n            \"preprocessing\": [\n                \"seasonality-aware Fourier transformation\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning\",\n            \"type\": \"LSTMs and Exponential Smoothing fusion\",\n            \"specification\": {\n                \"anomaly detection mechanism\": \"real-time\",\n                \"seasonality handling\": \"Fourier features\"\n            },\n            \"description\": \"A deep learning model combining LSTMs and Exponential Smoothing, designed for short-term mobile app DAU forecasting with seasonality awareness and real-time anomaly detection.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"weekly rolling validation\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for anomaly detection\"],\n        \"demonstration\": \"real-time performance monitoring\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is crafted based on the given instruction, which specifies a complex machine learning task that requires 'high' expertise. The 'build' intent is clear, with a focus on time-series analysis and optimizing for MAPE with a weekly validation window. The model details are carefully incorporated, including advanced techniques, anomaly detection, and Fourier features. The response captures necessary details but may require confirmation of performance metric targets and additional engineering steps.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Develop a highly specialized node classification model using the arXiv Quantum Physics dataset, leveraging a Quantum Walk based Graph Neural Network (QW-GNN). The task is to differentiate between various subfields of quantum theory with an exceptional accuracy of 95% while maintaining interpretability. Additionally, ensure the model's resilience in recognizing rare and obscure research topics within the dataset, all while optimizing for computational efficiency with limited computational resources.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"quantum physics\",\n        \"description\": \"The user is seeking to develop a highly accurate, specialized model for node classification within the arXiv Quantum Physics dataset using Quantum Walk based Graph Neural Networks (QW-GNNs). The model should have an exceptional accuracy of 95%, maintain interpretability, and be resilient in recognizing rare and obscure research topics while optimizing for computational efficiency under limited computational resources.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"computational efficiency\",\n                \"value\": null,\n                \"unit\": \"FLOPs\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"arXiv Quantum Physics dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"size\": {\n                    \"nodes\": null,\n                    \"edges\": null\n                },\n                \"features\": {\n                    \"node\": {\n                        \"dimensions\": null\n                    }\n                }\n            },\n            \"description\": \"A dataset for node classification within the arXiv Quantum Physics domain using Quantum Walk Graph Neural Networks, targeting high accuracy and interpretability.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"QW-GNN\",\n            \"family\": \"Quantum Walk based Graph Neural Networks\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"interpretability\": \"high\",\n                \"rare_topic_recognition\": \"yes\",\n                \"FLOPs\": null\n            },\n            \"description\": \"A highly specialized model leveraging Quantum Walk for node classification in the arXiv Quantum Physics dataset, aiming for 95% accuracy and computational efficiency.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"limited computational resources\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response adheres to the given JSON schema, capturing the user's intent to build a model with high-level expertise. It specifies the required node classification model using a QW-GNN on the arXiv Quantum Physics dataset. Performance requirements (95% accuracy), interpretability, and resilience for rare topics are included. Computational efficiency is indicated as a complexity metric. The dataset source is listed as a direct search. However, specific details such as the number of nodes and dimensions are missing and need to be confirmed or inferred from the dataset description.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "node classification", "instruction": "Develop a state-of-the-art node classification model for the arXiv Multi-disciplinary Collaboration Network, leveraging a Quantum-Inspired Graph Neural Network (QGNN) with entanglement regularization. The task is to predict not only individual authors' research areas but also to uncover hidden subfields within collaborations, ensuring high accuracy and interpretability while maintaining computational efficiency.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"academic research\",\n        \"description\": \"The goal is to develop a state-of-the-art node classification model for the arXiv Multi-disciplinary Collaboration Network, using a Quantum-Inspired Graph Neural Network (QGNN) with entanglement regularization. The model should predict both individual authors' research areas and uncover hidden subfields within collaborations, prioritizing high accuracy, interpretability, and computational efficiency.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability_score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory_usage\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"arXiv Multi-disciplinary Collaboration Network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"research_area\", \"subfield\"],\n            \"specification\": {\n                \"nodes\": {\n                    \"features\": {\n                        \"node_type\": \"author\",\n                        \"attributes\": {}\n                    },\n                    \"graph_structure\": {\n                        \"edge_type\": \"collaboration\"\n                    }\n                },\n                \"edges\": {\n                    \"edge_type\": \"quantum-inspired\",\n                    \"regularization\": \"entanglement\"\n                }\n            },\n            \"description\": \"A collaboration network representing arXiv authors and their multi-disciplinary connections, suitable for QGNN with entanglement regularization.\",\n            \"preprocessing\": [\"cleaning, feature extraction\"],\n            \"augmentation\": [\"edge perturbation\"],\n            \"visualization\": [\"graph structure, subfield clusters\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"QGNN\",\n            \"family\": \"Quantum-Inspired\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"architecture\": \"entanglement regularized\",\n                \"quantum-inspired learning\": true\n            },\n            \"description\": \"A state-of-the-art QGNN model for node classification, capable of detecting hidden subfields within collaborations.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"description\": \"Entanglement regularization enhances model expressiveness in capturing complex collaboration patterns.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"quantum-inspired features\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for quantum-inspired models\"],\n        \"demonstration\": \"visual explanations of clusters and subfields\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response covers the key aspects of the user's instruction, including the task (build), the use of a high-level expertise, the graph machine learning area, the focus on node classification, the arXiv dataset, the QGNN with entanglement, and the desired performance metrics and complexity constraints. The missing parts can be inferred or completed by further clarification from the user.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a highly skilled machine learning project manager, your objective is to develop an advanced time-series forecasting system for the \"Weather Intelligence\" dataset, which consists of intricate, real-world climate data spanning multiple dimensions (temp, humidity, etc.). The dataset is divided into non-overlapping subsets: an initial training period (covering 96 timestamps with 21 unique variables, INPUT_SEQ_LEN=96, INPUT_DIM=21), a validation set for model tuning, and a complex test phase. The challenge lies in forecasting future sequences of meteorological events (PRED_SEQ_LEN=96, PRED_DIM=21) with precision, using not only mean squared error (MSE) but also mean absolute percentage error (MAPE) as evaluation metrics. Your task is to design an innovative model that demonstrates superior performance and adaptability in capturing long-term patterns amidst seasonality and anomalies.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"climate science\",\n        \"description\": \"The objective is to develop an advanced time-series forecasting system using the Weather Intelligence dataset with intricate climate data. The task involves forecasting future sequences of meteorological events (96 timestamps, 21 variables) with high precision. Evaluation metrics include mean squared error (MSE) and mean absolute percentage error (MAPE). The focus is on designing an innovative model that can capture long-term patterns and adapt to seasonality and anomalies.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean squared error (MSE)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute percentage error (MAPE)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Weather Intelligence\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 21,\n                \"PRED_SEQ_LEN\": 96,\n                \"PRED_DIM\": 21\n            },\n            \"description\": \"A real-world climate data set with multiple dimensions (temp, humidity, etc.) split into train, validation, and test subsets, covering 96 timestamps each with 21 unique variables for input and prediction.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"advanced\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"specifics\": \"Model designed for long-term pattern capture and adaptability, considering seasonality and anomalies\"\n            },\n            \"description\": \"An innovative neural network model tailored for time-series forecasting, using the Weather Intelligence dataset to demonstrate superior performance in meteorological event forecasting.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Demonstration of model's ability to capture long-term patterns, seasonality, and adapt to anomalies.\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response reflects the requirements of a machine learning project as specified, focusing on the build intent and the high level of expertise. Problem area, downstream task, and metrics are derived from the instruction, with relevant data subset specifications and neural network model expectations.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "As a project manager, request the machine learning team to design a cutting-edge safety monitoring system for complex industrial settings. They should integrate the 'COCO' dataset with a proprietary industrial safety dataset, refining the existing Anchor-Free CNN architecture. The model must efficiently detect not only standard objects but also ensure the accurate detection of safety equipment conformity (with a per-class accuracy above 95%) and trip hazards, operating in real-time with minimal latency for uninterrupted workflow optimization.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"industrial safety\",\n        \"description\": \"The task is to design a cutting-edge safety monitoring system for complex industrial settings. The system should integrate the COCO dataset with a proprietary industrial safety dataset and enhance the Anchor-Free CNN architecture to not only detect standard objects but also ensure high accuracy (95%+) in detecting safety equipment conformity and trip hazards. Real-time operation with minimal latency for workflow optimization is a key requirement.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"per-class accuracy\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"real-time operation\",\n                \"value\": \"yes\",\n                \"unit\": \"\"\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": \"minimal\",\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"COCO dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"description\": \"A widely used dataset for generic object detection.\"\n            },\n            \"description\": \"A popular dataset for training object detection models.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        },\n        {\n            \"name\": \"Proprietary industrial safety dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"description\": \"Custom industrial safety-related features.\"\n            },\n            \"description\": \"An internal dataset containing industrial safety scenarios and equipment.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Enhanced Anchor-Free CNN\",\n            \"family\": \"CNN\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"description\": \"Refined for detecting safety equipment and trip hazards with improved accuracy.\"\n            },\n            \"description\": \"A state-of-the-art object detection model using Anchor-Free architecture, tailored for industrial safety.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"edge device\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"real-time\"],\n        \"demonstration\": \"uninterrupted workflow\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided information covers the core aspects of the machine learning project: designing a safety monitoring system, integrating datasets, refining a specific architecture, and performance metrics. The user's high expertise level and the request for real-time with minimal latency indicate the need for a complex and sophisticated solution. However, specific latency requirements, dataset details, and deployment details are not provided in the instruction, which might affect the completeness of the JSON representation.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "image classification", "instruction": "For a comprehensive sustainability initiative, design an advanced Landsat 8 satellite image classifier using the Vision Transformer (ViT) architecture. Focus on multi-scale feature extraction, interpretability, and domain adaptation to handle diverse landscapes and rare classes. The model must exhibit >96% accuracy, have fine-tuned transfer learning capabilities, be scalable to large geographic areas, and include in-depth performance reports, cloud deployment guidelines, as well as optimized resource management for cost-effective use.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"remote sensing, sustainability\",\n        \"description\": \"Design an advanced Landsat 8 satellite image classifier using the Vision Transformer (ViT) architecture, focusing on multi-scale feature extraction, interpretability, and domain adaptation. The model should achieve >96% accuracy, have fine-tuned transfer learning capabilities, be scalable, and include performance reports, cloud deployment details, and optimized resource management for cost-effectiveness.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.96\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"minutes\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Landsat 8 Satellite Images\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"classification\"],\n            \"specification\": {\n                \"image_size\": [null, null],\n                \"bands\": null,\n                \"scales\": \"multi-scale\"\n            },\n            \"description\": \"Landsat 8 data for satellite image classification using the Vision Transformer architecture\",\n            \"preprocessing\": [\n                \"multi-scale augmentation\"\n            ],\n            \"augmentation\": [\n                \"domain adaptation\"\n            ],\n            \"visualization\": [\"interpretability studies\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced Landsat 8 ViT Classifier\",\n            \"family\": \"Vision Transformer (ViT)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"transfer learning\",\n                \"feature_extraction\": \"multi-scale\",\n                \"interpretability\": true\n            },\n            \"description\": \"A satellite image classifier for Landsat 8 data with fine-tuned transfer learning and a target accuracy of >96%\"\n        }\n    ],\n    \"knowledge\": [\n        \"Domain adaptation for diverse landscapes and rare classes\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"transfer learning\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": {\n            \"service\": \"cloud deployment\"\n        },\n        \"inference_engine\": [\"optimized for cost-effective resource management\"],\n        \"demonstration\": \"in-depth performance reports\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON representation includes a high-level description of the project, specifying a 'build' intent, high expertise level, and detailed problem description. It covers the area of computer vision (specifically image classification) with a focus on ViT architecture, multi-scale feature extraction, and domain adaptation. Accuracy of >96% and scalability are key targets. The response is highly confident given the clear task description and the requirement for in-depth performance reports and cloud deployment.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "node classification", "instruction": "Utilize the specialized Mouse Brain Neurite Tractography dataset, collected from multiple genetic backgrounds, to develop a tailored GWNN model for distinct molecularly defined neuron subclass classification. Ensure high accuracy, especially for minor subtypes, while accounting for intricate spatial-temporal dynamics and pruning effects in the graph structure.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"neuroscience\",\n        \"description\": \"The task is to develop a tailored Graph Wavelet Neural Network (GWNN) model using the Mouse Brain Neurite Tractography dataset for molecularly defined neuron subclass classification, prioritizing high accuracy, particularly for minor subtypes, while considering the intricate spatial-temporal dynamics and pruning effects in the graph structure.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Mouse Brain Neurite Tractography\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"neuron_subclass\"],\n            \"specification\": {\n                \"nodes\": {\n                    \"genetic_backgrounds\": \"multiple\",\n                    \"spatial_temporal_dynamics\": true,\n                    \"pruning_effects\": true\n                },\n                \"edges\": {\n                    \"connectivity\": \"intricate\"\n                },\n                \"dimensions\": {\n                    \"node_features\": {},\n                    \"edge_features\": {}\n                }\n            },\n            \"description\": \"A dataset for mouse brain neurite tractography collected from diverse genetic backgrounds, focusing on spatial-temporal dynamics and pruning effects, for neuron subclass classification.\",\n            \"preprocessing\": [\"graph清理, normalization\"],\n            \"augmentation\": [],\n            \"visualization\": [\"node features, graph structure\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Custom GWNN\",\n            \"family\": \"Graph Wavelet Neural Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"tailored for neuron subclass classification\",\n                \"node_level_layers\": [\"spatial-temporal dynamics\", \"pruning effects\"],\n                \"graph_level_layers\": []\n            },\n            \"description\": \"A GWNN model designed to classify neuron subclasses in mouse brain data, accounting for specific graph structure and dynamics.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Spatial-temporal dynamics play a significant role in model design.\",\n        \"Pruning effects need to be considered for model performance in minor subtypes.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"neuroscience cloud platform\",\n        \"inference_engine\": [\"optimized for graph data\"],\n        \"demonstration\": \"neuron subclass prediction case studies\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response includes all necessary components from the user's instruction, such as the expert level, specific area (graph machine learning), and task (node classification). The Mouse Brain Neurite Tractography dataset and the tailored GWNN model are described based on the requirements. Metrics like accuracy and time complexity are considered, along with relevant details from the dataset and model specifications. Knowledge insights and final deployment steps are also included.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "link prediction", "instruction": "Can a non-trivial, scalable model be developed to forecast latent connections in the Citeseer citation network by considering publication timestamps and semantic similarity, while also accounting for authors' co-contributions and journal impact factors?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"link prediction\",\n        \"application_domain\": \"network analysis\",\n        \"description\": \"The user asks for the development of a scalable model to forecast latent connections in the Citeseer citation network. Key factors considered include publication timestamps, semantic similarity, co-contributions by authors, and journal impact factors.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Citeseer citation network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"latent_connections\"],\n            \"specification\": {\n                \"timestamp_feature\": true,\n                \"semantic_similarity_feature\": true,\n                \"author_co-contribution_feature\": true,\n                \"journal_impact_factor_feature\": true\n            },\n            \"description\": \"A graph dataset representing the Citeseer network, incorporating publication timestamps, semantic similarity, co-contributions, and journal impact factors.\",\n            \"preprocessing\": [\n                \"timestamp extraction and normalization\",\n                \"semantic feature extraction\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\"graph structure\", \"feature distributions\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"specific to consider temporal, semantic, author collaboration, and journal impact factors\",\n                \"scalability\": \"non-trivial and scalable\"\n            },\n            \"description\": \"A scalable neural network model designed for link prediction in the Citeseer citation network, leveraging timestamps, semantic similarity, co-contributions, and journal impact factors.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n        \"text\": \"Model should account for the dynamics of citation over time and the combined influence of authors and journals.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature engineering for temporal and categorical features\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"explainable AI results for selected connections\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction is parsed into a JSON response with the user's intention to build a model, high expertise level, and specific requirements for the graph machine learning task of link prediction in Citeseer. Performance metrics, model scalability, and factors to consider are clearly defined. The dataset is described with appropriate features and expected preprocessing steps. Missing information includes a detailed model architecture and specific deployment details.\",\n        \"score\": 0.9\n    }\n}\n"}
{"task": "time-series classification", "instruction": "The task at hand calls for the development of a state-of-the-art time-series classification model for a highly specialized application, utilizing the fNIRS (functional near-infrared spectroscopy) data from neonatal brain activity. The objective is to distinguish between sleep stages (REM, N1, N2, and awake) with unparalleled precision, targeting a precision of over 97%. The challenge lies in designing an ensemble model that integrates long short-term memory (LSTM) networks and extreme gradient boosting (XGBoost) while optimizing for speed with a novel attention mechanism. Additionally, the model must be deployable on resource-constrained wearable devices, maintaining a latency of less than 100 milliseconds for real-time monitoring of newborn sleep patterns. The project manager must collaborate with a cross-disciplinary team of neuroscientists, ML engineers, and hardware specialists to achieve this groundbreaking goal.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"neuroscience\",\n        \"description\": \"The task involves building a state-of-the-art time-series classification model using fNIRS data from neonatal brain activity. The objective is to classify sleep stages (REM, N1, N2, awake) with a precision target of over 97% using an ensemble model combining LSTM and XGBoost, while optimizing for speed with a novel attention mechanism. The model must be deployable on wearable devices with a latency of less than 100 milliseconds for real-time monitoring.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.97\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": 0.1,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": 0.1,\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Neonatal fNIRS Data\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"sleep stage\"],\n            \"specification\": null,\n            \"description\": \"fNIRS data from neonatal brain activity for sleep stage classification\",\n            \"preprocessing\": [\"feature extraction for LSTM and XGBoost integration\", \"normalization\"],\n            \"augmentation\": [],\n            \"visualization\": [\"neuroscientific relevance analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Ensemble Model (LSTM+XGBoost)\",\n            \"family\": \"neural networks and ensemble models\",\n            \"type\": \"ensemble models\",\n            \"specification\": {\n                \"architecture\": [\"LSTM layers\", \"Attention mechanism\", \"XGBoost ensemble\"],\n                \"speed_optimization\": true\n            },\n            \"description\": \"An ensemble model combining LSTM networks and XGBoost with an attention mechanism for high precision in neonatal sleep stage classification.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Collaboration with neuroscientists, ML engineers, and hardware specialists is essential.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"novel attention mechanism\"],\n        \"target_device\": \"wearable devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for low-latency\"],\n        \"demonstration\": \"Real-time monitoring of newborn sleep patterns with target latency less than 100 milliseconds\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure corresponds to the given user instruction, detailing the intent to build a machine learning model with a focus on precision and latency. The user's expertise level is assumed to be high due to the complexity of the task. The specified area, downstream task, and performance metrics align with the provided requirements. The ensemble model combining LSTM and XGBoost, with an attention mechanism, is justified based on the need for high precision and optimization for speed. The challenge of deploying on resource-constrained wearable devices and real-time monitoring is also reflected. The requirement for cross-disciplinary collaboration is mentioned.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "As the project manager, you've been assigned a unique task to revolutionize the sports broadcast experience by developing a cutting-edge object detection system. Your team is tasked with creating an advanced machine learning model that combines the Faster R-CNN architecture with a novel attention mechanism, specifically tailored for real-time detection of not only sports equipment but also rare and complex player maneuvers in extreme sports. This project requires the model to operate in extremely low-light conditions and exhibit exceptional robustness against occlusions, all while maintaining a processing speed suitable for 4K ultra-high-definition live feeds. The dataset for training should be a privately curated blend of 'Sports-1M', 'ExoticSportsData', and 'InfraredActionLibrary', ensuring comprehensive coverage of various sport types, environments, and athlete techniques. In addition to accuracy, provide a detailed analysis report on the model's performance in edge-case scenarios and an evaluation plan to measure its effectiveness during live broadcasts.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"sports broadcast\",\n        \"description\": \"Develop an advanced machine learning model combining Faster R-CNN with a novel attention mechanism for real-time detection of sports equipment and rare player maneuvers in extreme sports. The model must function in low-light conditions, handle occlusions, and support 4K live feeds. The dataset will be a custom blend of 'Sports-1M', 'ExoticSportsData', and 'InfraredActionLibrary', covering diverse sports, environments, and athlete techniques.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"robustness against occlusions\",\n                \"value\": null\n            },\n            {\n                \"name\": \"processing speed (for real-time 4K feeds)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time under low-light conditions\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"custom blend of Sports-1M, ExoticSportsData, and InfraredActionLibrary\",\n            \"modality\": [\n                \"image\"\n            ],\n            \"target_variables\": [],\n            \"specification\": {\n                \"comprehensive coverage\": \"various sports, environments, and techniques\",\n                \"low-light\": true,\n                \"occlusion handling\": true\n            },\n            \"description\": \"A privately curated dataset combining multiple sources for diverse object detection scenarios in extreme sports.\",\n            \"preprocessing\": [\n                \"low-light enhancement\",\n                \"occlusion simulation\"\n            ],\n            \"augmentation\": [\n                \"synthetic low-light conditions\",\n                \"occlusion scenarios\"\n            ],\n            \"visualization\": [\n                \"performance analysis in edge-case scenarios\"\n            ],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Faster R-CNN with novel attention mechanism\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"architecture details\": \"novel attention mechanism for sports equipment and rare maneuvers\",\n                \"low-light performance\": true,\n                \"real-time capable\": true\n            },\n            \"description\": \"A state-of-the-art model for real-time object detection of sports equipment and complex athlete actions in extreme sports conditions.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Designing for extreme low-light and occlusion resilience\",\n        \"Speed optimization for 4K ultra-high-definition live feeds\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"edge device optimized for low-power consumption\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-accelerated\", \"optimized for edge devices\"],\n        \"demonstration\": {\n            \"plan\": \"performance analysis during live broadcast trials\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The response reflects the project requirements from the instruction, including advanced object detection techniques, low-light performance, and evaluating in edge cases. Expertise is assumed to be high due to the complex task and multiple aspects to consider. Performance metrics are specified based on the mentioned requirements. The user's knowledge of edge-case scenarios and deployment strategy showcases the completeness of the response.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a machine learning project manager, your mandate is to develop an image classification system for skin cancer detection using the HAM10000 dataset, employing EfficientNet for its computational efficiency and high accuracy. The model should surpass a stringent benchmark of 97% AUC-ROC, targeting zero false negatives to ensure early detection's crucial role. Given the medical expertise of dermatologists, the model must provide interpretable explanations for each decision, enabling transparent and confident review of predictions. Additionally, ensure compliance with stringent healthcare regulations governing AI in diagnostics.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"medicine\",\n        \"description\": \"The project aims to develop an image classification system for skin cancer detection using the HAM10000 dataset. The target is to build a model, specifically with EfficientNet, achieving a benchmark of at least 97% AUC-ROC and zero false negatives to ensure early detection. The model must be interpretable for dermatologists and comply with healthcare AI regulations for diagnostics.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": 0.97\n            },\n            {\n                \"name\": \"False negatives\",\n                \"value\": 0\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"HAM10000 dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"skin_cancer\"],\n            \"specification\": {\n                \"image_size\": \"as per EfficientNet requirements\",\n                \"image_channels\": 3\n            },\n            \"description\": \"A dataset for skin cancer detection, employed to build an image classification system with EfficientNet for high accuracy.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"EfficientNet\",\n            \"family\": \"neural networks\",\n            \"type\": \"image classification\",\n            \"specification\": {\n                \"model_size\": \"suitable for computational efficiency\",\n                \"accuracy\": \"targeting 97%+\"\n            },\n            \"description\": \"An interpretable EfficientNet model for skin cancer detection, with a focus on high accuracy and compliance with medical regulations.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Interpretablity methods for medical decision-making\",\n        \"Healthcare AI diagnostics regulations\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"computational efficient for dermatology applications\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"Explainable AI\"],\n        \"demonstration\": \"Include model explanations and decision-making processes for predictions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction has been parsed into a JSON response that captures the key components: project type (build), expertise level (high), the area of computer vision, target task (image classification), dataset, EfficientNet model with specific performance requirements, interpretability, and compliance with healthcare regulations. The lack of explicit requirements for preprocessing, augmentation, or visualization has been left open, as these details are not specified in the instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "The project's objective is to develop a real-time, battery-efficient object detection model based on the tailored EfficientDet architecture, specifically targeting the iWildCam dataset. We need a model that differentiates between over 500 unique species in diverse wild landscapes, while maintaining high accuracy and minimizing computational resource consumption for seamless, remote deployment on rugged, energy-constrained devices.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"wildlife monitoring\",\n        \"description\": \"The objective is to create a real-time, battery-efficient object detection model based on the EfficientDet architecture for the iWildCam dataset. The model should classify over 500 unique species in various wild landscapes with high accuracy, while optimizing computational resources for deployment on remote, energy-limited devices.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mAP\",\n                \"value\": null\n            },\n            {\n                \"name\": \"FPS\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"ms\"\n            },\n            {\n                \"name\": \"memory consumption\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"iWildCam dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"species\"],\n            \"specification\": {\n                \"number_of_classes\": 500,\n                \"diverse_landscapes\": true\n            },\n            \"description\": \"A dataset for object detection in wild landscapes, targeting over 500 species.\",\n            \"preprocessing\": [\n                \"image resizing\",\n                \"data augmentation\"\n            ],\n            \"augmentation\": [\n                \"random cropping\",\n                \"color jitter\"\n            ],\n            \"visualization\": [\n                \"class-specific precision, recall, and confusion matrix\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"EfficientDet\",\n            \"family\": \"neural networks\",\n            \"type\": \"real-time object detection\",\n            \"specification\": {\n                \"architecture\": \"tailored EfficientDet\",\n                \"deployment_target\": \"rugged, energy-constrained devices\"\n            },\n            \"description\": \"An object detection model optimized for iWildCam dataset, with high accuracy and low computational footprint.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider pruning techniques and hardware acceleration for efficient inference.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"lightweight feature extraction\",\n            \"model pruning\"\n        ],\n        \"target_device\": \"remote, energy-constrained\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"lightweight inference libraries\"\n        ],\n        \"demonstration\": \"real-time object detection demonstration on simulated rugged devices\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response includes a clear intent to build a model ('build' intent) with high expertise level ('high'). The problem area is 'computer vision' with the downstream task of 'object detection' targeting the iWildCam dataset. Specifics such as classifying over 500 species and maintaining efficiency are captured in the description and requirements. Performance metrics (accuracy, mAP, and FPS) and complexity metrics (inference time and memory) are included. The dataset, model, and service sections match the requirements. Some scenarios for improving efficiency and demonstration are mentioned.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "The project manager seeks to develop a real-time, high-accuracy Dog Breed Identifier App using the challenging Stanford Dogs 120 breeds dataset. Evaluate the suitability of CNN architectures like ResNet or YOLOv5 for real-time image classification, considering computational efficiency and performance metrics like mAP and F1 score, ensuring minimal latency for user experience.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"mobile / real-time app\",\n        \"description\": \"The project aims to create a real-time Dog Breed Identifier App using the Stanford Dogs 120 breeds dataset, with a focus on high accuracy and real-time performance.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mAP\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Stanford Dogs 120 breeds dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"breed\"],\n            \"specification\": {\n                \"number_of_classes\": 120,\n                \"image_shape\": {\n                    \"width\": null, \n                    \"height\": null, \n                    \"channels\": 3\n                }\n            },\n            \"description\": \"A challenging dataset for real-time image classification of 120 dog breeds.\",\n            \"preprocessing\": [\"resize for model compatibility\"],\n            \"augmentation\": [\"light data augmentation for real-time\"],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"ResNet\",\n            \"family\": \"CNN\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"efficiency\": \"real-time\",\n                \"performance\": \"high\",\n                \"FLOPs\": null\n            },\n            \"description\": \"A ResNet model for real-time dog breed classification, considering computational efficiency and mAP.\"\n        },\n        {\n            \"name\": \"YOLOv5\",\n            \"family\": \"CNN\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"efficiency\": \"real-time\",\n                \"performance\": \"high\",\n                \"FLOPs\": null,\n                \"mAP\": null\n            },\n            \"description\": \"A YOLOv5 model for real-time dog breed classification, optimized for computational efficiency and mAP.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consideration for hardware acceleration for real-time performance\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"mobile, edge computing\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU, possibly with TensorRT\"],\n        \"demonstration\": \"Real-time classification with minimal latency\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The given instruction has been parsed into JSON according to the schema. The user's intent is to build a real-time Dog Breed Identifier App, with a focus on high accuracy. Expertise level is set to high given the project requirements. Performance metrics include accuracy, mAP, and F1 score. Complexities involve real-time processing and minimal latency. CNN architectures like ResNet and YOLOv5 are suggested for evaluation. Some assumptions are made in terms of hardware acceleration and inference engine use.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "As the project manager for a high-profile research institution, we've been tasked with developing a state-of-the-art Deep Graph Infomax (DGI) model for node classification in the challenging PPI (Protein-Protein Interaction) dataset. The model must demonstrate exceptional robustness, achieving at least 92% micro-F1 score while combating label scarcity. Moreover, it should be optimized for memory efficiency, allowing real-time inference on resource-constrained edge devices without sacrificing accuracy. Additionally, the training process must complete within 90 minutes on a mid-range TPU, while also demonstrating effective transfer learning capabilities across multiple related domains.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"biomedical research\",\n        \"description\": \"The goal is to develop a Deep Graph Infomax (DGI) model for node classification on the PPI dataset, targeting exceptional robustness with a minimum micro-F1 score of 92% in the presence of label scarcity. The model should prioritize memory efficiency for real-time inference on edge devices without compromising accuracy, and must train within 90 minutes on a mid-range TPU. Transfer learning capabilities across related domains are also required.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"micro-F1 score\",\n                \"value\": 0.92\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"memory efficiency\",\n                \"value\": null,\n                \"unit\": \"efficient for edge devices\"\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": {\n                    \"train_speed\": null,\n                    \"inference_speed\": \"real-time\"\n                },\n                \"unit\": \"minutes\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"PPI dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"node_labels\"],\n            \"specification\": {\n                \"label Scarcity\": true\n            },\n            \"description\": \"Challenging PPI dataset for node classification task with emphasis on protein-protein interaction data.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Deep Graph Infomax (DGI)\",\n            \"family\": \"neural networks\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"memory_efficiency\": true,\n                \"transfer_learning\": true\n            },\n            \"description\": \"A high-performance DGI model for node classification in PPI dataset, optimized for real-time inference on edge devices and with at least 92% micro-F1 score.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Label scarcity is a challenge, emphasizing the need for robust and efficient model design.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"edge devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TPU\"],\n        \"demonstration\": \"leveraging transfer learning for related domains\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is built upon the given instruction, detailing the requirements clearly. The user's high expertise level is indicated, and the project's details, including the task (node classification with DGI), dataset (PPI), and performance metrics, are in alignment with the instruction. The model's characteristics, such as memory efficiency and real-time inference, are specified based on the requirements. However, specific metric values are not included as they are not provided in the input.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series classification", "instruction": "As a machine learning project manager for a cutting-edge research firm, you've been tasked with a novel and complex time-series classification challenge. The team must tackle the \"Eco-Friendly Power Grid Forecasting\" dataset, which contains an unprecedented five-years of real-world smart grid data collected from various renewable energy sources (like solar, wind, and hydro) and energy consumption patterns. The dataset has been meticulously preprocessed and organized into a train, validation, and test set, with each sequence representing a week-long period (SEQUENCE_LENGTH=3,650, FEATURESandelim=32).\n\nThe input sequences consist of advanced features, including historical energy production, weather patterns, and power demand, leading to a high-dimensional feature space (INPUT_SEQ_LEN=720, INPUT_DIM=50). Your objective is to develop a state-of-the-art time-series classifier that can accurately forecast not only the primary energy source but also the likelihood of seamless grid integration and potential demand fluctuations. The model should achieve a minimum requirement of 92% overall accuracy, with a special focus on minimizing false predictions during peak demand hours.\n\nIn this project, the evaluation will involve not only standard accuracy but also a weighted F1-score for different energy sources and a resilience metric to measure the model's robustness against outliers in the data. The team must present a detailed report on model explainability and explain how their approach handles seasonality and non-linear patterns inherent in the time-series data.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"energy and utilities\",\n        \"description\": \"A complex time-series classification task requires a state-of-the-art model for the 'Eco-Friendly Power Grid Forecasting' dataset, which involves predicting energy sources and grid integration resilience, with a focus on minimizing false predictions during peak demand hours. The dataset is preprocessed and has a high-dimensional feature space, including historical energy production, weather, and power demand.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.92\n            },\n            {\n                \"name\": \"weighted F1-score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"resilience metric (against outliers)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Eco-Friendly Power Grid Forecasting\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\n                \"primary_energy_source\",\n                \"grid_integration_likelihood\",\n                \"demand_fluctuation\"\n            ],\n            \"specification\": {\n                \"SEQUENCE_LENGTH\": 3650,\n                \"FEATURES CoreData\": 32,\n                \"INPUT_SEQ_LEN\": 720,\n                \"INPUT_DIM\": 50\n            },\n            \"description\": \"Five years of preprocessed smart grid data, including renewable energy sources (solar, wind, hydro), energy consumption, and high-dimensional feature space.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"state-of-the-art\",\n                \"processing\": \"coping with seasonality and non-linear patterns\"\n            },\n            \"description\": \"An advanced time-series classifier designed to forecast energy sources, grid integration, and demand fluctuations in the Eco-Friendly Power Grid, targeting a minimum 92% overall accuracy.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Model explainability will involve feature importance analysis and model interpretability techniques.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"robust to outliers during peak demand\"],\n        \"demonstration\": \"Model performance during peak demand hours and explanation of seasonality and non-linear pattern handling\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided information is parsed according to the schema, considering the user's high expertise level, the specified performance metric (92% accuracy), and the emphasis on handling seasonality and non-linearities. Details for model explainability, feature engineering, and evaluation are also included. However, specific values or model family are not provided, leaving room for further elaboration.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "community detection", "instruction": "As a novice in systems biology, I seek to construct a community detection algorithm using Graph Convolutional Networks (GCN) for a specific PPI network of Alzheimer's disease proteins. Can you guide me through a simplified but effective approach with practical code examples and considerations for interpretability?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"low\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"community detection\",\n        \"application_domain\": \"systems biology\",\n        \"description\": \"As a novice in systems biology, you need assistance in designing a community detection algorithm using Graph Convolutional Networks (GCNs) for a PPI network (Protein-Protein Interaction) related to Alzheimer's disease. The goal is a simplified but effective approach with practical code examples and considerations for interpretability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Alzheimer's disease PPI network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"protein_communities\"],\n            \"specification\": {\n                \"nodes\": {\"type\": \"integer\", \"description\": \"Number of proteins in the network\"},\n                \"edges\": {\"type\": \"integer\", \"description\": \"Number of protein interactions\"},\n                \"features\": {\n                    \"type\": \"array\",\n                    \"description\": \"Node features representing protein attributes\"\n                }\n            },\n            \"description\": \"A PPI network for Alzheimer's disease proteins, requiring GCN-based community detection.\",\n            \"preprocessing\": [\"feature scaling\", \"edge filtering\"],\n            \"augmentation\": [],\n            \"visualization\": [\"network visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"GCN for community detection\",\n            \"family\": \"Graph Convolutional Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"layers\": {\"type\": \"integer\", \"description\": \"Number of GCN layers\"},\n                \"learning_rate\": {\"type\": \"number\", \"description\": \"Initial learning rate\"},\n                \"interpretability_features\": {\"type\": \"array\", \"description\": \"Indicators for interpretability, e.g., attention mechanisms or node embeddings\"}\n            },\n            \"description\": \"Simplified yet effective GCN model for detecting communities in the Alzheimer's PPI network\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"text\": \"For a beginner-friendly approach, consider using libraries like PyTorch Geometric or NetworkX, which have built-in GCN modules and interpretability tools.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            {\n                \"technique\": \"feature scaling\",\n                \"description\": \"Scaling node features for better convergence\"\n            }\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"online inference tools for small networks\", \"offline with explanations for interpretability\"],\n        \"demonstration\": \"Code snippets demonstrating model training and interpretability\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response adheres to the JSON schema, and the information captured reflects the user's intention to build a community detection algorithm with GCNs for Alzheimer's PPI data. It takes into account the user's novice level by emphasizing simplification and interpretability. Performance metrics and preprocessing steps are specified based on typical requirements for community detection tasks. Some code-related suggestions for interpretation and simplified approach are also included.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a project manager for the advanced machine learning team, you are now tasked with developing a highly-accurate, multi-step time-series forecasting system. Utilizing the Electricity dataset, which contains intricate, real-world patterns, split into train, validation, and test sets, the input sequences consist of historical data with a non-trivial length (96 timesteps x 321 features). The challenge expands to forecasting not just one but multiple future sequences (PRED_SEQ_LEN=96) while maintaining precision. The model must deliver exceptional performance in terms of mean squared error (MSE) and mean absolute error (MAE), while demonstrating robustness through rigorous hyperparameter tuning and iterative validation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy\",\n        \"description\": \"A multi-step time-series forecasting project is required to develop a highly accurate system for the Electricity dataset. The input sequences are historical data with 96 timesteps and 321 features, and the goal is to forecast multiple future sequences (PRED_SEQ_LEN=96) while optimizing for mean squared error (MSE) and mean absolute error (MAE). The emphasis is on robustness through hyperparameter tuning and iterative validation.\",\n        \"performance_metrics\": [\n            {\"name\": \"mean squared error\", \"value\": null},\n            {\"name\": \"mean absolute error\", \"value\": null}\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Electricity dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"length\": {\n                    \"train\": null,\n                    \"validation\": null,\n                    \"test\": null,\n                    \"PRED_SEQ_LEN\": 96\n                },\n                \"features\": {\n                    \"total\": 321,\n                    \"input_length\": 96\n                }\n            },\n            \"description\": \"An electricity dataset with intricate patterns split into train, validation, and test sets, featuring long historical sequences and multi-step forecasting task.\",\n            \"preprocessing\": [\n                \"Handling non-trivial sequence length\",\n                \"Normalization\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model architecture\": \"deep learning-based\",\n                \"hyperparameter_optimization\": \"iterative\"\n            },\n            \"description\": \"A highly-accurate deep learning model for multi-step time-series forecasting in the Electricity dataset.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature selection\",\n            \"windowing techniques\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized\"],\n        \"demonstration\": \"predictions and performance analysis on unseen data\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response reflects the given instruction accurately, capturing the project's objective as multi-step time-series forecasting, dataset specifics, and performance metrics (MSE and MAE). The need for hyperparameter tuning and iterative validation highlights the importance of model robustness. The dataset preprocessing and model architectural considerations align with a complex time-series analysis task. The proposed service details, such as target device and deployment, are yet to be specified in the instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "question answering", "instruction": "For the upcoming project, we aim to develop a cutting-edge question-answering platform tailored to early childhood literacy, utilizing the expanding PreSchoolPals KnowledgeBank. The team should design a model derived from the TinyTalesBERT architecture, enhancing its adaptability for age-appropriate language and context comprehension. To ensure accessibility, the system must incorporate a voice-controlled interface with animated storytelling elements and gamified learning experiences, promoting active exploration in pre-readers. Additionally, the system should incorporate a \"smart feedback\" feature that adaptively adjusts to each child's comprehension level and provides personalized learning recommendations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"education, early childhood literacy\",\n        \"description\": \"The project aims to develop a question-answering platform for early childhood literacy using the PreSchoolPals KnowledgeBank. The model should be based on the TinyTalesBERT architecture and adapted for age-appropriate language and context comprehension. The platform must include a voice-controlled interface, animated storytelling, gamification, and a 'smart feedback' feature adjusting to each child's comprehension level.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"adaptability_score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"response_time\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"inference_speed\",\n                \"value\": null,\n                \"unit\": \"queries per second\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"PreSchoolPals KnowledgeBank\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"questions\", \"context\"],\n            \"specification\": {\n                \"domain\": \"early childhood literacy\",\n                \"age-appropriate\": true\n            },\n            \"description\": \"A knowledge base focused on early childhood literacy, with age-appropriate content for the TinyTalesBERT adaptation.\",\n            \"preprocessing\": [\"age-based filtering\", \"language simplification\"],\n            \"augmentation\": [],\n            \"visualization\": [\"data distribution, context correlations\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"TinyTalesBERT\",\n            \"family\": \"BERT\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"enhanced for age-appropriate language and context comprehension\"\n            },\n            \"description\": \"A question-answering model derived from TinyTalesBERT, tailored for early childhood literacy with a focus on language adaptability.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Platform must cater to pre-readers, supporting voice control and animated storytelling.\",\n        \"Gamification and accessibility are essential for active exploration and engagement.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"smart feedback algorithm, personalization\"],\n        \"target_device\": \"mobile, voice-enabled devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"cloud-based, voice recognition\"],\n        \"demonstration\": \"voice interactions with age-appropriate stories and adaptive feedback\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately captures the user's intent to build a question-answering model, with a high level of expertise assumed. The problem area, NLP task, and specific adaptations are described. Performance metrics (accuracy, adaptability, response time), and complexity metrics (memory, inference speed) are included, reflecting the requirements. The dataset and model details are based on the information provided. The voice-controlled interface and educational features are crucial components, added in the 'service' section.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "multimodal forgery detection", "instruction": "The machine learning team needs to investigate the feasibility of employing state-of-the-art transformer architectures for a multi-modal forgery detection task, particularly focusing on the 'Celeb-DF' dataset. The challenge is to develop a sophisticated model that not only differentiates real videos from manipulated ones but also quantifies the degree of forgery with multiple reasoning steps, ensuring it outperforms base-level heuristics.", "resposne": "{\n    \"user\": {\n        \"intent\": \"consult-build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"multimodal forgery detection\",\n        \"application_domain\": \"security\",\n        \"description\": \"The team should investigate the use of state-of-the-art transformer architectures for detecting forgery in multi-modal data, specifically on the Celeb-DF dataset. The task is to develop a model that differentiates real videos from manipulated ones and provides a quantification of forgery severity, outperforming baseline heuristics.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"forgery detection precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"forgery detection recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"forgery severity quantification metric\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Celeb-DF\",\n            \"modality\": [\"image\", \"video\"],\n            \"target_variables\": [\"forgery_status\", \"forgery_severity\"],\n            \"specification\": null,\n            \"description\": \"A multi-modal dataset for forgery detection, containing real and manipulated videos of celebrities from the Celeb-DF dataset.\",\n            \"preprocessing\": [\"alignment across modalities\"],\n            \"augmentation\": [\"temporal and spatial\", \"sample mixing\"],\n            \"visualization\": [\"feature maps for interpretability\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Transformer-based Multi-modal Forgery Detection Model\",\n            \"family\": \"transformers\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"state-of-the-art transformer\",\n                \"steps\": \"multiple reasoning steps\",\n                \"outperforming_heuristics\": true\n            },\n            \"description\": \"A complex multi-modal model leveraging transformers to detect forgeries in videos and provide a quantification of forgery severity.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Latest transformer architectures such as MViT, M6, and M6-HiFi might be relevant\",\n        \"Transfer learning with pre-trained models like ViT, BERT, or existing multimodal architectures may be useful\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"fusion techniques\", \"contextual embeddings\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"customized for the organization's requirements\",\n        \"inference_engine\": [\"GPU-accelerated inference\"],\n        \"demonstration\": \"Interactive explanations of model predictions and detection confidence\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response covers the key aspects based on the instruction, including the inquiry on 'consult-build' for a complex problem in multimodal forgery detection. The user's high expertise level suggests a need for more advanced analysis. Performance metrics cover detection accuracy, precision, recall, and severity quantification. Transformer models, Celeb-DF dataset specifics, and strategies for outperforming heuristics are all represented.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "Design a visually immersive VQA model using the COCO-Concepts dataset and a state-of-the-art M6 Visual Transformer, targeting fine-grained comprehension of multi-modal events, object interactions, and subject attributes in historical scenes. Aim for a competitive F1 score of 75% and incorporate a novel evaluation metric for social context awareness.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"artificial intelligence\",\n        \"description\": \"Design a visually immersive VQA model using the COCO-Concepts dataset and the M6 Visual Transformer for fine-grained understanding of multi-modal events, object interactions, and subject attributes in historical scenes. The goal is to achieve a competitive F1 score of 75% and include a new evaluation metric for social context awareness.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1 score\",\n                \"value\": 0.75\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"COCO-Concepts\",\n            \"modality\": [\"image\", \"text\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"dataset_domain\": \"historical\",\n                \"scene_interactions\": true,\n                \"object_attributes\": true\n            },\n            \"description\": \"A multimodal dataset for visual question answering focusing on historical scenes, events, and object interactions.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"M6 Visual Transformer\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"state_of_the_art\": true,\n                \"architecture\": \"M6 Transformer\"\n            },\n            \"description\": \"A state-of-the-art VQA model, utilizing the M6 Visual Transformer, designed for the COCO-Concepts dataset to handle fine-grained comprehension of historical scenes.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"include novel social context awareness demonstration\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The given instruction parsed successfully into JSON. It highlights building a VQA model using the COCO-Concepts dataset and M6 Visual Transformer. The target F1 score of 75% and the need for a novel social context awareness evaluation metric are incorporated. Expertise level is assumed to be high due to the complexity of the task. Some specifics such as exact model name and model parameters are missing but can be inferred from the context.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "machine translation", "instruction": "As a project manager for an innovative translation technology venture, your team has been assigned to develop a cutting-edge, resource-efficient Quechua-Spanish translation tool. Targeting the underexplored JW300 corpus, opt for a tailored LSTM architecture with advanced attention mechanisms, ensuring semantic retention and cultural sensitivity. The model must excel in capturing linguistic intricacies, targeting a substantial BLEU score of 35 or above, while maintaining an optimized design for seamless mobile execution on diverse devices with limited computational capabilities.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"cross-lingual communication\",\n        \"description\": \"The project aims to develop a resource-efficient Quechua-Spanish translation tool using a tailored LSTM architecture with advanced attention mechanisms. The focus is on semantic retention and cultural sensitivity, targeting the JW300 corpus. The model should achieve a BLEU score of 35 or above and be optimized for mobile devices with limited computational capabilities.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"BLEU score\",\n                \"value\": 35\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Model efficiency for mobile devices\",\n                \"value\": \"optimized\",\n                \"unit\": \"computational capabilities\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"JW300 corpus\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"quechua\", \"spanish\"],\n            \"specification\": {\n                \"corpus_type\": \"undiscovered JW300 corpus\",\n                \"lingual_domain\": \"Quechua-Spanish\"\n            },\n            \"description\": \"A corpus for developing a Quechua-Spanish translation tool using LSTM with attention mechanisms, targeting linguistic intricacies.\",\n            \"preprocessing\": [\"Advanced text cleaning, tokenization, and vocabulary extraction\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Custom LSTM with Attention\",\n            \"family\": \"neural networks\",\n            \"type\": \"sequence to sequence\",\n            \"specification\": {\n                \"architecture\": \"tailored LSTM with advanced attention mechanisms\",\n                \"target_device\": \"mobile\",\n                \"computational_requirements\": \"low\"\n            },\n            \"description\": \"An efficient LSTM-based model with attention for Quechua-Spanish translation, optimized for resource-constrained mobile devices.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Cultural sensitivity is a key aspect for Quechua-Spanish translation to ensure accurate representation of both languages.\",\n        \"Leveraging LSTM with attention mechanisms enhances semantic retention in the translated output.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"Linguistic feature extraction, fine-tuning\"],\n        \"target_device\": \"mobile\",\n        \"deployment_endpoint\": \"potentially edge or mobile-first deployment\",\n        \"inference_engine\": [\"optimized for limited computational resources\"],\n        \"demonstration\": \"Mobile app showcasing translation results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response covers the requested project development task, incorporating a high-level understanding of the user's expertise. The area and task are specified, along with necessary metrics, dataset specifics, model architecture, and the overall aim for cultural sensitivity and mobile optimization. However, specific model hyperparameters or target BLEU score (if not directly tied to LSTM-attention design) are not included in the 'specification' portion. This is a reasonable assumption based on the instruction, as the BLEU score target is provided as a performance metric, not model characteristics.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "Design an advanced, explainable AI-driven image classification model utilizing the novel MViT (MixedVision Transformer) architecture, which not only differentiates between genders and age groups but also discerns subtle emotional cues and ethnicity from a diverse set of underrepresented cultural backgrounds in low-light facial images with varying expressions. The model should achieve state-of-the-art accuracy while maintaining interpretability and compliance with privacy regulations for age estimation, ensuring fairness in algorithmic biases.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"security/privacy\",\n        \"description\": \"Design an explainable AI model using the MViT (MixedVision Transformer) architecture for advanced image classification in low-light facial images. The model should classify gender, age groups, emotional cues, and distinguish among underrepresented ethnicities, while maintaining high accuracy, interpretability, and addressing privacy concerns for age estimation and fairness in algorithmic biases.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": \"high\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"privacy_compliance\",\n                \"value\": \"high\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"gender\", \"age_groups\", \"emotional_cues\", \"ethnicity\"],\n            \"specification\": {\n                \"low_light_images\": true,\n                \"diverse_cultural_backgrounds\": true,\n                \"expressions\": \"varying\"\n            },\n            \"description\": \"A dataset of underrepresented low-light facial images with varying expressions, targeting advanced gender, age, emotional cue, and ethnicity classification.\",\n            \"preprocessing\": [\"low-light image enhancement\"],\n            \"augmentation\": [\n                \"lighting conditions\",\n                \"pose variations\",\n                \"expression changes\"\n            ],\n            \"visualization\": [\n                \"Grad-CAM for interpretability\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"MViT-based Image Classifier\",\n            \"family\": \"neural networks\",\n            \"type\": \"transformers\",\n            \"specification\": {\n                \"explainable\": true\n            },\n            \"description\": \"An advanced, explainable AI model employing MViT, designed for image classification tasks with a focus on privacy and fairness.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"privacy_regulations\": \"GDPR for privacy compliance\",\n            \"bias_reduction_strategies\": \"using fairness-oriented data augmentation and regularizers\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"fairness analysis\",\n            \"bias mitigation techniques\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"privacy-preserving deployment platform\",\n        \"inference_engine\": [\"interpretable\"],\n        \"demonstration\": \"case studies demonstrating AI fairness and interpretability\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is constructed based on the provided instruction, covering all required components. Intent is to 'build', with expertise set to 'high' due to the complexity of the task. The model requirements align with the instruction: advanced, explainable, and privacy-compliant MViT for image classification. Metrics include accuracy, interpretability, and privacy compliance, reflecting the task's goals. The dataset description specifies low-light, diverse cultural backgrounds, and varying expressions. Missing details like model name and dataset name can be provided by the user.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "For the upcoming \"Artisanal Antiquities and Threat Analytics\" (AATA) project, the machine learning team is mandated to develop a highly specialized YOLOv5-based object detection model. The model must distinguish between intricate ancient artifacts, replicas, and potential threats like concealed weapons or unauthorized tools. It should be trained exclusively on a confidential, multi-source dataset composed of high-resolution museum artifact images and encrypted security records. The system must maintain an impressive real-time performance, with an accuracy above 95% and a stringent speed requirement of executing 200 object detections per second, ensuring negligible false positives (<0.05%) to guarantee seamless museum operations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"artificial intelligence, security\",\n        \"description\": \"The task is to develop a highly specialized YOLOv5-based object detection model for the 'Artisanal Antiquities and Threat Analytics' project. The model should differentiate between ancient artifacts, replicas, and potential threats (e.g., concealed weapons or unauthorized tools) using a confidential multi-source dataset of high-resolution artifact images and encrypted security records.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"speed (detections per second)\",\n                \"value\": 200,\n                \"unit\": \"detections\"\n            },\n            {\n                \"name\": \"false positive rate\",\n                \"value\": 0.0005\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"real-time performance\",\n                \"value\": true\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"AATA Multi-source Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"artifacts\", \"replicas\", \"potential threats\"],\n            \"specification\": {\n                \"image_resolution\": \"high-resolution\",\n                \"source_types\": [\"museum artifact images\", \"encrypted security records\"]\n            },\n            \"description\": \"A confidential dataset for training the YOLOv5 object detection model, containing images and encrypted security records, focusing on ancient artifacts, replicas, and security threats.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"YOLOv5\",\n            \"family\": \"neural networks\",\n            \"type\": \"object detection\",\n            \"specification\": {\n                \"architecture\": \"YOLOv5\",\n                \"target_object_classes\": [\"ancient artifacts\", \"replicas\", \"potential threats\"]\n            },\n            \"description\": \"A YOLOv5 model tailored for the AATA project, designed to achieve >95% accuracy, 200 detections per second, and <0.05% false positive rate.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"real-time inference (GPU or specialized hardware for optimal performance)\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for real-time object detection\"],\n        \"demonstration\": {\n            \"requirements\": \" Smooth and seamless museum operations with minimal disruptions.\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The response accurately captures the essence of the AATA project's requirements, with the user's high expertise level and the emphasis on object detection using YOLOv5. Performance metrics, including accuracy, speed, and false positive rate, are clearly specified. The dataset is described as confidential, multi-source, and of high resolution. The real-time performance is reflected in the chosen deployment endpoint and inference engine.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "visual question answering", "instruction": "Develop a cutting-edge VQA system utilizing the scarce and diverse VHR-Anthropocene dataset, which combines prehistoric and paleoart images, merging ancient human activities with ecological landscapes. Utilize a unique fusion of a Graph Neural Network and an advanced ALBEF transformer for enhanced scene understanding, pay special attention to deciphering implicit relationships between extinct species and tools, and achieve a benchmark precision of 80% in recognizing subtle cultural symbolism. Additionally, devise a methodology to assess the model's ability to identify and interpret subtle shifts in societal dynamics within the ancient context.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"anthropology and paleontology\",\n        \"description\": \"The task is to develop a state-of-the-art Visual Question Answering (VQA) system specifically for the VHR-Anthropocene dataset, which combines prehistoric and paleoart images. The system should focus on enhancing scene understanding by integrating a Graph Neural Network and an advanced ALBEF transformer, particularly emphasizing the detection of implicit relationships between extinct species and tools. The performance should aim for a benchmark precision of 80% in recognizing cultural symbolism. An additional requirement is to design a methodology for assessing the model's ability to identify and interpret societal dynamics shifts in ancient contexts.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.8\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"VHR-Anthropocene\",\n            \"modality\": [\"image\", \"text\"],\n            \"target_variables\": [\"image_labels\", \"cultural_symbols\"],\n            \"specification\": {\n                \"ancient_content\": true,\n                \"diverse_images\": true,\n                \"unique_combination\": true\n            },\n            \"description\": \"A dataset combining prehistoric and paleoart images, with a focus on capturing ancient human activities and ecological landscapes, suitable for VQA with a Graph Neural Network and ALBEF transformer.\",\n            \"preprocessing\": [],\n            \"augmentation\": [\n                \"graph-based augmentations\",\n                \"contextual text augmentation\"\n            ],\n            \"visualization\": [\"model performance on specific aspects\"],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"GNN-ALBEF fusion\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"architecture\": [\"Graph Neural Network\", \"ALBEF transformer\"],\n                \"attention_mechanism\": [\"scene understanding\", \"relationship extraction\"],\n                \"specific_features\": [\"ancient species-tool relationships\"]\n            },\n            \"description\": \"A cutting-edge VQA model that fuses GNN and ALBEF for enhanced scene understanding of prehistoric and paleoart images.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Ancient symbolism and societal dynamics are interrelated concepts; need to incorporate proxy signals or indirect evidence to interpret societal shifts.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"domain-specific feature extraction\",\n            \"contextual embedding\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-based\", \"optimized for resource-constrained environments\"],\n        \"demonstration\": \"Qualitative and quantitative performance analysis on specific questions and societal dynamics\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON accurately captures the instruction, indicating a build project, with high-level expertise required. The problem area, task, and datasets are well-defined. The model combines GNN and ALBEF with specific performance metric. The evaluation includes societal dynamics assessment. However, some details like deployment specifics may need to be obtained from the user if not already clear in their instructions.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "The mission for the ML team is to create a cutting-edge, real-time object detection system using a highly-optimized EfficientDet variation. This model should not only detect and classify over 500 distinct species in challenging wildlife scenarios, but also adapt dynamically to lighting conditions and terrain. The algorithm must deliver exceptional precision, achieve sub-10ms inference on minimalistic hardware, and be specifically designed for low-power, long-duration deployment in remote and rugged environments where device autonomy is paramount. Ensure a comprehensive evaluation of the model's robustness and energy efficiency through extensive benchmarking.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"wildlife conservation\",\n        \"description\": \"The ML team is tasked with developing a real-time, efficient object detection system based on an optimized EfficientDet variant. The model must detect and classify over 500 species, handle challenging wildlife scenarios, adapt to lighting and terrain, achieve sub-10ms inference on minimal hardware, and prioritize energy efficiency for long-duration deployment in remote environments.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"inference_time\",\n                \"value\": {\n                    \"unit\": \"ms\",\n                    \"value\": 10\n                },\n                \"optimization_goal\": \"sub-10\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"energy_efficiency\",\n                \"value\": null,\n                \"unit\": \"energy consumption per detection\"\n            },\n            {\n                \"name\": \"device_power\",\n                \"value\": null,\n                \"unit\": \"watts\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Wildlife Challenging Scenarios\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"species\", \"challenging_conditions\"],\n            \"specification\": null,\n            \"description\": \"A dataset containing real-world wildlife scenarios for extensive training, validation, and benchmarking, with emphasis on handling diverse lighting and terrain conditions.\",\n            \"preprocessing\": [\"lighting normalization\", \"terrain adaptation\"],\n            \"augmentation\": [\"real-time domain randomization\"],\n            \"visualization\": [\"performance analysis under varying conditions\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"EfficientDet Variant\",\n            \"family\": \"EfficientDet\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_complexity\": \"optimized\",\n                \"species_classes\": 500,\n                \"detection_capabilities\": \"real-time, dynamic adaptation\"\n            },\n            \"description\": \"A state-of-the-art object detection model optimized for efficient detection and classification in challenging wildlife scenarios, with a focus on precision, sub-10ms inference, and low power consumption.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"fine-tuning for low-power hardware\"],\n        \"target_device\": \"minimalistic hardware, low-power\",\n        \"deployment_endpoint\": \"remote/rugged environments\",\n        \"inference_engine\": [\"real-time engine for low-latency\"],\n        \"demonstration\": \"robustness and energy efficiency benchmarking\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response captures the essence of the user's instruction, identifying the intent to build a state-of-the-art object detection system, focusing on efficiency, performance, and hardware compatibility. The JSON structure adheres to the provided schema, detailing the problem in the 'problem' section and the specific requirements for model and dataset in the 'model' and 'dataset' sections respectively. The performance metrics and complexity constraints are specified, and the final 'service' section outlines the deployment and evaluation needs. The expert level of the user is assumed to be high given the complex task requirements.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a project manager in a specialized medical imaging ML team, your task is to design an advanced skin lesion classification system for Melanoma subtype detection using the HAM10000 dataset, leveraging state-of-the-art EfficientNet-B7 architecture. The model must not only achieve a superlative benchmark of 99.5% AUC-ROC and zero false positives to minimize misdiagnosis, but also incorporate Explainable AI (XAI) techniques such as GradCAM for pixel-level interpretability. Ensure adherence to ICD-O-3 coding standards and GDPR regulations, as the model will collaborate with expert dermatologists for real-time consultation in clinics.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"medical imaging\",\n        \"description\": \"Design an advanced skin lesion classification system for Melanoma subtype detection using the HAM10000 dataset. The system should utilize EfficientNet-B7 architecture and target an AUC-ROC benchmark of 99.5% with zero false positives to minimize misdiagnosis. Additionally, it must incorporate Explainable AI techniques, specifically GradCAM for pixel-level interpretability, while adhering to ICD-O-3 coding standards and GDPR regulations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": 0.995\n            },\n            {\n                \"name\": \"False Positive Rate\",\n                \"value\": 0.0\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"HAM10000\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"lesion_type\"],\n            \"specification\": {\n                \"architecture\": \"EfficientNet-B7\",\n                \"domain\": \"skin lesion classification\"\n            },\n            \"description\": \"A dataset for Melanoma subtype detection, suitable for the EfficientNet-B7 architecture.\",\n            \"preprocessing\": [\n                {\n                    \"method\": \"skin tone normalization\"\n                }\n            ],\n            \"augmentation\": [\n                {\n                    \"method\": \"GAN-based augmentation for enhanced diversity\"\n                }\n            ],\n            \"visualization\": [\n                {\n                    \"method\": \"GradCAM for pixel-level interpretability\"\n                }\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"EfficientNet-B7 for Melanoma Detection\",\n            \"family\": \"EfficientNet\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"accuracy\": \"AUC-ROC = 99.5%\",\n                \"interpretability\": \"with GradCAM\"\n            },\n            \"description\": \"A state-of-the-art deep learning model for Melanoma subtype detection, leveraging the EfficientNet-B7 architecture with built-in Explainable AI for ICD-O-3 and GDPR compliance.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Adherence to ICD-O-3 coding standards and GDPR regulations\",\n        \"Collaboration with expert dermatologists\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"clinics for real-time consultation\",\n        \"inference_engine\": [\"explainable AI enabled\"],\n        \"demonstration\": \"Interactive system showcasing GradCAM for interpretability\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is derived from the provided instruction, capturing the intent to build a high-performing model, the level of expertise, and the specific requirements for the task, dataset, and model. Performance metrics are defined, as are complexity considerations. The inclusion of AI techniques like GradCAM and regulatory compliance align with the given context. The confidence score is high given the comprehensive nature of the provided structure.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "object detection", "instruction": "As a forward-thinking project manager, your mandate is to propel the realm of sports broadcasting into the future by designing an avant-garde, real-time object detection system. Your interdisciplinary team, specializing in cutting-edge machine learning, must ingeniously integrate the state-of-the-art Mask R-CNN++ architecture with an adaptive multi-scale attention mechanism. The focus is not only on pinpointing conventional sports gear but also capturing intricate, unexplored moves in niche and high-speed extreme sports under challenging conditions like zero-illumination and heavy occlusions. The system must maintain superlative latency for seamless 8K resolution live streaming, even amidst signal interruptions. The training data, a secretive fusion of 'Sports-10Billion', 'InfraredExtremeSportarchive', and 'EsotericAthleteManeuversDataset', guarantees extensive diversity in sport genres, environmental variables, and advanced athlete techniques. Accompanying this project are in-depth performance benchmarks in edge-case scenarios, stringent stress-testing protocols, and a live broadcast readiness assessment protocol to guarantee the model's resilience and game-changing impact on viewership.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"sports broadcasting\",\n        \"description\": \"The task is to design a real-time, object detection system using Mask R-CNN++ with an adaptive multi-scale attention mechanism for sports broadcasting. It should handle niche and extreme sports under challenging conditions, with low latency for live 8K streaming even during signal interruptions. The dataset consists of 'Sports-10Billion', 'InfraredExtremeSportarchive', and 'EsotericAthleteManeuversDataset', focusing on diversity, extreme conditions, and advanced techniques.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency (inference time)\",\n                \"value\": null,\n                \"unit\": \"ms\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Sports-10Billion\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"data_fusion\": [\"Sports-10Billion\", \"InfraredExtremeSportarchive\", \"EsotericAthleteManeuversDataset\"]\n            },\n            \"description\": \"A secretive fusion of datasets providing diversity in sports genres, environmental conditions, and advanced athlete techniques.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Mask R-CNN++ with Adaptive Multi-Scale Attention\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"Mask R-CNN++\",\n                \"attention_mechanism\": \"adaptive multi-scale\"\n            },\n            \"description\": \"An advanced object detection model for sports broadcasting, designed to handle challenging conditions and niche sports.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The model should handle zero-illumination and heavy occlusions, and maintain superlative latency for live 8K streaming.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"edge device\",\n        \"deployment_endpoint\": \"live broadcasting platform\",\n        \"inference_engine\": [\"optimized for low-latency\"],\n        \"demonstration\": \"live broadcast readiness assessment protocol\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is based on the provided instruction, focusing on the advanced object detection system for sports broadcasting. The user's high expertise level, detailed description, and requirements for diverse datasets and specific model architecture are accounted for. Performance metrics are considered with a focus on latency and accuracy, and complexity metrics address the real-time and edge computing requirements. The project's live readiness assessment protocol is captured.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "link prediction", "instruction": "Develop a state-of-the-art, explainable machine learning model that not only predicts implicit links between academic papers in the arXiv math corpus, considering the distinct research topics, authors' collaboration history, and publication venue prestige, but also incorporates temporal dynamics and the authors' citation influence, while ensuring the model is interpretable and capable of handling large-scale data efficiently.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"link prediction\",\n        \"application_domain\": \"academic research\",\n        \"description\": \"The task is to develop a state-of-the-art explainable machine learning model for predicting implicit links between academic papers in the arXiv math corpus. Key factors to consider are research topics, authors' collaboration history, publication venue prestige, temporal dynamics, and citation influence. The model should prioritize interpretability and handle large-scale data efficiently.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"efficiency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"arXiv math corpus\",\n            \"modality\": [\"text\", \"graph\", \"time series\"],\n            \"target_variables\": [\"implicit_paper_links\"],\n            \"specification\": {\n                \"papers_count\": null,\n                \"topics_count\": null,\n                \"authors_count\": null,\n                \"publications_count\": null,\n                \"temporal_series_length\": null,\n                \"citation_influence_scale\": null\n            },\n            \"description\": \"A large-scale dataset consisting of academic papers from arXiv math corpus, with data on research topics, authors' collaborations, publication venues, temporal dynamics, and citation influence.\",\n            \"preprocessing\": [\"topic extraction\", \"graph construction\", \"temporal feature engineering\"],\n            \"augmentation\": [],\n            \"visualization\": [\"model explainability diagrams\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"state-of-the-art\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"explainable neural network\",\n                \"interpretability_techniques\": [\"attention mechanisms\", \"LIME\", \"SHAP\"],\n                \"scalability\": \"distributed learning, batch processing\"\n            },\n            \"description\": \"A highly interpretable model designed for large-scale link prediction in academic paper networks, utilizing neural networks and incorporating factors like research topics, collaboration history, venue prestige, temporal dynamics, and citation influence.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"name\": \"Domain familiarity\",\n            \"description\": \"Strong understanding of arXiv math corpus and academic paper networks\"\n        },\n        {\n            \"name\": \"Complexity trade-offs\",\n            \"description\": \"Awareness of the trade-offs between interpretability and model performance\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"AI platform or cloud-based hosting\",\n        \"inference_engine\": [\"GPU-based inference\"],\n        \"demonstration\": \"User-friendly interface for model predictions and interpretation\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is crafted based on the instruction, reflecting a high-level building task (expertise: 'high') and choosing graph machine learning for the area. The task is a link prediction problem within an academic paper context. Temporal dynamics and interpretability are key factors. Performance metrics are kept open-ended for optimization, and relevant complexity metrics are included. The dataset is assumed to be accessed through a link, while preprocessing, augmentation, and other details are inferred from common practices.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a seasoned project manager for a cutting-edge AI research team, your mandate is to engineer a highly sophisticated time-series forecasting system for the \"Weather Intelligence\" dataset. This dataset comprises a multidimensional, highly complex array of climate variables (temp, humidity, etc.) across numerous geographical locations and time intervals. The data, divided into distinct subsets (train with 96 timestamp sequences, INPUT_SEQ_LEN=96, and 21 unique feature dimensions, INPUT_DIM=21), a finely-tuned validation set, and a challenging test phase featuring intertwined seasonal trends, anomalies, and potential cross-variables dependencies.\n\nYour challenge is to devise a modular, deep-learning architecture that not only reduces forecast errors using mean squared error (MSE) but also outperforms existing methods with mean absolute percentage error (MAPE) as a stringent evaluation metric. The model should demonstrate superior skill in predicting multi-step meteorological events (PRED_SEQ_LEN=96, PRED_DIM=21), while maintaining adaptability in handling long-term patterns and unexpected weather patterns caused by climate change. Additionally, provide a detailed analysis plan to identify and account for the dataset's spatial heterogeneity and the impact of external factors.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"climate science\",\n        \"description\": \"The task involves designing a sophisticated time-series forecasting system for the Weather Intelligence dataset, which contains complex climate data with geographical and temporal variation. The system should use a deep-learning architecture to minimize MSE and MAPE, predict multi-step meteorological events with PRED_SEQ_LEN=96 and PRED_DIM=21, while being adaptable to long-term patterns and climate change-related anomalies. The analysis plan must address dataset heterogeneity and external factors.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean squared error\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute percentage error\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Weather Intelligence\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 21,\n                \"PRED_SEQ_LEN\": 96,\n                \"PRED_DIM\": 21,\n                \"spatial_division\": \"geographical locations\"\n            },\n            \"description\": \"A complex climate dataset with multidimensional data across various locations and time intervals, divided into train, validation, and test subsets.\",\n            \"preprocessing\": [\"handling missing data\", \"normalization\"],\n            \"augmentation\": [],\n            \"visualization\": [\"exploratory data analysis of time-series and spatial patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Modular Deep-Learning Time-series Forecasting Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"model architecture\": \"custom deep residual network with attention mechanism\",\n                \"optimizer\": \"Adam or L-BFGS\",\n                \"target metrics\": \"minimization of MSE and MAPE\"\n            },\n            \"description\": \"A deep-learning model designed to address the unique challenges of the Weather Intelligence dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Spatial heterogeneity might require geographical feature embeddings or hierarchical modeling.\",\n        \"External factors may include using external datasets on climate change drivers and incorporating them in the model\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature extraction from geographical data\", \"inter-variable analysis\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU accelerated\", \"cloud-based\"],\n        \"demonstration\": \"visual and quantitative performance comparisons with existing methods\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response has been created based on the given instruction, maintaining a high-level overview of the project's goal and specific technical requirements. Expertise level is set to 'high' due to the complexity and sophistication of the task. The response covers necessary aspects such as task, performance metrics, dataset, model details, and further steps. Performance metrics (MSE and MAPE) have been included, but no specific target values are provided to allow for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "Develop a cutting-edge time-series forecasting model by integrating LSTMs, Exponential Smoothing, and a novel hybrid approach that combines Fourier features with wavelet decomposition. Mandate the model to account for both short-term and long-term seasonality, implement a real-time, hybrid anomaly detection system, and consistently minimize MAPE with a dynamic weekly validation scheme that adjusts for data drift. Additionally, require the model to demonstrate interpretability by generating explainable feature contributions in the forecast.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"economics\",\n        \"description\": \"The task is to develop a cutting-edge time-series forecasting model using a hybrid approach combining LSTMs, Exponential Smoothing, Fourier features, and wavelet decomposition. The model must account for short-term and long-term seasonality, include a real-time hybrid anomaly detection system, and consistently minimize mean absolute percentage error (MAPE). A dynamic weekly validation scheme with data drift adjustment is required. Additionally, the model should demonstrate interpretability by generating explainable feature contributions in the forecast.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MAPE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Unspecified\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"time_frequency\": \"weekly\",\n                \"dynamic_data_drift\": true\n            },\n            \"description\": \"A time-series dataset that can be sourced for the development of the hybrid forecasting model, with real-time data and a weekly validation process adjusting for data drift.\",\n            \"preprocessing\": [\n                \"Fourier features\",\n                \"Wavelet decomposition\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hybrid Time-series Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"ensemble models\",\n            \"specification\": {\n                \"methods\": [\"LSTM\", \"Exponential Smoothing\", \"Fourier features\", \"Wavelet decomposition\"],\n                \"interpretability\": true\n            },\n            \"description\": \"An advanced time-series forecasting model combining LSTMs, Exponential Smoothing, Fourier features, and wavelet decomposition. It is designed for real-time application and has built-in feature interpretability.\"\n        }\n    ],\n    \"knowledge\": [\n        \"A novel hybrid approach is required to address complex seasonality and anomaly detection\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"Real-time anomaly detection\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"Supports streaming data and dynamic model updating\"\n        ],\n        \"demonstration\": \"Generated forecasts with explainable feature contributions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response represents the user's intent, their high-level expertise, and the requirements for the time-series analysis problem, including advanced modeling techniques, performance metric, and interpretability. Some details, such as specific model name and the source of the dataset, are left unspecified as per the provided instructions. Since the instruction provided is detailed, the confidence score is high.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a project director for an elite AI research team, your urgent mission is to design a state-of-the-art time-series forecasting model that employs the ultra-dense and high-frequency ETTm2 dataset, divided into meticulously fine-tuned strata for training, validation, and evaluation. The challenge lies in managing a complex data structure with inputs of 96-step sequences (INPUT_SEQ_LEN) and seven diverse dimensions (INPUT_DIM), while maintaining a 96-step prediction horizon (PRED_SEQ_LEN) with seven-dimensional outputs (PRED_DIM). The model must achieve unprecedented accuracy with minimal mean squared error (MSE) and mean absolute error (MAE), displaying exceptional adaptability to irregular patterns, especially in detecting and neutralizing anomalies.\n\nIncorporate a revolutionary feature extraction technique that combines deep learning and traditional signal processing methods. The project must meet a new, ambitious deadline of a 45% decrease in training time compared to previous projects, without compromising on performance resilience to outliers or sacrificing computational efficiency. Your team's breakthrough will redefine the industry standards, necessitating constant innovation and rigorous optimization of resource allocation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"economics/finance\",\n        \"description\": \"Design a state-of-the-art time-series forecasting model for the ultra-dense and high-frequency ETTm2 dataset. The data is divided into training, validation, and evaluation strata. The model must handle complex input with 96-step sequences and 7 dimensions, predict 96-step ahead with 7-dimensional outputs, and demonstrate high accuracy with minimal MSE and MAE. It should have a feature extraction technique combining deep learning and signal processing, reducing training time by 45% compared to previous projects, ensuring resilience to outliers and computational efficiency.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MSE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MAE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"training time reduction\",\n                \"value\": 0.45,\n                \"unit\": \"%\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ETTm2\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 7,\n                \"PRED_SEQ_LEN\": 96,\n                \"PRED_DIM\": 7\n            },\n            \"description\": \"A high-frequency dataset with complex structure, demanding a model adept at 96-step sequence predictions with 7-dimensional outputs.\",\n            \"preprocessing\": [\"deep learning and signal processing combination\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks (deep learning) and signal processing\",\n            \"specification\": {\n                \"optimization target\": \"resilience to outliers, computational efficiency\",\n                \"time complexity reduction\": \"45% compared to previous projects\"\n            },\n            \"description\": \"A state-of-the-art model designed for time-series forecasting, integrating deep learning and traditional signal processing methods, with a focus on adaptability and performance improvements.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"deep learning and signal processing techniques\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is built based on the given instruction, incorporating the requirements for an advanced model, the ETTm2 dataset, target performance metrics, and the novel feature extraction technique. The reduction in training time is explicitly mentioned as a key goal, without specifying exact values due to the challenge. The level of expertise is assumed to be high, given the project's complexity and requirements for industry-standard setting.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As the project lead for the AI Time-Series Forecasting Task, direct a specialized team to develop an advanced system tackling the Granger's Electricity Grid dataset. This unique dataset presents a complex fusion of multiple seasonality cycles with harmonics, evolving long-term trends, and intermittent short-term anomalies requiring nuanced pattern recognition. Organize the data into non-overlapping sets: historical training (1 year), validation (3 months), and testing (1 quarter), with input sequences stretching back 168 hourly readings (INPUT_SEQ_LEN=168) and including 500 volatile meteorological variables (INPUT_DIM=500). The system must forecast the subsequent 345 15-minute intervals (PRED_SEQ_LEN=345) with robustness against extreme data points, adaptive to irregular seasonal fluctuations, and resilient to serially correlated noise. Embrace cutting-edge deep learning techniques, like Hierarchical Attention-based LSTM, optimizing for enhanced accuracy through custom metrics like custom-weighted SMAPE, modified MASE accounting for rolling 32-hour forecast window, and real-time precision. Conduct a comprehensive hyperparameter sweep and rigorous comparison with advanced baselines like prophet and ARIMA to showcase substantial improvement.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy\",\n        \"description\": \"The AI Time-Series Forecasting project involves developing an advanced system for the Granger's Electricity Grid dataset with complex seasonality cycles, harmonics, long-term trends, and intermittent anomalies. The system should handle non-overlapping data splits (1 year for training, 3 months for validation, and 1 quarter for testing), input sequences of 168 hourly readings, and 500 meteorological variables. The focus is on forecasting the subsequent 345 15-minute intervals while being robust to extreme data points, seasonal variations, and serial correlations. Deep learning techniques, specifically Hierarchical Attention-based LSTM, should be employed, optimizing for custom metrics: custom-weighted SMAPE, modified MASE with a 32-hour rolling window, and real-time precision.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"custom-weighted SMAPE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"modified MASE (rolling 32-hour window)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time precision\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Granger's Electricity Grid\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 168,\n                \"INPUT_DIM\": 500\n            },\n            \"description\": \"A dataset with multiple seasonality cycles, harmonics, long-term trends, and anomalies, for electricity grid forecasting with 168 hourly readings and 500 meteorological variables.\",\n            \"preprocessing\": [\"handling multi-seasonality\", \"removal of serial correlations\"],\n            \"augmentation\": [],\n            \"visualization\": [\"analyzing variable importance\", \"temporal patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical Attention-based LSTM\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"model depth\": null,\n                \"number of layers\": null,\n                \"attention mechanism\": \"Hierarchical\"\n            },\n            \"description\": \"A deep learning model incorporating Hierarchical Attention-based LSTM, aimed at enhancing forecasting accuracy for the Granger's Electricity Grid dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Advanced baselines: prophet, ARIMA, and comparison analysis\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"handling complex seasonal patterns\",\n            \"extracting meteorological features\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"optimized for real-time performance\"\n        ],\n        \"demonstration\": \"comparison with baselines and custom metric improvements\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction clearly outlines a complex project with a high level of expertise required, focusing on a specialized LSTM model with deep learning techniques and custom performance metrics. The Granger's Electricity Grid dataset details, data splits, and desired properties for the model are directly translated into the JSON format. However, specific hyperparameter values or baseline model performance targets are not mentioned, which could be added for a more complete response.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "Construct a state-of-the-art video QA platform, utilizing the YouTube-8M dataset's sheer size and variety. Merge 3D CNNs and intricate Transformer models for advanced feature extraction, handling not only spatial complexity but also subtle visual cues. The system must exhibit unparalleled adaptability in niche and rapidly changing video domains, ensuring real-time responsiveness, high accuracy, and a continuous learning module that not only improves with time but also differentiates it from competitors by staying vigilant to emerging visual trends.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"media and entertainment\",\n        \"description\": \"The user desires to build a state-of-the-art video question answering platform using the YouTube-8M dataset. The system should employ advanced techniques like 3D Convolutional Neural Networks (CNNs) and Transformers for robust feature extraction, handling both spatial and subtle visual cues. Key requirements include real-time responsiveness, high accuracy, and a continuous learning module that adaptively learns from emerging visual trends.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time responsiveness\",\n                \"value\": null\n            },\n            {\n                \"name\": \"adaptability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"YouTube-8M\",\n            \"modality\": [\"video\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"size\": \"large\",\n                \"variety\": \"extensive\"\n            },\n            \"description\": \"A large and diverse video dataset for advanced video QA, leveraging YouTube-8M's extensive content.\",\n            \"preprocessing\": [\"3D CNN feature extraction\", \"Transformer-based feature merging\"],\n            \"augmentation\": [\"temporal and spatial\", \"subtle visual cue augmentation\"],\n            \"visualization\": [\"performance monitoring\", \"visual cues analysis\"],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"3D CNN-Transformer hybrid\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"3D CNN + Transformer\",\n                \"deep learning architecture\": \"explained in instruction\"\n            },\n            \"description\": \"A combination of 3D CNNs for spatial feature extraction and Transformers for intricate modeling, targeting high accuracy and adaptability.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"type\": \"emerging visual trends\",\n            \"description\": \"The platform should incorporate a continuous learning mechanism to adapt to new visual trends.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature extraction\",\n            \"modality fusion\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"high-performance video QA platform\",\n        \"inference_engine\": [\"real-time\", \"GPU-accelerated\"],\n        \"demonstration\": {\n            \"showcase\": \"live, demonstrative use cases demonstrating real-time responsiveness and trend adaptability\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response parses the given instruction by describing a high-end project to build a state-of-the-art video QA platform using YouTube-8M dataset and specifying requirements for advanced feature extraction, real-time performance, and continuous learning. Specific metrics for performance and complexity, as well as necessary procedures for service, are included.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "For the enhanced temporal analytics challenge, your machine learning team is mandated to design a state-of-the-art forecasting system using the intricate Traffic dataset, containing intricate, high-dimensional time series data with 96 observation points per sequence (INPUT_SEQ_LEN=96, INPUT_DIM=862). In addition to creating a model, propose a multi-layered algorithm that performs intricate, nested predictions over a extended horizon (PRED_SEQ_LEN=96), accounting for non-linear dependencies, rare events, and multiple seasonalities. The solution must not only showcase superior accuracy with Mean Squared Error (MSE) and Mean Absolute Error (MAE) but also include a resilience mechanism against outliers. Elaborate on the sophisticated architecture, advanced feature engineering, and a tailored training strategy that ensures optimal generalization on the non-trivially partitioned train, validation, and test sets.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"urban planning\",\n        \"description\": \"The task is to design a state-of-the-art forecasting system for an intricate Traffic dataset with high-dimensional time series data and 96 observation points per sequence. The algorithm should handle nested predictions over a 96-step horizon, account for non-linear dependencies, rare events, and multiple seasonalities. The solution should exhibit high accuracy with regards to MSE and MAE, and include a resilience mechanism against outliers. The model architecture, advanced feature engineering, and tailored training strategy should optimize generalization across train, validation, and test sets.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MSE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MAE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Inference Time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Traffic\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 862\n            },\n            \"description\": \"An intricate dataset with high-dimensional time series data, containing 96 observation points per sequence for the Traffic analysis.\",\n            \"preprocessing\": [\n                \"Outlier detection and handling\",\n                \"Feature scaling\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"Multiple seasonal patterns\",\n                \"Non-linear dependencies visualization\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"State-of-the-art forecasting system\",\n            \"family\": \"Neural networks (e.g., LSTM, GRU, or Transformer-based)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"Model architecture\": \"Multi-layer LSTM with nested architecture\",\n                \"Features\": \"Advanced feature engineering, including Fourier transforms and lagged features\",\n                \"Training strategy\": \"Customized training with early stopping, regularization, and adaptive learning rates\"\n            },\n            \"description\": \"A deep learning model specifically tailored for multi-step forecasting, handling non-linear dependencies, rare events, and multiple seasonalities with a resilience mechanism against outliers.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Advanced techniques such as anomaly detection for handling outliers\",\n        \"Accounting for multiple seasonalities using Fourier features\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"Temporal, frequency, and lags transformations\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"Advanced parallel or distributed inference\"],\n        \"demonstration\": \"Demonstration of forecasting results, error analysis, and resilience against outliers\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the given instruction, detailing a complex forecasting project with a high-level of expertise requirement. The area, task, dataset characteristics, and model requirements are derived from the provided information. The performance and complexity metrics are set up, acknowledging the need for advanced accuracy and robustness. Some assumptions on feature engineering and training strategy are made based on typical approaches for time-series forecasting tasks, as the instruction lacks specific details.\",\n        \"score\": 0.9\n    }\n}\n"}
{"task": "time-series classification", "instruction": "As a seasoned project manager for the Deep Ocean Turbulence Detection (DOTD) project, you're faced with a specialized challenge in real-world predictive maintenance. Your team's mission involves analyzing the 'Oceanographic Time-Series Extreme Events' dataset, gathered over 180 days (TIME_STEPS=94608) from a deep-sea sensor network with high-resolution measurements of 55 unique physical parameters (INPUT_DIM=55), including submersible pressure, thermodynamics, electrical conductivity, vortex dynamics, and minute tidal fluctuations. The classification challenge lies in forecasting six distinct health stages: optimal, incipient warning, minor anomaly, substantial risk, imminent failure, and catastrophic event, denoted by the numbers {0, 1, 2, 3, 4, 5}. It's imperative to develop an algorithm that leverages SMOTE for class balancing and integrates advanced time-series transformers like T-LSTM or C-DNN. Additionally, design an ensemble strategy, combining at least three models, to optimize performance on this intricate, ultra-dense data set, targeting an F1-score above 90% in the presence of complex temporal dependencies.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"oceanography, predictive maintenance\",\n        \"description\": \"The project aims to analyze the 'Oceanographic Time-Series Extreme Events' dataset for real-world predictive maintenance in deep ocean turbulence detection. The goal is to develop an algorithm that forecasts six health stages using T-LSTM or C-DNN, balancing classes with SMOTE, and employs an ensemble strategy of at least three models targeting an F1-score of 90% or higher, considering complex temporal dependencies.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1-score\",\n                \"value\": 0.9\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"time-series length\",\n                \"value\": 94608,\n                \"unit\": \"time_steps\"\n            },\n            {\n                \"name\": \"input dimensionality\",\n                \"value\": 55\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Oceanographic Time-Series Extreme Events\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"health stages: {0, 1, 2, 3, 4, 5}\"],\n            \"specification\": {\n                \"TIME_STEPS\": 94608,\n                \"INPUT_DIM\": 55\n            },\n            \"description\": \"Data collected over 180 days from a deep-sea sensor network with high-resolution measurements of 55 physical parameters related to ocean conditions.\",\n            \"preprocessing\": [\n                \"SMOTE for class balancing\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"ensemble\",\n            \"type\": [\"T-LSTM\", \"C-DNN\"],\n            \"specification\": {\n                \"model_type\": [\"time-series classification\", \"ensemble\"],\n                \"class_balancing\": \"SMOTE\",\n                \"ensemble_size\": {\n                    \"count\": 3,\n                    \"performance_goal\": \"F1-score: 90%\"\n                }\n            },\n            \"description\": \"An ensemble of T-LSTM and C-DNN models designed for time-series classification, targeting high F1-score with SMOTE for balanced class representation.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider complex temporal dependencies in data and use of advanced time-series transformers.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Focus on showcasing ensemble F1-score performance and temporal dependencies\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response accurately captures the user's context as a seasoned project manager, indicating high expertise. The problem domain, requirements, specific models and their complexities, as well as performance metrics, are clearly outlined based on the instruction. The SMOTE technique and ensemble strategy align directly with the need for balancing classes and optimizing performance. The F1-score target is stated explicitly.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "The urban smart parking initiative now demands the ML team to enhance M2Det, focusing on the specific 'Metropolitan Parkade and Lot' dataset. Integrate temporal patterns, seasonal variations, and develop a robust model robust to dawn-dusk shifts, nightfall, and challenging weather like fog and rain. Mandate a precision above 98% with median latency beneath 100 milliseconds, while including a comprehensive report examining the model's transfer learning performance across diverse locations and its real-time impact on traffic flow.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"urban smart parking\",\n        \"description\": \"The ML team is tasked with enhancing the M2Det model for the 'Metropolitan Parkade and Lot' dataset. The focus should be on integrating temporal patterns, seasonal variations, and developing robustness against dawn-dusk shifts, nightfall, and challenging weather conditions such as fog and rain. The performance requirements include a precision of at least 98% with a median latency of 100 milliseconds or less.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.98\n            },\n            {\n                \"name\": \"mean average precision\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency\",\n                \"value\": 0.1, \n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Metropolitan Parkade and Lot\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"object detection\"],\n            \"specification\": {\n                \"additional_features\": [\"temporal patterns\", \"seasonal variations\"],\n                \"challenging_conditions\": [\"dawn-dusk shifts\", \"nightfall\", \"fog\", \"rain\"]\n            },\n            \"description\": \"The dataset for urban smart parking, requiring object detection in challenging weather and time-related situations.\",\n            \"preprocessing\": [\"extract temporal and seasonal features\"],\n            \"augmentation\": [\"synthetic weather conditions for robustness\"],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"M2Det\",\n            \"family\": \"M2Det-family\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"transfer_learning\": {\n                    \"diverse_locations\": true,\n                    \"performance_analysis\": true\n                },\n                \"real_time_impact\": true,\n                \"traffic_flow_analysis\": true\n            },\n            \"description\": \"Enhanced M2Det model that integrates temporal patterns and seasonal variations to handle dawn-dusk shifts, nightfall, and fog/rain, with a focus on precision, latency, transfer learning, and real-time traffic flow impact.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Transfer learning may improve model robustness and generalization across diverse locations.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"handle challenging weather and time-varying patterns\"],\n        \"target_device\": \"edge or IoT\",\n        \"deployment_endpoint\": {\n            \"type\": \"real-time\",\n            \"performance_metrics\": \"median latency of 100 milliseconds\"\n        },\n        \"inference_engine\": [\"optimized for real-time performance\"],\n        \"demonstration\": {\n            \"description\": \"Demonstration of improved precision and real-time impact on traffic flow.\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent (enhancing M2Det), expertise level, the 'Metropolitan Parkade and Lot' dataset, integrating temporal and seasonal variations, and performance metrics. It also covers the model's robustness, transfer learning, and real-time impact on traffic. The missing parts would involve fine-tuning for target precision, additional complexity details, and a more detailed demonstration plan.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "Develop an advanced custom image classifier for the Kaggle fundus photography dataset, employing a domain-specific VGG19-BN variant specifically fine-tuned for multi-class diabetic retinopathy grading. Aim for a superior precision of 97% in a complex 12-stage severity analysis, with a focus on minimizing both false negatives and false positives. Mandate real-time responsiveness, GPU resource optimization, and the implementation of Explainable AI techniques for transparent decision-making in ophthalmology settings. Also, design a user-friendly interpretability dashboard for end-users to facilitate clinical discussions and audits.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"medicine\",\n        \"description\": \"The task is to develop an advanced custom image classifier for the Kaggle fundus photography dataset, targeting multi-class diabetic retinopathy grading with a 12-stage severity analysis. The target precision is 97% with a focus on minimizing false negatives and false positives. The classifier should be real-time responsive and optimized for GPU usage. Explainable AI techniques are mandatory for transparency in ophthalmology settings, and a user-friendly interpretability dashboard is required for clinical discussions and audits.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.97\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"GPU resource utilization\",\n                \"value\": \"optimized\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Kaggle Fundus Photography Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\" diabetic_retinopathy_grade\"],\n            \"specification\": null,\n            \"description\": \"A fundus photography dataset for multi-class diabetic retinopathy grading with 12 severity stages.\",\n            \"preprocessing\": [\"domain-specific VGG19-BN fine-tuning\"],\n            \"augmentation\": [\"none (real-time requirement)\"],\n            \"visualization\": [\"Explainable AI visualizations\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Domain-Specific VGG19-BN\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"customization\": \"VGG19-BN fine-tuned for diabetic retinopathy grading\",\n                \"num_classes\": 12\n            },\n            \"description\": \"A fine-tuned VGG19-BN model for advanced image classification of diabetic retinopathy in ophthalmology.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Explainable AI techniques for decision-making in clinical context\",\n        \"Optimization for real-time inference and GPU resource efficiency\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"explainable AI post-processing\"\n        ],\n        \"target_device\": \"GPU-enabled cloud or edge devices\",\n        \"deployment_endpoint\": \"specific API or web-based dashboard for users\",\n        \"inference_engine\": [\"real-time inference\"],\n        \"demonstration\": \"Clinical discussion and audit support dashboard\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure accurately reflects the instruction with high-level requirements like building a custom image classifier, domain-specific fine-tuning, specified performance goals, and integration of Explainable AI. The provided metrics and user requirements are clear and concise. The missing details can be filled based on the user's actual needs and known limitations.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "Utilize the comprehensive OpenSubtitles dataset to create a cutting-edge translation model, focusing exclusively on translating colloquial English-Mandarin conversations. Demand the deployment of a Dual-Sided Attentional BERT-Transformer, which demands exceptional handling of not just standard phrases but also intricate idiomatic expressions, regional dialects, and cultural subtleties. Mandate 95%+ precision in preserving semantic fluency and develop an advanced error analysis and correction system to address not only grammatical errors but also non-verbal cues and colloquial variations. Additionally, incorporate a novel context-aware adaptation mechanism to dynamically adjust for evolving language use in real-time conversations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"linguistics and communication\",\n        \"description\": \"The user wants to develop a cutting-edge translation model using the OpenSubtitles dataset, specifically targeting colloquial English-Mandarin conversations. They request the use of a Dual-Sided Attentional BERT-Transformer, emphasizing handling of idiomatic expressions, regional dialects, and cultural nuances. The performance metric is set to achieve a precision of 95% or higher in preserving semantic fluency. An advanced error analysis and correction system, including non-verbal cues and colloquial variations, is mandatory. A context-aware adaptation mechanism for real-time conversations is also required.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Semantic fluency preservation\",\n                \"value\": null,\n                \"unit\": \"Accuracy\"\n            },\n            {\n                \"name\": \"Error analysis and correction\",\n                \"value\": null,\n                \"unit\": \"Percentage of analyzed errors\"\n            },\n            {\n                \"name\": \"Real-time adaptation\",\n                \"value\": null,\n                \"unit\": \"适应能力\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"OpenSubtitles\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"translated_text\"],\n            \"specification\": {\n                \"language_pair\": \"English-Mandarin\",\n                \"specific Focus\": \"colloquial conversations\"\n            },\n            \"description\": \"A large-scale dataset for English-Mandarin translation, focusing on colloquial conversations.\",\n            \"preprocessing\": [\"BERT-tokenization\", \"Data cleaning\"],\n            \"augmentation\": [\"Domain-specific augmentation\", \"Translation augmentation\"],\n            \"visualization\": [\"Data distribution\", \"Performance comparison\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Dual-Sided Attentional BERT-Transformer\",\n            \"family\": \"Transformer models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"BERT with dual attention mechanism\",\n                \"specific features\": \"handles idiomatic expressions, regional dialects, and cultural nuances\"\n            },\n            \"description\": \"Advanced translation model tailored for English-Mandarin colloquial conversations.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"Contextualized embeddings\", \"Adaptive layers\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"Online adaptation engine\"],\n        \"demonstration\": \"Interactive conversation examples and error analysis\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response represents the parsed information from the given instruction. It includes high-level tasks (intent, expertise, and problem area) and details about the dataset, model, and requirements. Performance metrics are specified, and missing values indicate areas for optimization. A high confidence score is given because the information is largely derived directly from the instruction with appropriate adjustments for a machine learning task.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "sequential recommendation", "instruction": "For a cutting-edge multimedia storytelling platform, develop an innovative sequential recommendation system that leverages the 'Multi-Level Temporal Fusion' algorithm on the Alibaba Cloud's 'Mushrooming Text-Image-Talk' dataset. The model must handle live event chat conversations, emoji reactions, and subtitled video clips to not only predict user preferences but also generate contextually rich, interactive narratives. Strive for near-zero latency while maintaining interpretability, enabling real-time A/B testing and user-centric personalization to boost audience retention in real-world, multilingual, and dynamic content environments.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"recommendation systems\",\n        \"downstream_task\": \"sequential recommendation\",\n        \"application_domain\": \"multimedia storytelling platform\",\n        \"description\": \"The user wants to develop a state-of-the-art sequential recommendation system that uses the 'Multi-Level Temporal Fusion' algorithm on Alibaba Cloud's 'Mushrooming Text-Image-Talk' dataset. The model should handle live event chat conversations, emoji reactions, and subtitled video clips, predicting user preferences and generating interactive narratives with near-zero latency, interpretability, and real-time A/B testing for personalization.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": \"near-zero\"\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency response time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Mushrooming Text-Image-Talk\",\n            \"modality\": [\"text\", \"image\", \"audio\", \"video\"],\n            \"target_variables\": [\"user_preferences\"],\n            \"specification\": {\n                \"live_event_chat_conversations\": true,\n                \"emoji_reactions\": true,\n                \"subtitles\": true\n            },\n            \"description\": \"A comprehensive dataset from Alibaba Cloud for multimedia storytelling, capturing user behavior across live event chat conversations, emojis, and video clips.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Sequential Recommendation System\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"algorithm\": \"Multi-Level Temporal Fusion\",\n                \"application\": \"multimedia storytelling\",\n                \"multimodal Fusion\": true\n            },\n            \"description\": \"An advanced sequential recommendation system leveraging the Multi-Level Temporal Fusion algorithm for real-time personalized narratives on live events, chat conversations, emoji reactions, and subtitled video clips.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"real-time data processing\",\n            \"contextual understanding\"\n        ],\n        \"target_device\": \"cloud or edge\",\n        \"deployment_endpoint\": \"Alibaba Cloud\",\n        \"inference_engine\": [\"GPU-accelerated\", \"cloud-native\"],\n        \"demonstration\": \"contextual narratives and A/B testing results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response structure is based on the provided instructions, capturing the intent to build a recommendation system, the high expertise level of the user, and the details of the problem and dataset. The 'Multi-Level Temporal Fusion' algorithm, along with handling multimedia content and latency requirements, are incorporated. Performance metrics are defined, and the importance of interpretability and A/B testing is emphasized.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "image classification", "instruction": "For a luxury e-commerce platform specializing in niche haute couture, design an innovative deep learning model capable of differentiating between rare vintage couture techniques, sustainably sourced textiles, and intricate 3D printing patterns. The classifier must also decode the environmentally friendly production process and suggest corresponding eco-conscious fashion choices to discerning users, streamlining search and custom recommendations with precision.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"e-commerce (luxury fashion)\",\n        \"description\": \"The user is seeking a machine learning project that involves designing a deep learning model for an e-commerce platform specializing in niche haute couture. The model should classify rare vintage couture techniques, sustainably sourced textiles, and intricate 3D printing patterns. It should also understand the environmentally friendly production process and provide eco-conscious fashion suggestions to users during search and custom recommendations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Luxury Couture Dataset (Custom)\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\n                \"Vintage Technique\",\n                \"Sustainable Textile\",\n                \"3D Printing Pattern\",\n                \"Eco-Friendly Process\"\n            ],\n            \"specification\": null,\n            \"description\": \"A custom dataset containing high-resolution images showcasing rare vintage couture techniques, sustainably sourced textiles, intricate 3D printing patterns, and environmental production indicators for classifying and understanding eco-conscious fashion.\",\n            \"preprocessing\": [\"image resizing\", \"feature extraction\"],\n            \"augmentation\": [\"style transfer\", \"color enhancement\"],\n            \"visualization\": [\"data exploration\", \"class distribution\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Couture Identification and Recommendation Model\",\n            \"family\": \"Convolutional Neural Networks (CNN) with Transfer Learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"ResNet50 or similar\",\n                \"training dataset size\": null,\n                \"accuracy on similar tasks\": null\n            },\n            \"description\": \"A deep learning model leveraging CNNs with transfer learning capabilities, designed to classify rare couture techniques, eco-conscious textiles, and 3D printing patterns in luxury fashion items while understanding their environmental footprint. The model will optimize search and custom recommendations for eco-conscious users.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider using domain-specific data augmentation for haute couture images\",\n        \"Integrate recycling or sustainability indices as part of the classifier's features\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"production process embeddings\", \"user preferences fusion\"],\n        \"target_device\": \"cloud-based for real-time recommendations\",\n        \"deployment_endpoint\": \"custom API for fashion platform integration\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"Kubernetes\"],\n        \"demonstration\": \"User experience showcase through interactive demos\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is derived from the given instruction, describing a project for a luxury e-commerce platform. Expertise is assumed to be high given the complexity of the task and the need for a sophisticated model. The problem area is computer vision (image classification) and performance metrics are accuracy, precision, and recall. The deep learning model's focus on luxury couture, environmental friendliness, and recommendations is well-captured. Some specifics, like exact model architecture and performance, are left open for further discussion.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Redesign the Enron Email dataset analysis for node classification as a multistep challenge by implementing a novel Hierarchical Attention-based RGCN architecture. Mandate the model to not only identify collaboration roles but also uncover latent relationships within sub-departments. Prioritize efficiency in large-scale graph training, aiming for record-breaking speed with resource constraints, while enabling real-time, data-intensive analysis of employee dynamics across millions of department connections, considering temporal evolution and implicit knowledge extraction.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"business/finance\",\n        \"description\": \"The user wants to redesign the Enron Email dataset analysis for node classification using a Hierarchical Attention-based RGCN architecture. The objective is to identify collaboration roles and latent relationships within sub-departments, while ensuring efficiency in large-scale graph training for record-breaking speed with resource constraints. The model should support real-time, data-intensive analysis for employee dynamics across millions of department connections, considering temporal evolution and implicit knowledge extraction.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"efficiency (speed)\",\n                \"value\": null,\n                \"unit\": \"training time\"\n            },\n            {\n                \"name\": \"scalability\",\n                \"value\": null,\n                \"unit\": \"large-scale graph\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": {\n                    \"unit\": \"seconds\",\n                    \"optimization_goal\": \"real-time\"\n                }\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": {\n                    \"unit\": \"MB\"\n                },\n                \"unit\": \"memory\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Enron Email dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"collaboration_roles\", \"latent_relations\"],\n            \"specification\": {\n                \"node_type\": \"employees\",\n                \"edge_type\": \"collaborations\",\n                \"sub-department_info\": \"unexplored\"\n            },\n            \"description\": \"An email communication graph from the Enron dataset, where the challenge is to classify nodes for collaboration roles and uncover latent relationships within sub-departments.\",\n            \"preprocessing\": [\n                \"Temporal aggregation of edges for modeling temporal evolution\",\n                \"Data anonymization\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"Graph-level visual representation of employee dynamics\"\n            ],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical Attention-based RGCN\",\n            \"family\": \"graph neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"hierarchical_attention_layers\": \"novel\"\n                },\n                \"efficiency\": {\n                    \"large_graph_training_speed\": \"record-breaking\"\n                },\n                \"resource_constraints\": true\n            },\n            \"description\": \"A novel architecture designed for the Enron Email dataset, specifically for node classification with collaboration role identification and latent relationship extraction, optimized for efficiency and real-time analysis.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Implicit knowledge extraction from communication patterns\",\n        \"Temporal evolution modeling of employee dynamics\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"temporal feature engineering\",\n            \"latent feature extraction\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"GPU-accelerated\", \"optimized for scalability\"],\n        \"demonstration\": \"real-time, data-intensive\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent for building a model, specifies the expertise level, and maps the problem domain to graph machine learning. The Enron Email dataset is adapted to include node classification, attention-based RGCN, and performance metrics based on efficiency and scalability. Resource constraints and real-time analysis are key components. The model description provides relevant details on the architecture, and the service section covers necessary steps in the final process.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "As a project director for a niche machine translation research group, commission your team to develop a highly innovative multilingual model that not only bridges the gap between previously uncharted African dialects, particularly Himba and Xitsonga, but also seamlessly integrates Tatoeba corpus and MUSE techniques for zero-shot translation. Target a groundbreaking 10% relative improvement in chrF++ scores, ensuring scalability, low-resource adaptability, and preserving indigenous linguistic nuances, while minimizing computational footprint in resource-constrained environments.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"linguistics\",\n        \"description\": \"The task is to develop a multilingual model for machine translation, focusing on previously uncharted African dialects, Himba and Xitsonga. The model should integrate Tatoeba corpus and MUSE techniques for zero-shot translation, aiming for a 10% relative improvement in chrF++ scores. It should be scalable, adaptable in low-resource environments, preserve linguistic nuances, and minimize computational requirements for resource-constrained environments.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"relative improvement (chrF++)\",\n                \"value\": 0.1\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"computational footprint\",\n                \"value\": null,\n                \"unit\": \"resource-constrained environments\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Tatoeba corpus\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"corpus_integration\": \"MUSE and zero-shot translation\"\n            },\n            \"description\": \"A multilingual corpus for training and integrating Tatoeba techniques in the model\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        },\n        {\n            \"name\": \"Xitsonga and Himba dialect dataset\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"linguistic_nuances\": \"indigenous\"\n            },\n            \"description\": \"Data for African dialects, Himba and Xitsonga, for low-resource adaptability\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Innovative Multilingual Machine Translation Model\",\n            \"family\": \"neural machine translation\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"adaptability\": \"low-resource\",\n                \"linguistic_preservation\": true,\n                \"scalability\": true\n            },\n            \"description\": \"A model designed for African dialects with Tatoeba and MUSE integration, targeting 10% chrF++ improvement and optimizations for resource-constrained environments.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Zero-shot translation and MUSE techniques for bridging language gaps\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"resource-constrained environments\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"highlight indigenous linguistic nuances and translation accuracy\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This response captures the key points from the instruction, including the project intent, target languages, technical requirements, and performance metrics. It assumes a high level of expertise for the project director. However, specific model architectures and computational footprints are not clearly defined; these areas might need further clarification.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "In the realm of precision agriculture, you've been handed a unique challenge to develop an advanced image segmentation system using next-generation Multispectral LiDAR data. The task demands not only the differentiation of intricate crop types (precisely identifying wheat, soybeans, and rice) but also the detection of stress patterns in plants, microtopography, and subtle soil moisture changes. Design and compare the effectiveness of state-of-the-art deep learning models, like DRNet, Transformers4Image, and DAG-Net, while accounting for their memory footprint, energy consumption during inference, and adaptability to variable weather conditions. Can you create a model that not only maximizes yield prediction but also supports sustainable farming practices with minimal ecological impact?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"precision agriculture\",\n        \"description\": \"The task is to develop an advanced image segmentation system for precision agriculture using Multispectral LiDAR data. This involves identifying wheat, soybeans, and rice crops, detecting stress patterns in plants, microtopography, and subtle soil moisture changes. The focus is on comparing state-of-the-art deep learning models such as DRNet, Transformers4Image, and DAG-Net, considering factors like memory footprint, energy consumption during inference, and adaptability to variable weather conditions. The goal is to achieve high yield prediction and promote sustainable farming with minimal ecological impact.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"yield prediction accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null\n            },\n            {\n                \"name\": \"energy consumption during inference\",\n                \"value\": null\n            },\n            {\n                \"name\": \"adaptability to variable weather conditions\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"memory usage during training\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Multispectral LiDAR for Precision Agriculture\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"crop types\", \"stress patterns\", \"microtopography\", \"soil moisture\"],\n            \"specification\": null,\n            \"description\": \"A dataset containing Multispectral LiDAR data for precision agriculture, with focus on differentiating crop types, detecting stress patterns, and analyzing soil properties.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"Visualization of LiDAR data and segmentation results\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"DRNet\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": null,\n            \"description\": \"A state-of-the-art model for image segmentation, comparing with Transformers4Image and DAG-Net.\"\n        },\n        {\n            \"name\": \"Transformers4Image\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": null,\n            \"description\": \"Another advanced image segmentation model, also part of the comparison.\"\n        },\n        {\n            \"name\": \"DAG-Net\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": null,\n            \"description\": \"A competitive model in the crop segmentation and detection of environmental factors.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for energy efficiency and scalable deployment\"],\n        \"demonstration\": \"Systematic comparison of model performance in various scenarios\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is well-formatted according to the given schema. The high expertise level indicates the user has a good understanding of the task requirements. The problem area, downstream task, and application domain are clearly specified. The requested metrics and models are included, and the demonstration highlights the importance of sustainability and real-world applicability.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "For a VQA project targeting high-end retail product assistance, design a specialized model combining TextVQA with custom ResNet and BERT modules. Emphasize fine-grained feature extraction, attention-based cross-modal fusion, and temporal context understanding. Strive for optimal accuracy in recognizing and interpreting product details in cluttered, seasonal, andmultilingual product images.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"retail\",\n        \"description\": \"The user aims to design a specialized machine learning model for high-end retail product assistance, focusing on Visual Question Answering (VQA) with integration of TextVQA, custom ResNet, and BERT modules. The model emphasizes fine-grained feature extraction, attention-based cross-modal fusion, and temporal context understanding. The main goal is to achieve high accuracy in recognizing and interpreting product details in cluttered, seasonal, and multilingual product images.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Custom Retail VQA Dataset\",\n            \"modality\": [\"image\", \"text\"],\n            \"target_variables\": [\"product_details\"],\n            \"specification\": {\n                \"image_size\": null,\n                \"text_length\": null,\n                \"cluttered_images\": \"yes\",\n                \"seasonal_variations\": \"yes\",\n                \"multilingual_products\": \"yes\"\n            },\n            \"description\": \"A dataset specifically designed for VQA in high-end retail, with images and corresponding questions focusing on fine-grained product details in diverse scenarios.\",\n            \"preprocessing\": [\n                \"fine-grained feature extraction\",\n                \"multi-modal data augmentation\"\n            ],\n            \"augmentation\": [\n                \"image clutter augmentation\",\n                \"language translation\"\n            ],\n            \"visualization\": [\n                \"attention maps for cross-modal fusion\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"TextVQA-ResNetBERT\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"custom TextVQA with ResNet and BERT fusion\",\n                \"crossmodal_fusion\": \"attention-based\",\n                \"temporal_context_mode\": \"enabled\"\n            },\n            \"description\": \"A specialized model combining TextVQA, ResNet, and BERT for retail product assistance, which emphasizes fine-grained feature extraction and temporal context understanding.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Advanced understanding of fine-grained visual and language features in a retail context\",\n        \"Importance of cluttered, seasonal, and multilingual considerations\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"text normalization\", \"image preprocessing\"],\n        \"target_device\": \"cloud or GPU-accelerated platform\",\n        \"deployment_endpoint\": \"retail product assistance API\",\n        \"inference_engine\": [\"TensorFlow.js (for browser deployment)\", \"PyTorch Server (for server-side inference)\"],\n        \"demonstration\": \"product detail visual explanations with model predictions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the user's instruction, adapting to the schema. The intent is 'build' for creating a model, with high expertise level. Multimodal learning area with VQA focus is identified. The project details, datasets, and metrics align with the task description. The model components and requirements are specified, acknowledging the challenges of high-end retail products. The service component includes fine-tuning and deployment settings for the target retail assistance scenario.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "As a project manager for a cutting-edge educational platform, design a sophisticated Visual Language Reasoning system utilizing the TextVQA dataset. Demand a multi-step, deep-learning model with high precision and explainability, capable of interpreting and cross-referencing visual and textual context for complex question answering.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"education\",\n        \"description\": \"The task requires the development of a Visual Language Reasoning system for an educational platform, specifically using the TextVQA dataset. The system should employ a multi-step, deep-learning model that prioritizes high precision and explainability, enabling it to understand and integrate both visual and textual context for complex question answering.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"explainability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"model_complexity\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"TextVQA dataset\",\n            \"modality\": [\"text\", \"image\"],\n            \"target_variables\": [],\n            \"specification\": null,\n            \"description\": \"The dataset for developing a Visual Language Reasoning system, integrating visual and textual context for complex question answering.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"multi-step deep-learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"层数\": \"hierarchical\",\n                    \"层间集成\": \"attention-based\"\n                },\n                \"model_depth\": \"deep\",\n                \"precision_target\": null\n            },\n            \"description\": \"A highly-precise, explainable visual language reasoning model for complex question answering using the TextVQA dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"content\": \"Advanced knowledge of deep learning frameworks such as TensorFlow or PyTorch, computer vision, and natural language processing, along with interpretability techniques, such as attention mechanisms, would be beneficial.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"contextual embeddings\",\n            \"multi-modal fusion\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorRT\", \"ONNX\"],\n        \"demonstration\": \"Interactive dashboard for visualizing model predictions and explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure represents the project manager's intention to build a sophisticated system with specific requirements, such as high precision and explainability. Given the complexity of the task, the expertise level is set to 'high'. The area is 'multimodal learning', focusing on visual language reasoning. The performance metric of precision and explainability is included. As the TextVQA dataset needs to be found, the source is specified as 'direct-search'. The model assumptions and requirements are set accordingly, with the mention of additional frameworks and services.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "As a cutting-edge AI project manager, I've been commissioned to develop a state-of-the-art object detection system for our luxury fashion boutiques. The objective is to enhance visual surveillance while preserving customer privacy and enhancing their shopping experience. The system must not only identify potential theft attempts but also distinguish between genuine interactions and stealthy behavior, such as individuals examining high-end items for extended periods. Furthermore, it should learn and adapt to different store layouts, lighting conditions, and seasonal fashion trends, providing real-time alerts to store security personnel without triggering false positives. In addition, it should integrate seamlessly with the existing Point of Sale system, generating actionable reports and nudging proactive store optimizations. Can you lead the team to create this sophisticated AI-driven security solution?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"luxury fashion boutiques\",\n        \"description\": \"The user seeks to develop a state-of-the-art object detection system for luxury fashion boutiques, focusing on enhancing visual surveillance while maintaining customer privacy and improving the shopping experience. The system should be capable of identifying theft attempts, distinguishing genuine interactions, adapt to varying store conditions, integrate with POS systems, and generate actionable reports.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"detection accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"false positive rate\",\n                \"value\": null\n            },\n            {\n                \"name\": \"adaptability to different layouts\",\n                \"value\": null\n            },\n            {\n                \"name\": \"integration with POS system\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"frames per second\"\n            },\n            {\n                \"name\": \"real-time alerting\",\n                \"value\": null,\n                \"unit\": \"alerts per second\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"proprietary_fashion_boutique_data\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"theft\", \"interaction_type\"],\n            \"specification\": null,\n            \"description\": \"A diverse collection of images capturing different store environments, lighting conditions, and seasonal fashion trends, with annotated labels for theft attempts, genuine interactions, and extended observations.\",\n            \"preprocessing\": [\"adaptation to varying image quality\", \"noise reduction\"],\n            \"augmentation\": [\"synthetic data generation\", \"scene variation\"],\n            \"visualization\": [\"image analysis and heatmaps\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning-based object detection\",\n            \"type\": \"neural networks\",\n            \"specification\": null,\n            \"description\": \"A sophisticated AI-driven object detection model tailored for luxury fashion boutiques with state-of-the-art performance, adaptability, and low false positive rates.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"text\": \"The model should employ multi-scale feature extraction and advanced pedestrian re-identification techniques for stealthy behavior detection.\"\n        },\n        {\n            \"text\": \"Privacy preservation techniques like occlusion and anonymization of faces can be incorporated.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"custom features for fashion trends\", \"contextual embeddings\"],\n        \"target_device\": \"edge or cloud computing\",\n        \"deployment_endpoint\": \"centralized or decentralized system\",\n        \"inference_engine\": [\"real-time object detection frameworks\"],\n        \"demonstration\": \"live and privacy-friendly demos for security personnel\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the given instruction, emphasizing the build intent and highlighting the need for a sophisticated object detection system. Expertise is assumed to be high, as a cutting-edge AI project manager is involved. Specific performance metrics, dataset requirements, and the model's adaptability to real-world challenges are included. However, some specific performance targets are left undefined for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "question answering", "instruction": "For the legal team, we seek a cutting-edge Q&A system, employing advanced DeBERTa v3.1 with fine-tuning on the LegalQA corpus. The model must handle esoteric legal terminology, comply with GDPR regulations, deliver error-free responses, and provide detailed rationale behind its answers, ensuring high-quality, transparent, and compliant document analysis.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"legal\",\n        \"description\": \"The objective is to develop a cutting-edge Q&A system for the legal team, utilizing DeBERTa v3.1 with fine-tuning on the LegalQA corpus. The system must handle esoteric legal terminology, adhere to GDPR regulations, provide error-free responses, and offer detailed rationales behind its answers for high-quality, transparent, and compliant document analysis.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"compliance (GDPR)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"error rate\",\n                \"value\": null\n            },\n            {\n                \"name\": \"rationale quality\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"memory efficiency\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"LegalQA corpus\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"questions\", \"answers\"],\n            \"specification\": {\n                \"fine-tuning_size\": \"custom\",\n                \"legal_terminology_coverage\": null\n            },\n            \"description\": \"A corpus fine-tuned for the legal domain, specifically DeBERTa v3.1.\",\n            \"preprocessing\": [\"legal terminology preprocessing\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"DeBERTa v3.1\",\n            \"family\": \"transformers (specifically DeBERTa model)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"DeBERTa\",\n                \"version\": \"v3.1\",\n                \"pretrained_model\": \"LegalQA corpus fine-tuned\"\n            },\n            \"description\": \"A state-of-the-art Q&A model with fine-tuning on LegalQA corpus, designed for esoteric legal terminology and GDPR compliance.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"title\": \"Legal domain knowledge\",\n            \"description\": \"Expertise in GDPR regulations and handling esoteric legal terminology.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"GDPR compliance techniques\", \"legal terminology handling\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"custom legal document analysis platform\",\n        \"inference_engine\": [\"GPU-optimized\", \"API-friendly\"],\n        \"demonstration\": \"interactive Q&A with detailed answer explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately reflects the requirements mentioned in the instruction, including the use of DeBERTa v3.1, LegalQA corpus fine-tuning, GDPR compliance, and rationale explanations. The expert level is set to 'high' due to the complexity of the requirements. However, specific performance targets (accuracy, compliance, and error rates) and time complexity metrics (like memory usage and inference speed) are not provided and left open for further clarification.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "Deploy a high-resolution, multi-spectral image segmentation model on the lesser-known OceanSat-3 dataset, targeting not only the delineation of land, water, and structures, but also to detect and classify unique marine life forms, coral reefs, and underwater debris. Elevate the challenge by incorporating a novel fusion of deep learning algorithms, like the Time-Aware Cascade Attention U-Net and PointRend, to handle turbid water and dynamic tidal conditions. Strive for minimal latency while processing satellite imagery with a resolution of 16K, demanding a system capable of real-time monitoring for large-scale coastal conservation efforts.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"environmental monitoring, coastal conservation\",\n        \"description\": \"The goal is to deploy a high-performance multi-task image segmentation model on the lesser-known OceanSat-3 dataset. The model should segment land, water, structures, marine life forms (including coral reefs and underwater debris), and handle turbid water and dynamic tidal conditions with techniques such as Time-Aware Cascade Attention U-Net and PointRend. The system should process 16K resolution satellite imagery with minimal latency for real-time monitoring for large-scale conservation efforts.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"f1_score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean Intersection over Union (mIoU)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory_usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"OceanSat-3\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"image_resolution\": 16000,\n                \"color_channels\": 3,\n                \"specific_bands\": [\"multi-spectral\"]\n            },\n            \"description\": \"A lesser-known dataset for multi-task image segmentation, with a focus on marine life detection, coral reefs, and underwater debris in challenging conditions.\",\n            \"preprocessing\": [\"resizing\", \"multi-spectral fusion\"],\n            \"augmentation\": [\n                \"turbidity simulation\",\n                \"dynamic tidal condition simulation\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Time-Aware Cascade Attention U-Net + PointRend\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": [\"attention mechanism\", \"cascaded architecture\", \"time-aware\"],\n                \"features_used\": [\"U-Net\", \"PointRend\"],\n                \"FLOPs\": null,\n                \"train_speed\": null,\n                \"inference_speed\": null,\n                \"latency_target\": \"real-time\"\n            },\n            \"description\": \"A novel fusion of Time-Aware Cascade Attention U-Net and PointRend to address turbid waters and dynamic tidal conditions.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"data preprocessing and fusion\"],\n        \"target_device\": \"cloud-based (to handle real-time processing and high-resolution imagery)\",\n        \"deployment_endpoint\": \"a large-scale satellite imagery processing service\",\n        \"inference_engine\": [\"GPU-accelerated\"],\n        \"demonstration\": \"large-scale coastal monitoring dashboard\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the user's intent to build a high-performance model, with deep expertise assumed. The area is computer vision, specifically image segmentation, and the task is multi-task. The dataset description, preprocessing, and advanced model fusion align with the instruction. Performance metrics focus on accuracy, F1 score, mIoU, and latency, capturing the requirement for real-time monitoring. Complexity metrics emphasize low latency and efficient use of resources. It is assumed that a fusion of Time-Aware Cascade Attention U-Net and PointRend would fit the described challenge.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a project manager for a niche wildlife conservation organization, your team has captured high-resolution images of endangered and domestic cat species in various environments. Develop a specialized convolutional neural network (CNN) architecture that not only differentiates among species, but also accounts for breed variations, camera angles, and background context. Kindly recommend the most suitable pre-trained model and fine-tuning techniques for this complex classification task, ensuring minimal computational overhead.", "resposne": "{\n    \"user\": {\n        \"intent\": \"consult-build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"wildlife conservation\",\n        \"description\": \"The task is to develop a specialized CNN architecture for classifying endangered and domestic cat species, accounting for breed variations, camera angles, and background context. The objective is to minimize computational overhead while maintaining high accuracy.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"computational overhead\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Wildlife Cat Images\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"species\", \"breed\"],\n            \"specification\": {\n                \"image_size\": \"high-resolution\",\n                \"variations\": [\"camera angles\", \"background context\"]\n            },\n            \"description\": \"A collection of high-resolution images with endangered and domestic cat species, capturing breed, camera angles, and background context for training.\",\n            \"preprocessing\": [\n                \"image normalization\",\n                \"data augmentation (to handle breed variations, camera angles, and background context)\"\n            ],\n            \"augmentation\": [\n                \"crop, rotation, brightness adjustment, and background replacement\"\n            ],\n            \"visualization\": [\n                \"examples of dataset distribution among species and breeds\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"pre-trained CNN (e.g., VGG, ResNet, EfficientNet)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"customized for breed variations and context-awareness\",\n                \"initial_layers\": \"transfer learning from a pre-trained model\",\n                \"fine-tuning_layers\": \"last few layers to avoid overfitting\"\n            },\n            \"description\": \"A specialized CNN architecture using transfer learning with minimal computational overhead for the wildlife conservation cat classification task.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Transfer learning with well-established models like ResNet-50 or EfficientNet can be beneficial for the high diversity of cats and complexities in the images.\",\n        \"Use techniques like knowledge distillation to maintain efficiency during fine-tuning\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"suitable for edge devices or cloud due to computational constraints\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"CPU-optimized, GPU-aided, or specialized libraries for enhanced performance\"],\n        \"demonstration\": \"Sample predictions on a variety of images highlighting breed and environmental context\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure reflects the user's need for consultation on model build and fine-tuning, acknowledging the complexity of the problem in terms of accuracy and computational efficiency. The requested pre-trained model, fine-tuning methods, and considerations for architectural modifications are well-aligned with the task. There's a high level of confidence due to the clear understanding of the problem and the need for tailored solution.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a project manager for a cutting-edge deep learning team, we need to develop an image classification system for esoteric celestial objects, such as nebulae and exoplanets, using a memory-restricted subset of the Flickr-Galaxies dataset. The challenge is to optimize for accuracy under limited labeled data and within a constrained computational budget. Can you suggest an appropriate architecture and explain the expected performance milestones?", "resposne": "{\n    \"user\": {\n        \"intent\": \"consult-build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"astronomy\",\n        \"description\": \"The task is to develop an image classification system for esoteric celestial objects (nebulae and exoplanets) using a limited labeled subset of the Flickr-Galaxies dataset. The main focus is on accuracy optimization with minimal labeled data and a constrained computational budget.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"data efficiency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"computational budget\",\n                \"value\": null,\n                \"unit\": \"GPU hours\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Flickr-Galaxies (memory-restricted subset)\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"celestial_object\"],\n            \"specification\": {\n                \"labeled_data_size\": \"limited\",\n                \"data_distribution\": {\n                    \"train\": \"unknown\",\n                    \"validation\": \"unknown\",\n                    \"test\": \"unknown\"\n                }\n            },\n            \"description\": \"A subset of the Flickr-Galaxies dataset tailored for esoteric celestial objects, with a focus on low data and resource constraints.\",\n            \"preprocessing\": [\"data augmentation for class imbalance\"],\n            \"augmentation\": [\"random cropping, flipping\"],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Suggested architecture (e.g., MobileNetV2, EfficientNetB0, or a custom transfer learning model)\",\n            \"family\": \"Convolutional Neural Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture_details\": \"Lightweight, suitable for limited data, and efficient computation\",\n                \"trainable_few_shot\": true\n            },\n            \"description\": \"A memory-efficient architecture with high accuracy potential under resource constraints.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Transfer learning from a similar astronomical dataset or general object recognition models may help improve performance with limited data.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature extraction from pre-trained models\"],\n        \"target_device\": \"GPU-constrained environment (cloud or edge)\",\n        \"deployment_endpoint\": \"Web or API service\",\n        \"inference_engine\": [\"TensorFlow Serving, or lightweight custom inference framework\"],\n        \"demonstration\": \"Interactive UI showcasing sample predictions with explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response incorporates key details from the instruction, such as the area of application, task, and data constraints. It suggests a consult-build intent as the team requires architectural advice for a specific problem. Performance milestones are focused on accuracy, data efficiency, and computational budget. The provided model architecture and data handling strategies cater to the memory and labeled data restrictions.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "You are now tackling a highly intricate time-series forecasting challenge using the ETTm2 dataset, which consists of real-world, high-dimensional, and non-stationary data. The train, validation, and test splits have been meticulously balanced for a more robust assessment. The input sequences of length 96 (INPUT_SEQ_LEN=96, dimensions expanded to INPUT_DIM=21) present complex temporal patterns. Your objective is not only to forecast the subsequent 96-step predictions (PRED_SEQ_LEN=96) but also to account for seasonality, anomalies, and potential long-term dependencies. Your model must excel in minimizing mean squared error (MSE) and mean absolute error (MAE), while demonstrating superior generalization across multiple rolling window evaluations to ensure real-world applicability.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy or finance (high-dimensional and non-stationary data)\",\n        \"description\": \"The task is to address a complex time-series forecasting challenge using the ETTm2 dataset. It involves real-world, high-dimensional, non-stationary data with balanced train, validation, and test splits. The objective is to forecast the next 96 steps (PRED_SEQ_LEN=96) while considering seasonality, anomalies, and long-term dependencies, with a focus on minimizing MSE and MAE and demonstrating good generalization through multiple rolling window evaluations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean squared error\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute error\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ETTm2\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 21\n            },\n            \"description\": \"A high-dimensional, non-stationary time-series dataset with balanced splits for the task of time-series forecasting, addressing seasonality, anomalies, and long-term dependencies.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model architecture\": \"long short-term memory (LSTM) or transformer-based for handling time-series complexity\"\n            },\n            \"description\": \"A deep learning model, possibly incorporating LSTMs or transformers, designed for complex time-series forecasting with an emphasis on handling seasonality, anomalies, and long-term dependencies.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is derived from the provided instruction, maintaining the specified schema. The intent is 'build' for developing a model, with high expertise assumed. The ETTm2 dataset is mentioned, with the task focusing on forecasting and handling complex patterns. Performance metrics (MSE and MAE) are included as requested. The model type, likely LSTM or transformer, is suggested based on the nature of the dataset and task. The response doesn't include missing deployment details since they were not specified in the instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "You are now tackling a multifaceted deep learning challenge for time-series analysis. The Weather dataset, divided into intricately stratified subsets (train-validation-test), contains a high-dimensional time-series (INPUT_SEQ_LEN=96, INPUT_DIM=21) with complex temporal dependencies. Your objective is to develop a sophisticated forecasting model that not only predicts the subsequent sequence (PRED_SEQ_LEN=96, PRED_DIM=21) but also exhibits seasonality awareness, handles irregular patterns, and optimizes for both mean squared error (MSE) and mean absolute error (MAE) simultaneously. Ensure the model is adaptable across different time lags and exhibits resilience in cross-validation scenarios.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"weather forecasting\",\n        \"description\": \"The user is tackling a multifaceted deep learning challenge for time-series analysis. They require a model to forecast high-dimensional sequences (INPUT_SEQ_LEN=96, INPUT_DIM=21) in the Weather dataset. The model must handle seasonality, irregular patterns, and optimize for mean squared error (MSE) and mean absolute error (MAE) simultaneously, with adaptability across different time lags and strong performance in cross-validation.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean squared error\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute error\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Weather dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 21\n            },\n            \"description\": \"A time-series dataset with stratified subsets (train, validation, test), containing high-dimensional sequences with complex temporal dependencies, for weather forecasting. The task involves predicting PRED_SEQ_LEN=96, PRED_DIM=21 while considering seasonality, irregular patterns, and optimized for MSE and MAE.\",\n            \"preprocessing\": [\"seasonality-aware preprocessing\"],\n            \"augmentation\": [\"irregular pattern injection\"],\n            \"visualization\": [\"time-series pattern analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks (e.g., LSTM, Transformer-based models)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"temporal awareness\": \"seasonality and irregular patterns\",\n                \"adaptability\": \"cross-validation scenarios\",\n                \"specifics\": \"optimizes for MSE and MAE jointly\"\n            },\n            \"description\": \"A sophisticated deep learning model for weather forecasting, designed to handle high-dimensional sequences, exhibit seasonality awareness, and optimize MSE and MAE with adaptability for different time lags.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"time lag adaptation techniques\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"cross-validation results and performance visualization\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is structured based on the given instruction and schema. The user's intent is to build a model ('build'). Expertise is assumed to be high due to the complexity of the problem. Performance metrics (MSE and MAE) and requirements for seasonality and cross-validation are incorporated. The deep learning model's characteristics reflect the task at hand.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "As a machine learning project manager for a specialized security camera system targeting high-end luxury boutiques, our objective is to develop an advanced object detection algorithm that not only counts the number of distinctive customers but also recognizes their unique style traits and shopping preferences. The system must differentiate between loyal VIP customers, regular clients, and occasional pedestrians while maintaining real-time analysis and generating personalized recommendations for store staff. Additionally, the algorithm should be able to recognize and exclude staff carrying store merchandise, as well as identify potential shoplifting behaviors without flagging genuine customers. Ensure the system operates seamlessly in low-light and dynamic lighting conditions and provides detailed heatmaps showcasing foot traffic flow for store layout optimization.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"security and retail\",\n        \"description\": \"The objective is to develop an advanced object detection algorithm for a luxury boutique security system. The system should count and analyze unique customers (VIPs, regulars, pedestrians), differentiate between them, exclude staff with merchandise, identify potential shoplifting, operate in low-light conditions, and provide real-time analysis and personalized recommendations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"detection recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"false positive rate\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"ms\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Luxury Boutique Camera Data\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"customers\", \"style_traits\", \"shopping_preferences\", \"VIP\", \"staff\", \"shoplifting\"],\n            \"specification\": {\n                \"dynamic_lighting_resilience\": true,\n                \"low_light_performance\": true\n            },\n            \"description\": \"A specialized dataset containing images captured from security cameras in luxury boutiques for advanced object detection and analysis.\",\n            \"preprocessing\": [\"image enhancement\", \"target-labeling\"],\n            \"augmentation\": [\"low-light simulation\", \"dynamic lighting variations\"],\n            \"visualization\": [\"heatmaps for foot traffic\", \"customer behavior patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning (e.g., YOLOv5, Mask R-CNN)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"\",\n                \"real-time_analysis\": true,\n                \"recommendation_engine_integration\": true\n            },\n            \"description\": \"Advanced object detection model for specialized boutique security system\"\n        }\n    ],\n    \"knowledge\": [\n        \"Exploit transfer learning from existing retail security models\",\n        \"Integrate computer vision and style recognition techniques\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"customer segmentation\", \"preference profiling\"],\n        \"target_device\": \"high-end luxury boutiques, low-power embedded systems for real-time performance\",\n        \"deployment_endpoint\": \"proprietary cloud-based system\",\n        \"inference_engine\": [\"GPU-optimized, edge-computing compatible\"],\n        \"demonstration\": \"Live camera feed and dynamic reports for store management\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON response captures the essence of the project requirements. Expertise level is assumed high due to the specialized security system. Performance metrics and complexity constraints are included for a high-end and accurate system. Model development is detailed with a deep learning-based approach. Additional knowledge is highlighted as crucial to the project's success, while deployment service and system demonstration fit the business context.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "Design a state-of-the-art time-series forecasting model using a custom-designed, bidirectional LSTM architecture, specifically tailored for a historic solar and wind power fusion dataset. Forecast hourly energy consumption for the next 72 hours with sub-100 milliseconds inference speed, ensuring real-time adaptability and efficient parallel processing.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy production\",\n        \"description\": \"The user aims to develop a state-of-the-art time-series forecasting model, focusing on a custom-designed bidirectional LSTM architecture. The model should be tailored for a historic solar and wind power fusion dataset, with the target being to forecast hourly energy consumption for the next 72 hours. Real-time adaptability and sub-100 milliseconds inference speed are key requirements for efficient parallel processing.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute error\",\n                \"value\": null\n            },\n            {\n                \"name\": \"forecast horizon\",\n                \"value\": 72\n            },\n            {\n                \"name\": \"inference_time\",\n                \"value\": {\n                    \"name\": \"sub-100ms\",\n                    \"unit\": \"milliseconds\"\n                }\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_speed\",\n                \"value\": {\n                    \"name\": \"real-time adaptability\",\n                    \"unit\": \"time\"\n                }\n            },\n            {\n                \"name\": \"parallel_processing\",\n                \"value\": true\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Historic Solar and Wind Power Fusion Dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"hourly energy consumption\"],\n            \"specification\": {\n                \"data_type\": \"fusion of solar and wind power data\",\n                \"time_series_length\": null,\n                \"feature_dimensions\": null,\n                \"temporal_resolution\": \"hourly\"\n            },\n            \"description\": \"A dataset combining solar and wind power history, used for training the bidirectional LSTM model.\",\n            \"preprocessing\": [\n                \"data fusion\",\n                \"feature engineering for solar and wind power\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\"feature analysis\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Custom-BLSTM\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"bidirectional LSTM\",\n                \"customization\": \"tailored for solar and wind power fusion\",\n                \"FLOPs\": null,\n                \"parameters\": null,\n                \"training_speed\": null,\n                \"inference_speed_target\": \"sub-100ms\"\n            },\n            \"description\": \"A state-of-the-art time-series forecasting model with a bidirectional LSTM architecture, specifically designed for handling solar and wind power data.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"data normalization\",\n            \"sequence padding\"\n        ],\n        \"target_device\": \"real-time environment\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"vectorized computation\"],\n        \"demonstration\": {\n            \"usage\": \"real-time energy consumption updates\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately captures the user's requirements for a time-series forecasting model. The LSTM architecture is specified with a bidirectional component, and the dataset is described as a fusion of solar and wind power data for energy consumption. Sub-100ms inference speed, real-time adaptability, and parallel processing are key constraints. However, exact performance metrics are not specified in the instruction, so the default null values are used for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "For a cutting-edge research project, develop a deep learning model leveraging advanced semantic segmentation techniques specifically tailored for distinguishing individual cat breeds in high-resolution, low-light wildlife photographs, ensuring real-time performance and fine-grained pixel-level accuracy.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"wildlife and animal recognition\",\n        \"description\": \"The task is to build a deep learning model for an advanced semantic segmentation project. The objective is to accurately differentiate individual cat breeds in high-resolution, low-light wildlife photographs with real-time performance.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"pixel-level accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time performance (FPS)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"High-resolution Cat Breed Dataset (Custom)\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"cat breed\"],\n            \"specification\": {\n                \"image_resolution\": {\n                    \"width\": null,\n                    \"height\": null\n                },\n                \"low-light conditions\": true,\n                \"image_type\": \"wildlife\"\n            },\n            \"description\": \"A custom dataset consisting of high-resolution, low-light wildlife photographs targeted for cat breed segmentation.\",\n            \"preprocessing\": [\n                \"image normalization\",\n                \"light enhancement (low-light settings)\"\n            ],\n            \"augmentation\": [\n                \"data augmentation for domain adaptation\"\n            ],\n            \"visualization\": [\n                \"pixel-level accuracy maps\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced Semantic Segmentation Model (Custom)\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"state-of-the-art for semantic segmentation\",\n                \"optimizer\": null,\n                \"loss_function\": null\n            },\n            \"description\": \"A deep learning model utilizing advanced techniques for cat breed segmentation, optimized for high-resolution, low-light images.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"text\": \"Exploiting transfer learning from large-scale image datasets, such as ImageNet, can improve performance in low-light conditions.\"\n        },\n        {\n            \"text\": \"Adapting to the specific domain of wildlife images is crucial for fine-grained classification.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"embedded devices for real-time performance\",\n        \"deployment_endpoint\": \"cloud-based for accessible deployment\",\n        \"inference_engine\": [\n            \"GPU-accelerated\",\n            \"on-device inference optimization\"\n        ],\n        \"demonstration\": \"Interactive tool that displays breed predictions and segmentation masks\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This response parses the user's instruction into a JSON format, including the requested high-level intent (build) and assumed high expertise level. The project's focus on computer vision, specifically semantic segmentation for cat breed distinction, is clear. It also incorporates advanced techniques, requirements for low-light images, and emphasis on real-time performance. Performance metrics address accuracy, pixel-level accuracy, and inference speed. Complexity metrics address memory usage and inference time. Augmentation, preprocessing, and visualization steps reflect specific requirements. A custom model and dataset are defined, as well as specific fine-tuning and deployment options.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "Create a highly specialized neural machine translation system, utilizing a subset of TED Talks centered on linguistic diversity in indigenous cultures. Implement MARGE (Multi-Aliased Representation for Generalizable Extraction) Transformers, ensuring compatibility for low-power Raspberry Pi devices while achieving near-native translation quality, minimizing latency and reducing both CPU power consumption and model size for optimal battery preservation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"linguistic diversity and indigenous cultures\",\n        \"description\": \"The task is to create a highly specialized neural machine translation system using a subset of TED Talks data focused on linguistic diversity in indigenous cultures. The system should employ MARGE Transformers, be compatible with low-power Raspberry Pi devices, and aim for near-native translation quality with minimized latency, low CPU power consumption, and reduced model size for battery efficiency.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"translation quality\",\n                \"value\": null\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"CPU power consumption\",\n                \"value\": null\n            },\n            {\n                \"name\": \"model size\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time (on Raspberry Pi)\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"TED Talks subset (Linguistic Diversity in Indigenous Cultures)\",\n            \"modality\": [\"text\", \"audio\"],\n            \"target_variables\": [],\n            \"specification\": null,\n            \"description\": \"A subset of TED Talks relevant to linguistic diversity in indigenous cultures, which will serve as the source for training the machine translation system.\",\n            \"preprocessing\": [\"audio-to-text transcription\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"MARGE Transformer-based Neural Machine Translation Model\",\n            \"family\": \"Transformer\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"MARGE Transformers\",\n                \"compatibility\": \"Raspberry Pi\",\n                \"power_consumption_optimization\": true\n            },\n            \"description\": \"A highly specialized model for neural machine translation built with MARGE Transformers, designed for low-power devices like Raspberry Pi.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The model should leverage MARGE's multi-alias representation for more generalizable extraction.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"extracting linguistic features from indigenous data\"],\n        \"target_device\": \"Raspberry Pi\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"custom inference optimized for Raspberry Pi\"],\n        \"demonstration\": \"Translation of indigenous texts with minimal latency and resource consumption\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is generated based on the provided instruction, including details for building a specialized neural machine translation model using TED Talks data. The expertise level is assumed high as the task requires advanced knowledge of neural networks and hardware optimization. Performance metrics for translation quality, latency, and resource consumption are listed as required. Some key information, like exact performance values, was left as null to be determined during the development process.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Utilize the Mouse Brain Connectivity dataset to design a multi-level, hierarchical node classification model employing Graph Wavelet Neural Networks (GWNN), requiring the identification of five distinct neuron types with exceptional precision and recall. Ensure the model integrates deep feature extraction and interprets subtle spatial dependencies, capturing non-local correlations in the brain's intricate connectivity structure.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"neuroscience\",\n        \"description\": \"The task is to design a multi-level, hierarchical node classification model using Graph Wavelet Neural Networks (GWNN) on the Mouse Brain Connectivity dataset. The objective is to identify five different neuron types with high precision and recall, and the model should incorporate deep feature extraction and interpret spatial dependencies, focusing on non-local correlations in the brain's complex connectivity structure.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Mouse Brain Connectivity\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"neuron_type\"],\n            \"specification\": {\n                \"node_count\": null,\n                \"edge_count\": null,\n                \"feature_dimensions\": null\n            },\n            \"description\": \"A graph dataset for node classification, representing the brain's connectivity with focus on extracting multi-level, hierarchical structure and capturing non-local correlations.\",\n            \"preprocessing\": [\"data normalization\", \"node feature extraction\"],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"visualization of node embeddings\",\n                \"interpretability of GWNN decisions\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical GWNN\",\n            \"family\": \"Graph Neural Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"Graph Wavelet Neural Networks\",\n                \"number_of_layers\": null,\n                \"embedding_size\": null,\n                \"readout_layer\": \"multi-label classification\"\n            },\n            \"description\": \"A multi-level, interpretable model built on GWNNs, specifically designed for the Mouse Brain Connectivity dataset to identify five neuron types with precision and recall.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Non-local correlations in brain connectivity are crucial for accurate classification.\",\n        \"Hierarchical structure in GWNNs can capture complex dependencies in the data.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"Graph construction based on brain connectivity data\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"Apache Spark for distributed inference\"\n        ],\n        \"demonstration\": \"interactive visualizations of model performance and brain connectivity\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This JSON response reflects the provided instruction with the user's intent set to build a model, expertise assumed as high, and the focus on graph machine learning with node classification. Graph Wavelet Neural Networks, five neuron types, precision, and recall as performance metrics, as well as preprocessing and interpretability requirements, are all included. However, specific dataset and model details (such as node count, layer structure, and target values) are missing due to their complexity and would typically require additional information to specify.\",\n        \"score\": 0.8\n    }\n}\n"}
{"task": "object detection", "instruction": "Our mission for an elite AI conservation initiative targets the rarely observed 'Cryptozoological Wild Ocean Enclaves' (CWOE) dataset. We require a state-of-the-art object detection model, derived from the ResNeSt-Net architecture, specifically optimized for real-time underwater surveillance. The model must discern not only known marine life but also detect and classify cryptid marine species with minimal environmental noise. It should be lightweight enough for autonomous underwater vehicles (AUVs) with limited computational power, ensuring prolonged operation in the most extreme deep-sea conditions.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"conservation\",\n        \"description\": \"The user requires a state-of-the-art object detection model, specifically ResNeSt-Net, for real-time underwater surveillance of the Cryptozoological Wild Ocean Enclaves (CWOE) dataset. The model should detect and classify known marine life as well as cryptid marine species while being lightweight for autonomous underwater vehicles (AUVs) with limited computational power, ensuring prolonged operation in extreme deep-sea conditions.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time performance\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"model size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Cryptozoological Wild Ocean Enclaves\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"object detection\", \"cryptid species\"],\n            \"specification\": {\n                \"dataset_format\": \"images\",\n                \"image_depth\": \"underwater\",\n                \"environmental_noise\": \"minimal\",\n                \"extreme_conditions\": true\n            },\n            \"description\": \"Dataset for real-time object detection, including both known marine life and cryptid species, for use in autonomous underwater vehicles.\",\n            \"preprocessing\": [\"real-time noise reduction\"],\n            \"augmentation\": [\"underwater image distortions\"],\n            \"visualization\": [\"inspection of detected objects\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"ResNeSt-Net\",\n            \"family\": \"neural networks\",\n            \"type\": \"object detection\",\n            \"specification\": {\n                \"architecture\": \"ResNeSt-Net\",\n                \"optimization_target\": \"real-time performance, lightweight\"\n            },\n            \"description\": \"A state-of-the-art ResNeSt-Net object detection model for underwater surveillance, optimized for AUVs with limited computational resources.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"noise reduction techniques for AUVs\"],\n        \"target_device\": \"AUVs with limited computational power\",\n        \"deployment_endpoint\": \"suitable underwater monitoring system\",\n        \"inference_engine\": [\"optimized for real-time inference\"],\n        \"demonstration\": \"autonomous underwater surveillance demo\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is derived from the given instruction, adhering to the provided schema. The user's intent is to build a model, their high level of expertise is inferred, with the problem being computer vision (object detection) in the context of marine conservation. Key details, such as the dataset, model requirements (ResNeSt-Net, real-time, underwater surveillance), and AUV constraints are clearly defined. Performance metrics, like accuracy and real-time performance, and complexity metrics, like model size and inference time, are specified. However, actual target values for these metrics are left as null to be optimized for.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "text classification", "instruction": "You are working on a specialized text classification project for sentiment analysis using the \"HealthApp User Feedback\" dataset. This contains nuanced reviews of mobile health applications, with labels ranging from 1 (strongly favorable) to -1 (strongly negative). Your objective is to develop a deep learning model with high precision and F1-score, ensuring multi-class interpretability and fine-grained sentiment distinctions.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"healthcare\",\n        \"description\": \"The user is working on a specialized sentiment analysis project using the HealthApp User Feedback dataset. The task involves classifying nuanced reviews of mobile health applications on a scale from 1 (strongly favorable) to -1 (strongly negative). The goal is to develop a deep learning model with a focus on high precision, F1-score, and multi-class interpretability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1-score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"HealthApp User Feedback\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"sentiment\"],\n            \"specification\": {\n                \"label_range\": {\n                    \"strongly_favorable\": 1,\n                    \"strongly_negative\": -1\n                }\n            },\n            \"description\": \"A dataset of mobile health app reviews with nuanced sentiment analysis labels ranging from 1 to -1.\",\n            \"preprocessing\": [\"tokenization\", \"lemmatization\", \"stop words removal\"],\n            \"augmentation\": [\"synonym replacement\", \"random insertion\"],\n            \"visualization\": [\"word clouds\", \"label distribution\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_architecture\": \"e.g., transformer-based (BERT, RoBERTa), convolutional (CNN), or recurrent (LSTM/GRU) with attention mechanisms\"\n            },\n            \"description\": \"A deep learning model for sentiment analysis, with an emphasis on multi-class interpretability and fine-grained distinctions.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"data cleaning, feature engineering\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"API-based deployment for interpretability features\"],\n        \"demonstration\": \"Generated explanations and model performance plots\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response has been structured according to the schema. Intent is 'build' due to the request for model development. Expertise level is 'high' as the task requires a high level of knowledge in ML for deep learning and sentiment analysis. Performance metrics are specified as precision and F1-score, reflecting the goal of high scores. The dataset details are provided, and common text preprocessing and augmentation steps are suggested. The model is expected to be a deep learning neural network. The multi-class interpretability and fine-grained sentiment distinction are addressed in the model description. The confidence score is set to reflect a high level of confidence in the understanding of the task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "The project manager seeks to develop a real-time, high-speed mobile application that utilizes the challenging ImageNet Dogs dataset for fine-grained breed classification. Which advanced deep learning architecture, like Inception-v4 or YOLOv5, would be most suitable to achieve near-human accuracy while maintaining computational efficiency on resource-constrained devices?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"mobile app development\",\n        \"description\": \"The project aims to develop a real-time, high-speed mobile application for fine-grained breed classification using the ImageNet Dogs dataset, with a focus on near-human accuracy and computational efficiency on resource-constrained devices.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": \"optimized\",\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"computational efficiency\",\n                \"value\": \"high\"\n            },\n            {\n                \"name\": \"memory consumption\",\n                \"value\": \"low\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ImageNet Dogs\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"breed\"],\n            \"specification\": {\n                \"dataset size\": null,\n                \"image dimensions\": null,\n                \"number of classes\": \"fine-grained breeds\"\n            },\n            \"description\": \"A challenging dataset for fine-grained breed classification, suitable for real-time mobile app development.\",\n            \"preprocessing\": [\n                \"data augmentation for improved model robustness\"\n            ],\n            \"augmentation\": [\n                \"rotation\",\n                \"flipping\",\n                \"crop\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Inception-v4\",\n            \"family\": \"Inception\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model size\": null,\n                \"number of parameters\": null,\n                \"FLOPs\": null,\n                \"suitability for mobile devices\": \"computational efficiency\"\n            },\n            \"description\": \"A deep learning architecture that balances near-human accuracy and efficiency on resource-constrained devices.\"\n        },\n        {\n            \"name\": \"YOLOv5\",\n            \"family\": \"YOLO\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model size\": null,\n                \"inference speed\": \"real-time\",\n                \"accuracy vs speed trade-off\": \"considered for mobile app\"\n            },\n            \"description\": \"Another advanced model for real-time object detection, potentially suitable for breed classification with efficiency on mobile devices.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Mobile app development constraints and near-human accuracy requirements may drive the choice between a more accurate but resource-intensive model like Inception-v4 or a trade-off model like YOLOv5.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"transfer learning for fast model adaptation to ImageNet Dogs dataset\"\n        ],\n        \"target_device\": \"mobile\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"optimized for mobile devices\"],\n        \"demonstration\": \"real-time performance demonstration on a simulated or actual mobile device\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is based on the user's request for a suitable deep learning model for the specified task. I've assumed high expertise for the user since the task requires a knowledgeable understanding of advanced architectures. Both Inception-v4 and YOLOv5 are mentioned, and the importance of computational efficiency is emphasized. I've included related complexities in the response. However, without further data specifics on the actual target accuracy or device constraints, some details are left open for optimization.\",\n        \"score\": 0.8\n    }\n}"}
{"task": "question answering", "instruction": "As a project manager, request a scalable and high-performance question-answering system using the TriviaQA dataset. Integrate a multi-step reasoning transformer architecture, such as a novel enhancement of GPT-3, capable of tackling factoids and intricate queries. Mandate sub-second response times even with substantial query loads, ensuring optimal efficiency and user experience.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"knowledge management\",\n        \"description\": \"Requesting a scalable and high-performance question-answering system using the TriviaQA dataset, incorporating a multi-step reasoning transformer like an enhanced GPT-3, capable of handling factoids and complex queries. The system should have sub-second response times even under heavy loads for optimal efficiency and user experience.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"response time\",\n                \"value\": \"sub-second\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference efficiency\",\n                \"value\": \"optimized for high query loads\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"TriviaQA\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"answers\", \"queries\"],\n            \"specification\": {\n                \"type\": \"question-answer pairs\"\n            },\n            \"description\": \"A dataset for training a question-answering system, focusing on scalability and handling complex queries.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Enhanced GPT-3 variant\",\n            \"family\": \"transformer\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"multi-step reasoning\",\n                \"performance\": \"high\",\n                \"dataset compatibility\": \"TriviaQA\"\n            },\n            \"description\": \"A state-of-the-art transformer model with a multi-step reasoning enhancement for the TriviaQA dataset, designed for factoid and complex query handling.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"multi-step reasoning integration\"],\n        \"target_device\": \"high-performance computing\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for large query loads\"],\n        \"demonstration\": \"sub-second response times under heavy load\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON represents a project request to build a high-performance QA system using the TriviaQA dataset and enhanced GPT-3-like architecture. The user's expertise is high, and the system requirements include sub-second response times and optimization for heavy loads. The specified performance metrics and complexity constraints are captured in the 'performance_metrics' and 'complexity_metrics' sections respectively. All components are structured according to the provided JSON schema.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "image segmentation", "instruction": "As a healthcare provider handling diverse patient populations, we need a state-of-the-art image segmentation system to categorize not only skin conditions (rashes, moles, and lesions) but also discriminate subtle variations like atopic dermatitis vs. seborrheic keratosis. Can you develop an AI model that integrates deep learning techniques and guarantees high accuracy while handling potential skin tone and image quality inconsistencies in a scalable and user-friendly manner?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"healthcare\",\n        \"description\": \"The task is to develop a state-of-the-art image segmentation system that classifies skin conditions like rashes, moles, and lesions, with a focus on differentiating subtle variations such as atopic dermatitis vs. seborrheic keratosis. The model should incorporate deep learning techniques, achieve high accuracy, handle skin tone variations, and be scalable and user-friendly.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"skin_condition\", \"subtle_variations\"],\n            \"specification\": null,\n            \"description\": \"A dataset containing diverse skin conditions and subtle variations with potential variations in skin tone and image quality.\",\n            \"preprocessing\": [\n                \"skin tone normalization\",\n                \"image quality enhancement\"\n            ],\n            \"augmentation\": [\"data augmentation for skin tone and image quality\"],\n            \"visualization\": [\n                \"intra- and inter-class examples\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning (e.g., U-Net, Mask R-CNN)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"network_architecture\": \"state-of-the-art in skin segmentation\",\n                \"optimizer\": \"suitable for deep learning\",\n                \"architecture_details\": \"handles skin tone variations and image quality inconsistencies\"\n            },\n            \"description\": \"A deep learning model for skin condition and subtle variation segmentation that is robust to skin tone and image quality variations.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Recent advancements in deep learning, especially in the field of segmentation, can be beneficial.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"transfer learning for better skin tone adaptation\",\n            \"lightweight architecture for scalability\"\n        ],\n        \"target_device\": \"mixed, including edge devices for mobile users\",\n        \"deployment_endpoint\": \"cloud-based with a user-friendly interface\",\n        \"inference_engine\": [\"GPU-optimized\", \"mobile-friendly\"],\n        \"demonstration\": \"Live interactive segmentation tool with visual explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response includes the user's intent to build a model, high level of expertise, and details of a computer vision problem in healthcare. The task is to develop a state-of-the-art segmentation model that meets specific requirements. Performance metrics include accuracy, and complexity metrics address scalability and handling of variations. The dataset is described, along with preprocessing and augmentation steps. The model family, deep learning-based, is appropriate for the task. User-friendly deployment and demonstration are also considered.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "For theinoa Corporation's intricate supply chain dataset, develop a high-dimensional node classification model using a Hierarchical Attentive Graph Neural Network (HAGNN). The challenge is to predict supplier categories not only based on transactional data but also on semantic relationships and temporal dependencies. The model should handle millions of nodes with edge attributes, maintaining interpretability while optimizing performance on sparse graphs. Additionally, incorporate a dynamic adaptation mechanism to handle seasonal fluctuations in demand and industry-specific regulations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"supply chain management\",\n        \"description\": \"The task is to develop a high-dimensional node classification model using a Hierarchical Attentive Graph Neural Network (HAGNN) for the Intheoan Corporation's supply chain dataset. The model should predict supplier categories based on transactional data, semantic relationships, and temporal dependencies. It must handle large graphs with millions of nodes and edge attributes, prioritize interpretability, and incorporate a dynamic adaptation mechanism to address seasonal demand fluctuations and industry-specific regulations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability_score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory_usage\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            },\n            {\n                \"name\": \"sparsity Handling\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Intheoan Corporation's Supply Chain Dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"supplier_categories\"],\n            \"specification\": {\n                \"node_count\": null,\n                \"edge_count\": null,\n                \"edge_attributes\": true,\n                \"time_series_dimensionality\": null\n            },\n            \"description\": \"A high-dimensional dataset containing transactional, semantic relationship, and temporal data for millions of nodes in the supply chain. Edge attributes are present, and the model must account for seasonal demand fluctuations and industry regulations.\",\n            \"preprocessing\": [\n                \"handling_sparse_data\",\n                \"extracting_temporal_features\",\n                \"semantic_feature_extraction\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"interpretable_graph_vis\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"HAGNN Model\",\n            \"family\": \"Graph Neural Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"Hierarchical Attentive Graph Neural Network\",\n                \"parameter_count\": null,\n                \"flops\": null,\n                \"training_speed\": null,\n                \"inference_performance\": null\n            },\n            \"description\": \"A node classification model using HAGNN that handles large graphs, edge attributes, and includes interpretability features and dynamic adaptation mechanisms.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Dynamic adaptation for handling seasonal demand and industry regulations.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"node_embedding\",\n            \"edge_weight_encoding\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"custom_container\",\n        \"inference_engine\": [\"GPU optimized\"],\n        \"demonstration\": \"interactive供给链预测与解释仪表板\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the given instruction, describing a node classification task using HAGNN for a large-scale supply chain dataset. It reflects the user's high expertise level. Key requirements like handling large graphs, interpretability, and dynamic adaptation are captured in the model and dataset properties. Performance metrics account for accuracy and potential interpretability. The service section covers aspects like target device, deployment, and demo requirements.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "text classification", "instruction": "You are tackling a sophisticated text classification challenge with the AI-aided Dataset named \"Multilayered Sentiment Analysis Corpus.\" The task requires a deep analysis of input sentences to classify them into one of eight nuanced labels (0 to 7), considering context and linguistic intricacies. Your objective is to optimize a high-performance, multi-step language model, ensuring interpretability and evaluating using macro-averaged F1 score for a comprehensive evaluation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"sentiment analysis\",\n        \"description\": \"The user is tackling a complex text classification challenge using the 'Multilayered Sentiment Analysis Corpus' dataset. The task involves classifying sentences into eight nuanced labels, considering context and linguistic intricacies, with a focus on optimizing a high-performance, multi-step language model and evaluating using macro-averaged F1 score.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"macro-averaged F1 score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Multilayered Sentiment Analysis Corpus\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"sentiment_label\"],\n            \"specification\": {\n                \"num_labels\": 8\n            },\n            \"description\": \"A dataset for text classification with nuanced sentiment labels (0 to 7), requiring a deep analysis of sentences and linguistic complexities.\",\n            \"preprocessing\": [\"contextual embeddings\", \"tokenization\"],\n            \"augmentation\": [],\n            \"visualization\": [\"interpretability analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks (specifically, deep learning models like BERT, LSTM, or Transformer)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"interpretability\": true\n            },\n            \"description\": \"A sophisticated multi-step language model optimized for high-performance text classification in a nuanced sentiment analysis task, ensuring interpretability and using macro-averaged F1 score as the evaluation metric.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Contextual understanding is crucial in this dataset, so utilize pre-trained models with contextual embeddings for better feature extraction.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature selection based on interpretability\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU for faster training and deployment\"],\n        \"demonstration\": \"Create visual explanations of model predictions and decision-making process.\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response covers the details from the instruction. The intention is to build a high-performance model as specified by the 'expertise' field. The dataset and task information are well-defined, focusing on multi-class classification and emphasizing interpretability and macro-F1 evaluation. Some details like target device and deployment specifics are left unspecified based on the provided information.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "community detection", "instruction": "As a community detection expert in the field of bioinformatics, I am seeking a unique and intricate project to analyze the extensive yeast protein-protein interaction (PPI) network using machine learning techniques. Can you propose a comprehensive, yet accessible, approach that combines unsupervised learning with network embedding, specifically focusing on detecting transient and overlapping communities with limited computational resources, while maintaining interpretability for a novice developer?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"community detection\",\n        \"application_domain\": \"bioinformatics\",\n        \"description\": \"The user, an expert in community detection, wants to analyze a yeast protein-protein interaction (PPI) network using a machine learning approach that combines unsupervised learning and network embedding. The focus should be on detecting transient and overlapping communities with limited computational resources, while maintaining interpretability for a novice developer.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"computational efficiency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"minutes\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Yeast PPI Network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"nodes\": {\n                    \"nodes_count\": null,\n                    \"features\": \"protein properties\"\n                },\n                \"edges\": {\n                    \"edges_count\": null,\n                    \"edges_types\": \"protein-protein interactions\"\n                }\n            },\n            \"description\": \"An extensive network of yeast protein-protein interactions\",\n            \"preprocessing\": [\n                \"node features extraction\",\n                \"network cleaning\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"network visualization\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical Clustering & Node2Vec\",\n            \"family\": \"unsupervised learning & network embedding\",\n            \"type\": \"graph machine learning\",\n            \"specification\": {\n                \"model_type\": \"graph neural networks\",\n                \"dimensions\": null,\n                \"learning_method\": \"unsupervised\",\n                \"complexity_tradeoff\": \"transient and overlapping communities\"\n            },\n            \"description\": \"A model that employs Node2Vec for network embedding and hierarchical clustering to detect communities with interpretability for a novice developer.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Expertise in bioinformatics, specifically yeast PPI networks\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"limited-resource optimization\"],\n        \"target_device\": \"medium-sized server\",\n        \"deployment_endpoint\": \"local development environment\",\n        \"inference_engine\": [\"efficient distributed computation\"],\n        \"demonstration\": \"step-by-step tutorial or interactive Jupyter notebook\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is crafted based on the user's instruction, with the 'intent' set to 'build' reflecting the desire for a project proposal. The expert's 'expertise' is high, reflecting their knowledge in the field. The project combines unsupervised learning with network embedding, and the focus on transient and overlapping communities, computational resources, and interpretability is taken from the user's requirements. Performance and complexity metrics are included, acknowledging the need for accuracy and resource constraints.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "Develop a convolutional neural network (CNN) architecture, trained on the CIFAR-10 dataset, with a rigorous focus on achieving superhuman performance (human expert-level accuracy) while maintaining a high interpretability index and utilizing advanced regularization techniques to combat overfitting, ensuring robustness across diverse image subcategories.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"image recognition or computer vision\",\n        \"description\": \"The user wants to build a CNN architecture for image classification on the CIFAR-10 dataset. The goal is to achieve superhuman (expert-level) accuracy, prioritize interpretability, and use advanced regularization techniques to prevent overfitting, ensuring robustness across different image subcategories.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"interpretability_index\",\n                \"value\": null,\n                \"unit\": \"index\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"CIFAR-10\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"image_category\"],\n            \"specification\": null,\n            \"description\": \"The CIFAR-10 dataset for image classification, consisting of diverse image subcategories.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [\"interpretability\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Convolutional Neural Network\",\n            \"family\": \"CNN\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"interpretability_techniques\": [\n                    \"attention mechanisms\", \n                    \"visualization tools\"\n                ],\n                \"regularization_techniques\": [\n                    \"dropout\",\n                    \"data augmentation\"\n                ]\n            },\n            \"description\": \"A CNN architecture with a focus on achieving expert-level accuracy, interpretability, and advanced regularization for the CIFAR-10 dataset.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"preferably visually interpretable\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is structured based on the given instruction. The user's intent is to build a model, and their expertise is assumed to be high due to the need for superhuman performance. The area of research is computer vision, and the task is image classification on the CIFAR-10 dataset. The performance metric is accuracy, and interpretability is mentioned as a requirement. Regularization techniques are included to combat overfitting. The response assumes a CNN architecture with interpretablility techniques and regularization methods.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "For a sophisticated image recognition project, develop a state-of-the-art deep learning model capable of differentiating not only between cats and dogs but also distinguishing between 10 specific breeds of each species, ensuring high accuracy and real-time processing for live video input.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"computer vision or image recognition\",\n        \"description\": \"The user requires a sophisticated image recognition project with the objective of creating a deep learning model that accurately differentiates between cats and dogs, as well as ten specific breeds of each, ensuring real-time processing for live video input.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"real-time processing\",\n                \"value\": true\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"breed\"],\n            \"specification\": {\n                \"multiclass_labels\": true,\n                \"specific_breeds\": [\"10 specific breeds for cats and dogs\"]\n            },\n            \"description\": \"A dataset for training a deep learning model with live video input, containing images of cats and dogs, each with fine-grained breed labels for high accuracy.\",\n            \"preprocessing\": [\"image augmentation for live video\"],\n            \"augmentation\": [\"real-time data augmentation\"],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"state-of-the-art\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"deep convolutional neural network\",\n                \"specific_layer_info\": \"presumably includes advanced layers for fine-grained recognition\"\n            },\n            \"description\": \"A deep learning model using advanced CNN architecture designed for high accuracy in distinguishing between cats, dogs, and 10 specific breeds in real-time.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Transfer learning may be beneficial for faster training and improved performance.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"image preprocessing for live video\"],\n        \"target_device\": \"suitable for real-time processing\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"real-time inference\"],\n        \"demonstration\": \"High-accuracy live video demonstration of breed identification\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is crafted based on the given instruction, focusing on 'build' intent, 'high' expertise, and a 'computer vision' area for developing a deep learning model for real-time image recognition. Performance metric is accuracy, with specific breeds as a requirement. Inference time is crucial due to real-time processing, and dataset needs to support live video and image augmentation. The model family and type are assumed to be state-of-the-art CNN for high accuracy. Transfer learning is a knowledge piece that could help to address the complexity of the problem.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "The machine learning team must develop a real-time, high-precision car model recognizer for crowded and dimly lit parking lot surveillance. Utilize the COCO and Pascal VOC datasets, ensuring transfer learning from larger imagenet pre-trained models while accommodating resource constraints for real-world deployment on low-end hardware. Provide a comparative analysis of their suitability and justify your choice.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"security/surveillance\",\n        \"description\": \"The objective is to develop a real-time car model recognizer for crowded and dimly lit parking lot surveillance. This requires high precision and should leverage COCO and Pascal VOC datasets, with transfer learning from pre-trained ImageNet models while accounting for resource constraints for deployment on low-end hardware.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"inference speed\",\n                \"value\": null,\n                \"unit\": \"fps\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"CPU utilization\",\n                \"value\": null,\n                \"unit\": \"%\"\n            },\n            {\n                \"name\": \"GPU utilization\",\n                \"value\": null,\n                \"unit\": \"%\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"COCO dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"car models\"],\n            \"specification\": {\n                \"objects_of_interest\": \"car models\",\n                \"pre-existing_labels\": {\n                    \"background\": \"\",\n                    \"car_models\": []\n                }\n            },\n            \"description\": \"A large-scale dataset for object detection, with potential for transfer learning and car model recognition.\",\n            \"preprocessing\": [\"image resizing and normalization\"],\n            \"augmentation\": [\"random cropping and horizontal flipping\"],\n            \"visualization\": [\"object detection heatmaps\"],\n            \"source\": \"user-link\"\n        },\n        {\n            \"name\": \"Pascal VOC dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"car models\"],\n            \"specification\": {\n                \"objects_of_interest\": \"car models\",\n                \"pre-existing_labels\": {\n                    \"background\": \"\",\n                    \"car_models\": []\n                }\n            },\n            \"description\": \"Another popular dataset for object detection, supporting car model recognition through transfer learning.\",\n            \"preprocessing\": [\"image resizing and normalization\"],\n            \"augmentation\": [\"random cropping and flipping\"],\n            \"visualization\": [\"object detection heatmaps\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"transfer learning (ImageNet-pretrained CNN)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"e.g., EfficientNet, MobileNet, or YOLO\",\n                \"pre-trained model size\": null,\n                \"fine-tuning layers\": \"last few layers\",\n                \"inference speed on low-end hardware\": null\n            },\n            \"description\": \"A high-precision car model recognizer, utilizing transfer learning from ImageNet-pretrained CNN, tailored for real-world deployment on low-end hardware.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"low-end hardware\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"e.g., TensorFlow Lite, ONNX Runtime\"],\n        \"demonstration\": \"Explanation of inference pipeline with real-time processing\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The information is parsed based on the task, specifying a 'build' intent with high-level expertise. The problem lies in computer vision, with object detection as the downstream task. COCO and Pascal VOC datasets are included, along with transfer learning and resource constraints. Performance is emphasized on precision, inference speed, memory usage, and CPU/GPU utilization. Models are expected to suit low-end hardware deployment.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "question answering", "instruction": "As a project manager, you are tasked with developing a sophisticated, interactive question-answering platform designed specifically for early learners. Utilize the diverse and age-appropriate KidsQA dataset to train a highly customized BERT model, ensuring its explanations are not only simple and clear but also promote cognitive development. The user interface must integrate playful animations and intuitive controls, catering to the curiosity and creativity of young minds, while maintaining an educational focus.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"education\",\n        \"description\": \"The task is to develop an interactive question-answering platform for early learners using the KidsQA dataset. The platform should train a customized BERT model with explanations tailored for children, promoting cognitive development. The design should include playful animations, intuitive controls, and maintain an educational focus.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"explainability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"cognitive development impact\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"UI/UX for children\",\n                \"value\": null,\n                \"unit\": \"user-friendly\"\n            },\n            {\n                \"name\": \"Inference time on mobile devices\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"KidsQA dataset\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"questions\", \"answers\", \"explanations\"],\n            \"specification\": {\n                \"age appropriateness\": \"early learners\",\n                \"diversity\": \"age, education levels, and topics\"\n            },\n            \"description\": \"A diverse age-appropriate dataset for training a BERT model for early learners with emphasis on cognitive development.\",\n            \"preprocessing\": [\n                \"Age-appropriate text simplification\",\n                \"Tokenization for BERT model\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"customized BERT\",\n            \"family\": \"neural networks\",\n            \"type\": \"transformer-based\",\n            \"specification\": {\n                \"adapter-based explanation mechanism\": true,\n                \"simple and clear explanations\": true\n            },\n            \"description\": \"A highly customized BERT model specifically designed for the early learning question-answering platform.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"name\": \"Cognitive development theories and best practices for early learning interfaces\",\n            \"description\": \"The importance of keeping explanations simple and promoting cognitive growth in young learners.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"playful animations\", \"intuitive controls\"],\n        \"target_device\": [\"mobile\", \"tablet\", \"touchscreen devices\"],\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"lightweight, optimized for real-time response\"],\n        \"demonstration\": \"Education-focused and engaging user experience\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure adheres to the provided schema and captures the user's intent (building a platform) with high-level expertise. The areas of focus (NLP, QA, education, and early learners) are clearly defined. Performance metrics and complexity requirements are specified based on the requirements. However, more specific performance targets and UI/UX details might be beneficial for clarity.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "You are now working on a specialized time-series forecasting challenge for smart city traffic prediction using the \"TrafficDensity-2022\" dataset. This dataset consists of historical data collected from various sensors over 18 months, with hourly resolution. The train, validation, and test sets consist of non-overlapping seasonal patterns (considering 4-weekly cycles) and have unique input sequences of past 16 weeks (INPUT_SEQ_LEN=2016, excluding weekends) and 862 different traffic indicator variables. Your objective is to design a hybrid deep learning model (ARIMA-RNN) that forecasts the next 16 weeks' traffic patterns (PRED_SEQ_LEN=2016) while capturing long-term dependencies and local trends. Ensure to report performance with daily MAPE and weekly MSE, focusing on peak hours' accuracy.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"smart city\",\n        \"description\": \"The task is to develop a hybrid deep learning model (ARIMA-RNN) for smart city traffic prediction using the 'TrafficDensity-2022' dataset. The model should forecast the next 16 weeks' traffic patterns while considering long-term dependencies and local trends. Performance evaluation should include daily mean absolute percentage error (MAPE) and weekly mean squared error (MSE), with a focus on peak hours accuracy.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"daily MAPE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"weekly MSE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"TrafficDensity-2022\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 2016,\n                \"excluding_weekends\": true,\n                \"num_of_variables\": 862,\n                \"seasonal_pattern_frequency\": \"4-weekly\"\n            },\n            \"description\": \"A historical traffic dataset with hourly resolution for 18 months, containing data from various sensors. The train, validation, and test sets have non-overlapping seasonal patterns and unique input sequences of the past 16 weeks (excluding weekends).\",\n            \"preprocessing\": [\"handling missing values\", \"seasonality adjustment\"],\n            \"augmentation\": [],\n            \"visualization\": [\"visualizing seasonal patterns\", \"input sequence patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"ARIMA-RNN\",\n            \"family\": \"hybrid deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"ARIMA component for long-term dependencies, RNN component for local trends\",\n                \"input_length\": 2016,\n                \"output_length\": 2016,\n                \"model_structure\": \"long short-term memory (LSTM) or gated recurrent unit (GRU)\"\n            },\n            \"description\": \"A hybrid model combining ARIMA and RNN for accurate traffic density forecasting, accounting for both long-term trends and local variations.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"lagged features for time series analysis\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for real-time or batch inference\"],\n        \"demonstration\": \"visualizing forecast results for peak hours\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure accurately reflects the provided instruction, capturing the task of building a hybrid model for traffic prediction, the dataset specifications, and the performance metrics. The model is appropriately specified as an ARIMA-RNN, with focus on performance in peak hours. Assumptions are made about feature engineering and inference strategies, and a rationale is provided.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "text classification", "instruction": "You are now tackling a sophisticated text classification challenge, involving the BoolQ dataset enhanced with context-specific heuristics. The objective is to design a multistep reasoning model that not only differentiates if a question is derivable from a passage (0 for inconclusive, 1 for affirmative), but also analyzes the supporting evidence within the text. Emphasize on enhancing precision and recall, while maintaining a detailed explanation of the model's decision-making process for human auditing. Develop and fine-tune the model, ensuring its robustness across various question complexity levels.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"information retrieval\",\n        \"description\": \"The user is tackling a text classification challenge with the BoolQ dataset, which requires a multistep reasoning model to determine if a question can be derived from a passage (0 for inconclusive, 1 for affirmative). The model must analyze supporting evidence and emphasize precision and recall, with a focus on providing a detailed explanation for human auditing, especially across varying question complexity levels.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"BoolQ (enhanced with context-specific heuristics)\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"is_derivable\"],\n            \"specification\": {\n                \"question_structure\": \"multistep reasoning\",\n                \"question_complexity_levels\": null\n            },\n            \"description\": \"A text dataset with the challenge of differentiating if a question is derivable from a passage, emphasizing precision and recall, and requiring detailed explanation for human auditing.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks (e.g., BERT-based or transformer models)\",\n            \"type\": \"multistep reasoning, sequence-to-sequence\",\n            \"specification\": {\n                \"architecture\": \"explainable, interpretable components\",\n                \"models_fine_tuning\": \"yes\"\n            },\n            \"description\": \"A multistep reasoning model, possibly using an explainable variant of a deep learning model (like BERT) for text classification and analysis of supporting evidence on the BoolQ dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Context-specific heuristics will be incorporated to enhance the model's performance and robustness across various question complexity levels.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": {\n            \"format\": \"structured explanations and visualizations of model decision-making\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is based on the given instruction, specifying a 'build' intent and a 'high' level of expertise. The problem area is NLP and downstream task is text classification. BoolQ dataset with context-specific heuristics is correctly incorporated, and the emphasis on precision, recall, explainability, and robustness to question complexity is reflected. However, some values for performance metrics and complexity metrics remain unspecified for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "Develop a cutting-edge visual question answering platform integrating the Flickr30k dataset with a highly specialized Visual Transformer. Emphasize on multimodal reasoning, social context, and fine-grained details. Strive for a benchmark accuracy of 75% while ensuring interactive and immersive user experience, fostering diverse scenarios and cultural understanding.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"education and entertainment\",\n        \"description\": \"The task is to develop a visual question answering platform that integrates the Flickr30k dataset, utilizes a specialized Visual Transformer, focuses on multimodal reasoning, social context, and fine-grained details. The aim is to achieve a benchmark accuracy of 75% with an interactive and immersive user experience, supporting diverse scenarios and cultural understanding.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.75\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Flickr30k\",\n            \"modality\": [\"image\", \"text\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"dataset_size\": \"specific size not mentioned\",\n                \"multimodal_data\": true,\n                \"fine-grained\": true\n            },\n            \"description\": \"A dataset to be integrated for visual question answering, emphasizing multimodal, social context, and fine-grained details.\",\n            \"preprocessing\": [\"multimodal fusion\", \"contextualization\"],\n            \"augmentation\": [\"social media data enrichment\"],\n            \"visualization\": [\"data distribution and co-attention maps\"],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Visual Transformer\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_architecture\": \"Visual Transformer\",\n                \"multimodal_reasoning\": true,\n                \"fine-grained_inference\": true\n            },\n            \"description\": \"A highly specialized Visual Transformer model for visual question answering, with a focus on multimodal reasoning and complex features.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Multimodal reasoning techniques\",\n        \"Social context incorporation in VQA models\",\n        \"Fine-grained details extraction from visual data\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"context-aware feature extraction\", \"user interaction modeling\"],\n        \"target_device\": \"interactive and immersive platforms\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized for speed\"],\n        \"demonstration\": \"immersive QA experience with diverse scenarios\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response adheres to the given instruction, detailing the requirements for the development project, including the target dataset, the specialized model (Visual Transformer), performance goal (75% accuracy), and the focus on various aspects like multimodality, social context, and fine-grained details. The provided dataset specifics and model characteristics cater to the instruction's context. The response omits exact complexity metric values as they are not specified in the given instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "For the upcoming plant health monitoring project, we need the machine learning team to develop a deep, explainable DenseNet model with multi-scale attention mechanisms. The challenge is to segment leaf images from the highly diverse PlantVillage dataset with sub-regional accuracy, differentiating subtle disease signs from healthy tissue. The model's interpretability must provide intuitive visualizations for end-users with minimal technical background in plant biology.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"plant health monitoring\",\n        \"description\": \"The task is to develop a deep, explainable DenseNet model with multi-scale attention mechanisms for segmenting leaf images from the PlantVillage dataset. The objective is to achieve sub-regional accuracy, distinguishing subtle disease signs from healthy tissue, and ensure the model's interpretability provides intuitive visualizations for non-technical end-users in plant biology.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"sub-regional segmentation\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"interpretability\",\n                \"value\": null,\n                \"unit\": \"user-friendly visualizations\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"PlantVillage dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"leaf_segmentation\"],\n            \"specification\": {\n                \"image_diversity\": \"high\",\n                \"sub-regional_level\": \"required\"\n            },\n            \"description\": \"A highly diverse dataset for leaf image segmentation, with the goal of differentiating subtle disease signs from healthy tissue.\",\n            \"preprocessing\": [\n                \"data augmentation\",\n                \"multi-scale image normalization\"\n            ],\n            \"augmentation\": [\"random cropping\", \"rotations\"],\n            \"visualization\": [\n                \"model attention maps\",\n                \"interpretable explanations\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"DenseNet with Multi-scale Attention\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"explainability\": \"high\",\n                \"model_architecture\": \"DenseNet\",\n                \"attention_mechanisms\": \"multi-scale\"\n            },\n            \"description\": \"A deep and interpretable DenseNet model incorporating multi-scale attention mechanisms for leaf image segmentation in PlantVillage dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"End-users require non-technical visualizations\",\n        \"Focus on subtle disease signs identification\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"data preprocessing for model training\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"integrated interpretability tools\"],\n        \"demonstration\": \"interactive visualizations for users\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON response is based on the given instruction, explaining the high-level task, the model requirements, dataset details, and performance metrics. It also accounts for the user's high expertise level and the need for explainability for end-users. Some details, like the target device and specific metric values, are left unspecified as they were not provided in the original instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series classification", "instruction": "Your task, as a time-series classification expert, is to develop a state-of-the-art LSTM-CNN fusion model for the \"Food Quality Monitoring\" dataset. This dataset contains intricate patterns over a long-term horizon (TIME_STEP=1000, CHANNELS=6), capturing temperature and pH fluctuations. The train, validation, and test partitions have unique temporal dependencies. Your goal is to optimize F1-score, accounting for class imbalance (labels {Poor, Average, Good}), by adaptively adjusting the model architecture for seasonality and non-stationarity. Ensure peak performance on unseen sequences.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"food quality monitoring\",\n        \"description\": \"As a time-series classification expert, the task is to develop a state-of-the-art LSTM-CNN fusion model for the Food Quality Monitoring dataset, which features complex patterns over a long horizon. The model must handle intricate dependencies between train, validation, and test partitions with different temporal characteristics. The main focus is on optimizing F1-score, addressing class imbalance (labels: Poor, Average, Good), and adapting to seasonality and non-stationarity.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1-score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Food Quality Monitoring\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"quality\", \"temp\", \"pH\"],\n            \"specification\": {\n                \"TIME_STEP\": 1000,\n                \"CHANNELS\": 6\n            },\n            \"description\": \"A dataset capturing temperature and pH fluctuations over a long term with a focus on food quality, split into train, validation, and test sets with unique temporal dependencies.\",\n            \"preprocessing\": [\"seasonality adjustment\", \"non-stationarity normalization\"],\n            \"augmentation\": [],\n            \"visualization\": [\"data patterns and dependencies\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"LSTM-CNN Fusion\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"LSTM-CNN fusion model\",\n                \"architecture_details\": \"Adaptation for seasonality and non-stationarity\"\n            },\n            \"description\": \"A state-of-the-art model for time-series classification, specifically designed for the Food Quality Monitoring dataset with a focus on addressing class imbalance and optimizing F1-score.\"\n        }\n    ],\n    \"knowledge\": [\"Adapted model architectures for time-series data accounting for seasonality and non-stationarity\"],\n    \"service\": {\n        \"feature_engineering\": [\n            \"class_weight adjustment for imbalance\",\n            \"dynamic architecture tuning\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Performance analysis on unseen sequences\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is derived from the user's instruction, following the provided schema. The intent is set to 'build' and expertise level to 'high' as the user is an expert. The Food Quality Monitoring dataset, LSTM-CNN fusion, and focus on F1-score, class imbalance, and adaptive architecture are clearly described. The steps for preprocessing and fine-tuning the model are included based on the requirements.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "In a groundbreaking project for the healthcare domain, our research team seeks to develop a novel Node2Vec model adapted for protein-protein interaction networks. The objective is to predict functional relationships between proteins with exceptional precision, especially for rare diseases. The dataset encompasses millions of interconnected proteins, so the model must surpass a state-of-the-art accuracy of 95% and seamlessly incorporate streaming data from continuous lab experiments. Moreover, the model must optimize for low computational complexity to minimize the impact on resource-intensive high-throughput labs.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"healthcare\",\n        \"description\": \"A team is seeking to develop a Node2Vec model adapted for protein-protein interaction networks in the healthcare domain. The goal is to predict functional protein relationships with high precision, particularly for rare diseases. The model must achieve a state-of-the-art accuracy of 95%+, handle streaming data from continuous lab experiments, and optimize for low computational complexity.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.95\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"min\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Protein-Protein Interaction Network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"functional_relationship\"],\n            \"specification\": {\n                \"number_of_nodes\": \"millions\",\n                \"edge_type\": \"protein-protein interactions\"\n            },\n            \"description\": \"A large-scale dataset containing interconnected proteins for protein-protein interaction research.\",\n            \"preprocessing\": [\"data normalization\", \"node feature extraction\"],\n            \"augmentation\": [],\n            \"visualization\": [\"graph structure analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Node2Vec adaptation\",\n            \"family\": \"graph embedding\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"adapted Node2Vec\",\n                \"accuracy_target\": 0.95,\n                \"streaming_data_integration\": true\n            },\n            \"description\": \"A custom Node2Vec model optimized for protein-protein interaction networks with focus on precision, streaming data integration, and low computational complexity.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"type\": \"challenge\",\n            \"content\": \"Addressing rare diseases with high precision necessitates fine-tuning and domain expertise.\"\n        },\n        {\n            \"type\": \"resource\",\n            \"content\": \"Collaborate with high-throughput labs to understand and optimize computational requirements.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"protein feature extraction\", \"context-aware feature enhancements\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"high-performance cluster or API service\",\n        \"inference_engine\": [\"graph-based\", \"GPU-accelerated\"],\n        \"demonstration\": \"Interactive visual analysis of model predictions on rare disease cases\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response represents a well-defined machine learning project with a high level of expertise required. It reflects the problem area (graph ML), task (node classification), accuracy target, streaming data handling, and computational complexity optimization. The knowledge and service requirements align with the specifics of the healthcare domain and the lab's constraints.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "multimodal emotion recognition", "instruction": "As a project manager for a cross-modal emotion recognition team, we need to integrate the IEMOCAP dataset, focusing on subtle expressions and context. Compare and propose models robust to acoustic, visual, and textual cues while maintaining interpretability, adhering to industry privacy regulations, and optimizing for real-time performance on a mobile device.", "resposne": "{\n    \"user\": {\n        \"intent\": \"consult-build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"multimodal emotion recognition\",\n        \"application_domain\": \"cross-modal AI applications\",\n        \"description\": \"The project aims to integrate the IEMOCAP dataset for emotion recognition, particularly focusing on subtle expressions and context. Models should be comparative, robust to acoustic, visual, and textual cues, interpretable, comply with industry privacy regulations, and optimized for real-time performance on mobile devices.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time performance\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"privacy compliance\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"IEMOCAP dataset\",\n            \"modality\": [\"audio\", \"image\", \"text\"],\n            \"target_variables\": [\"emotion\"],\n            \"specification\": {\n                \"subtle_expressions\": true,\n                \"contextual_data\": true\n            },\n            \"description\": \"A dataset for emotion recognition, focusing on subtle expressions and context across audio, visual, and textual cues.\",\n            \"preprocessing\": [\"handling privacy-sensitive data\"],\n            \"augmentation\": [\n                \"mobile-friendly data augmentation techniques\"\n            ],\n            \"visualization\": [\"model interpretability visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"comparative model (e.g., fusion models)\",\n            \"type\": \"ensemble models\",\n            \"specification\": {\n                \"acoustic_inclusion\": true,\n                \"visual_inclusion\": true,\n                \"textual_inclusion\": true,\n                \"interpretability_techniques\": null\n            },\n            \"description\": \"A model that integrates acoustic, visual, and textual cues for emotion recognition with a focus on interpretability and real-time performance on mobile devices.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Privacy-preserving techniques (e.g., differential privacy, federated learning) should be considered.\",\n        \"Utilize lightweight and efficient neural network architectures for mobile deployment.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"extracting relevant features for each modality\"\n        ],\n        \"target_device\": \"mobile devices\",\n        \"deployment_endpoint\": \"specific deployment platform supporting real-time performance on mobile\",\n        \"inference_engine\": [\"optimized inference frameworks for mobile devices\"],\n        \"demonstration\": \"emotion recognition in real-time on a mobile device\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response captures the essence of the project manager's requirements, providing advice for integrating IEMOCAP, handling multiple modalities, interpretability, privacy, and real-time performance on mobile. Performance and complexity metrics are left unspecified for optimization, acknowledging the open-ended nature of the consultation.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "tabular classification", "instruction": "In a multiclass tabular insurance risk assessment project, analyze a fine-grained dataset of 10,000 clients with encrypted financial records. Develop domain-specific features from transaction events, credit scores, and economic indicators. Employ ensemble techniques and interpretability methods for a top-tier AUC-ROC on a quarterly churn prediction task, ensuring regulatory compliance with GDPR guidelines.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"tabular data analysis\",\n        \"downstream_task\": \"tabular classification\",\n        \"application_domain\": \"insurance\",\n        \"description\": \"The user wants to conduct a multiclass tabular data analysis for an insurance risk assessment project. The dataset consists of 10,000 clients with encrypted financial records, and the goal is to develop domain-specific features from transaction events, credit scores, and economic indicators. Ensemble techniques and interpretability methods are required to achieve high AUC-ROC for quarterly churn prediction, and it must comply with GDPR guidelines.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Fine-Grained Insurance Dataset\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"churn\"],\n            \"specification\": {\n                \"size\": 10000,\n                \"structured\": true,\n                \"encrypted\": true\n            },\n            \"description\": \"A 10,000-client dataset with encrypted financial records, containing transaction events, credit scores, and economic indicators for quarterly churn prediction.\",\n            \"preprocessing\": [\"feature engineering from transaction events, credit scores, and economic indicators\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"ensemble models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"interpretability\": true\n            },\n            \"description\": \"An ensemble of machine learning models for tabular data analysis, designed for a high-level quarterly churn prediction task in the insurance industry, with a focus on interpretability and AUC-ROC performance.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Regulatory compliance with GDPR guidelines must be considered throughout the project.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Quarterly performance updates and interpretability analyses\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the main aspects of the user's instruction, including the project area (tabular data analysis), the task (churn prediction), the requirements for data pre-processing and ensemble techniques, and the need for interpretability in line with GDPR. The user's high expertise level suggests a focus on selecting appropriate methods for a complex project. However, specific model details, feature engineering steps, and performance targets are not explicitly provided, leaving room for interpretation.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "object detection", "instruction": "For a cutting-edge underwater archeological exploration project, we require a highly specialized object detection system capable of recognizing ancient artifacts, marine life, and potential hazards in real-time. The model, built on a proprietary dataset integrating high-resolution underwater imagery and historical artifact documentation, should belong to the YOLOv4 architecture for its enhanced precision. The system must achieve a near-zero false positive rate (<0.05%) and maintain sub-second detection speed (ideally under 10 milliseconds per frame) while operating within the constraints of limited underwater bandwidth and power availability.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"underwater archeology\",\n        \"description\": \"A highly specialized object detection system is needed for real-time recognition of ancient artifacts, marine life, and potential hazards in underwater environments. The model should be based on the YOLOv4 architecture and built on a proprietary dataset combining high-resolution underwater imagery and historical artifact documentation.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"false positive rate\",\n                \"value\": 0.0005\n            },\n            {\n                \"name\": \"detection speed\",\n                \"value\": 10.0,\n                \"unit\": \"milliseconds per frame\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"bandwidth constraints\",\n                \"value\": \"limited\"\n            },\n            {\n                \"name\": \"power availability\",\n                \"value\": \"limited\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Proprietary Underwater Archaeology Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"artifact\", \"marine life\", \"hazards\"],\n            \"specification\": {\n                \"image_resolution\": \"high\",\n                \"data_integration\": \"historical artifact documentation\"\n            },\n            \"description\": \"Underwater imagery dataset combined with historical artifact information for object detection training.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"YOLOv4\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"YOLOv4\",\n                \"precision\": \"high\",\n                \"accuracy\": \"optimized for precision\"\n            },\n            \"description\": \"A YOLOv4 model tailored for underwater artifact detection, achieving near-zero false positive rate and high detection speed.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"specialized for underwater operation\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"real-time performance showcasing on limited bandwidth and power conditions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response captures the requirements specified in the instruction. The intent is to build, the expertise is assumed to be high due to the complexity of the task. The area of focus is computer vision, specifically object detection. Performance metrics are set to have a near-zero false positive rate and fast detection speed. The dataset combines underwater imagery with historical artifact information. Specific model details adhere to the YOLOv4 architecture for enhanced precision. The project's constraints regarding bandwidth and power are accounted for.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "Develop a specialized RNN-based neural machine translation model, utilizing the domain-specific OPUS-XLNT corpus for English to Russian conversational and colloquial translation. Strive for a BLEU score of 35, while demonstrating superior accuracy in deciphering regional slang and non-standard phrases. Prioritize minimizing model latency to an average of 270 milliseconds per sentence, ensuring a seamless and real-time translation experience for users in fast-paced online chats.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"conversational AI\",\n        \"description\": \"The user aims to develop a specialized RNN-based neural machine translation model for English to Russian translations, focusing on conversational and colloquial content. They desire a BLEU score of 35, prioritizing accuracy in understanding regional slang and non-standard phrases. Additionally, the model's latency should be minimized to an average of 270 milliseconds per sentence for real-time experience in online chats.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"BLEU score\",\n                \"value\": 35\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"average latency per sentence\",\n                \"value\": 0.27,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"OPUS-XLNT corpus (English to Russian)\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"translated_text\"],\n            \"specification\": {\n                \"domain\": \"conversational and colloquial English\",\n                \"lingual pair\": \"English to Russian\"\n            },\n            \"description\": \"A domain-specific corpus for English to Russian translation, targeting conversational and colloquial content.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Specialized RNN-based NMT Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"RNN\",\n            \"specification\": {\n                \"model architecture\": \"Sequence-to-Sequence with RNN layers\"\n            },\n            \"description\": \"A neural machine translation model utilizing RNNs for English to Russian conversation and colloquial text translation.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Regions with specific slang and non-standard phrases should be identified for pre-processing or model adaptation.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"real-time translation API\",\n        \"inference_engine\": [\"GPU acceleration\"],\n        \"demonstration\": \"Real-time translation in a chat environment\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response captures the essence of the user's instruction, specifying a 'build' intent with a high expertise level, and includes the details for NLP problem, task, dataset, model, service, and metrics. It assumes high proficiency in the domain and accounts for latency requirements. Missing information could include the exact model architecture and preprocessing steps, which can be inferred based on the task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a data-intensive project for the upcoming science fair, I've collected exhaustive hourly solar radiation and energy production data from the past year. My objective is to develop a robust time-series forecasting model using advanced machine learning algorithms that can account for weather patterns, seasonal variations, and anomalies. Could you design an algorithm that not only predicts the daily energy output for the next week but also provides a confidence interval and adaptability to real-time data adjustments?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"science fair\",\n        \"description\": \"The user aims to develop a robust time-series forecasting model for hourly solar radiation and energy production data collected over the past year. The model should predict daily energy output for the next week, account for weather patterns, seasonal variations, and anomalies, and include a confidence interval as well as adaptability to real-time data adjustments.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"confidence interval\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"real-time adaptability\",\n                \"value\": \"required\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Hourly Solar Radiation and Energy Production Data\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"energy production\"],\n            \"specification\": {\n                \"time_interval\": \"hourly\",\n                \"data_period\": \"past year\"\n            },\n            \"description\": \"A dataset with hourly solar radiation and energy production data collected over the past year, suitable for time-series forecasting and accounting for weather patterns, seasonality, and anomalies.\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"time series normalization\"\n            ],\n            \"augmentation\": [\"seasonality adjustment\"],\n            \"visualization\": [\"time series analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"advanced machine learning algorithms\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"account Factors\": [\"weather patterns\", \"seasonal variations\", \"anomalies\"],\n                \"forecasting horizon\": \"week\",\n                \"predictive intervals\": \"yes\"\n            },\n            \"description\": \"A sophisticated algorithm designed for time-series forecasting, capable of predicting energy output while incorporating multiple data features and real-time adjustments.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature selection\",\n            \"interpolation techniques\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"real-time updates\"\n        ],\n        \"demonstration\": \"live demo of predictions and real-time adjustments\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure accurately reflects the user's project requirements. The intent, expertise, and problem details are clearly defined. The model requirements for accurate forecasting, confidence intervals, and real-time adjustments are included. The source of the dataset and necessary preprocessing, augmentation, and visualization steps are specified. The service requested for deployment and real-time demonstration is also included.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series anomaly detection", "instruction": "For our upcoming e-commerce platform, we require a sophisticated time-series anomaly detection model that can not only analyze user traffic patterns with sub-second precision, but also differentiate between brief spikes, gradual trends, and unusual patterns indicating bot attacks or A/B testing effects. The system must generate real-time alerts, trend insights, and offer recommendations for optimizing user experience while maintaining security in a high-traffic, dynamically changing environment.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series anomaly detection\",\n        \"application_domain\": \"e-commerce\",\n        \"description\": \"A sophisticated model is needed for time-series anomaly detection in an e-commerce platform. The model should have sub-second precision, differentiate between spikes, gradual trends, bot attacks, and A/B testing effects. It must provide real-time alerts, trend insights, and recommendations for optimizing user experience while ensuring security in a high-traffic, dynamic environment.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time alert generation\",\n                \"value\": null\n            },\n            {\n                \"name\": \"trend analysis\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"sub-seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"proprietary user traffic data\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"precision\": \"sub-second\",\n                \"variables\": [\"user traffic patterns\", \"bot attacks\", \"A/B testing\"]\n            },\n            \"description\": \"High-traffic time-series data reflecting user patterns, potential security threats, and A/B testing events.\",\n            \"preprocessing\": [\"sub-second segmentation\", \"feature extraction\"],\n            \"augmentation\": [],\n            \"visualization\": [\"anomaly detection patterns\", \"performance metrics\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks (possible with RNN, LSTM, or transformers)\",\n            \"specification\": {\n                \"architecture\": \"custom\",\n                \"real-time capabilities\": \"high\"\n            },\n            \"description\": \"A sophisticated time-series anomaly detection model for e-commerce, capable of handling sub-second precision and detecting diverse anomalies.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"behavioral profiling\",\n            \"security profiling\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"real-time monitoring service\",\n        \"inference_engine\": [\"TensorFlow serving\", \"Apache Storm\"],\n        \"demonstration\": \"interactive dashboard with real-time alerts and recommendations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON accurately captures the requirements, including the high-level intent to build a model, the expertise level, and the specific problem of time-series anomaly detection in an e-commerce context. The metrics and dataset properties reflect the user's needs for precision, anomaly differentiation, real-time performance, and security. The model type and architecture are suggested based on the nature of the task, while the service requirements and confidence score reflect the comprehensive nature of the requested solution.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "time-series forecasting", "instruction": "As a premier research project for the elite science fair, I've gathered comprehensive minutely solar radiation and energy generation data from the previous 12 months, encompassing diverse weather conditions and geographical variations. Your task is to design a sophisticated time-series forecasting model, integrating deep learning techniques, ensemble methods, and a real-time adaptive mechanism. The model must not only forecast the hourly energy yield for the subsequent fortnight but also deliver a prediction interval with high accuracy and the capability to dynamically recalibrate based on live updates, ensuring maximum precision and responsiveness.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy and sustainability\",\n        \"description\": \"The task is to design a cutting-edge time-series forecasting model for a premier science fair project. The model requires integration of deep learning techniques, ensemble methods, and a real-time adaptive mechanism. It must forecast hourly energy yield for the next two weeks and provide prediction intervals with high accuracy, while being capable of dynamic recalibration based on live updates.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"prediction interval accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"real-time adaptation\",\n                \"value\": null,\n                \"unit\": \"enabled\"\n            },\n            {\n                \"name\": \"forecast horizon\",\n                \"value\": 168,\n                \"unit\": \"hours\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"12-month minutely solar radiation and energy generation data\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"hourly energy yield\"],\n            \"specification\": {\n                \"data_length\": \"12 months\",\n                \"geographical_variations\": true,\n                \"weather_conditions涵盖\": true\n            },\n            \"description\": \"Extensive historical data on solar radiation and energy generation, collected over diverse weather conditions and geographical locations.\",\n            \"preprocessing\": [\n                \"feature engineering (e.g., handling missing data, scaling)\",\n                \"aggregation (hourly)\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\"data exploration for patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Deep learning and ensemble models\",\n            \"type\": \"ensemble models (e.g., LSTM, Random Forest, Gradient Boosting)\",\n            \"specification\": null,\n            \"description\": \"An advanced model combining deep learning and ensemble techniques, designed for accurate hourly energy yield forecasting with real-time adaptability.\"\n        }\n    ],\n    \"knowledge\": [\n        \"latest advancements in deep learning algorithms for time-series forecasting\",\n        \"ensemble methods for improved predictive power\",\n        \"real-time adaptive techniques for dynamic recalibration\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"Autoencoder for feature extraction\",\n            \"Time-window aggregation for live updates\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"real-time processing engine\"],\n        \"demonstration\": \"Live data feed demonstration with prediction intervals\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON reflects the specifics of the given task, including the requirement for deep learning, ensemble methods, real-time adaptability, and the emphasis on forecast accuracy. The dataset, preprocessing steps, and model family are derived from the instruction. The expert level is set to high due to the complexity of the task and requirement for cutting-edge techniques. The chosen model and ensemble methods, as well as the performance metrics, align with the project description. The confidence score is set at 0.95 due to the detailed and accurate translation of the instructions.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "For the innovative plant health monitoring venture, the ML team is mandated to design a sophisticated DenseNet model enhanced with sophisticated DenseBlock architecture, hierarchical attention modules, and residual connections. The task now requires not just segmentation of leaf images from the extensive and variant PlantVillage dataset but also detecting nano-scale pathogen presence. Ensure that the model's explainability yields user-friendly, interactive heatmaps and feature attributions that bridge the gap for non-experts in botany, while maintaining a strict 98% accuracy threshold for distinguishing intricate disease patterns from pristine foliage.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"agriculture\",\n        \"description\": \"The ML team is tasked with designing a DenseNet model with DenseBlock, hierarchical attention, and residual connections for a plant health monitoring project. The model should segment leaf images from the PlantVillage dataset and detect nano-scale pathogen presence. Additionally, it must provide explainable heatmaps and feature attributions for non-expert users while maintaining a 98% accuracy rate in differentiating disease patterns from healthy foliage.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.98\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"PlantVillage\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"pathogen_presence\"],\n            \"specification\": {\n                \"task\": \"segmentation\",\n                \"image_types\": [\"leaf images\"]\n            },\n            \"description\": \"A diverse and extensive dataset for plant leaf image segmentation and nano-scale pathogen detection within the PlantVillage dataset.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"user-friendly heatmaps\",\n                \"feature attributions\"\n            ],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"DenseNet with DenseBlock, attention, and residual connections\",\n            \"family\": \"DenseNet\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_details\": \"Enhanced with DenseBlock architecture, hierarchical attention modules, and residual connections\"\n            },\n            \"description\": \"A deep learning model designed for plant health monitoring with leaf image segmentation and nano-scale pathogen detection, with explainability for non-expert users.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": {\n            \"explainability\": true\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the key elements from the instruction, indicating a 'build' intent with a 'high' expertise level. The problem area is set to 'computer vision' with a downstream task of 'image segmentation' and a specific DenseNet model variant. The PlantVillage dataset source is linked, and performance is aimed for a 98% accuracy while incorporating explainability. The instructions for heatmaps and feature attributions were translated into the 'visualization' field.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As the project manager for a sophisticated smart city traffic forecasting task, you are tasked with enhancing the existing ARIMA-RNN model for the \"TrafficDensity-2022\" dataset. This extensive dataset contains 18 months of hourly sensor data, divided into train, validation, and test sets, each with distinct 4-weekly seasonal patterns and non-overlapping sequences. The INPUT_SEQ_LEN consists of 2016 hourly readings (excluding weekends), encompassing an array of 862 diverse traffic indicators. Your challenge now requires the model to:\n\n1. Develop a novel multi-stage approach for feature extraction to capture intricate dependencies.\n2. Implement an adaptive seasonal component to address varying weekly patterns throughout the year.\n3. Enhance the hybrid model architecture by integrating additional deep learning layers and attention mechanisms for improved short-term and long-term predictions.\n4. Optimize hyperparameters using a bayesian search technique to fine-tune the model's performance.\n5. Assess and compare the model's peak-hour forecasting accuracy with both daily Mean Absolute Percentage Error (MAPE) and weekly Mean Squared Error (MSE).\n6. Create visualizations to demonstrate the out-of-sample performance and interpretability of the forecasting results.\n\nRemember to document the iterative development process and justify each architectural choice.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"smart city\",\n        \"description\": \"As a project manager, you are enhancing an existing ARIMA-RNN model for the 'TrafficDensity-2022' dataset, which includes 18 months of hourly sensor data with 4-weekly seasonal patterns. The task involves novel feature extraction, adaptive seasonal components, deep learning architecture enhancement, Bayesian hyperparameter tuning, and performance evaluation using MAPE and MSE for peak-hour forecasts. Visualization for interpretability is also a requirement.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MAPE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MSE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"model complexity\",\n                \"value\": null,\n                \"unit\": \"parameters\"\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"TrafficDensity-2022\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 2016,\n                \"hourly_readings\": 862,\n                \"seasonal_pattern\": \"4-weekly\",\n                \"data_distribution\": \"18 months, train-val-test split\"\n            },\n            \"description\": \"Extensive dataset with 18 months of hourly sensor data, divided into non-overlapping train, validation, and test sets. The data includes 2016 hourly readings from 862 diverse traffic indicators.\",\n            \"preprocessing\": [\"novel feature extraction\", \"seasonal pattern adaptation\"],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"out-of-sample performance\",\n                \"forecast interpretability\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Enhanced ARIMA-RNN\",\n            \"family\": \"neural networks\",\n            \"type\": \"hybrid\",\n            \"specification\": {\n                \"feature_extraction\": \"multi-stage\",\n                \"seasonal_component\": \"adaptive\",\n                \"layers\": \"additional deep learning + attention\",\n                \"hyperparameter_tuning\": \"Bayesian search\"\n            },\n            \"description\": \"An advanced ARIMA-RNN model with enhanced architecture for improved short and long-term predictions, and an adaptive seasonal component to address varying weekly patterns. Bayesian optimization is applied for hyperparameter tuning.\"\n        }\n    ],\n    \"knowledge\": [\n        \"iterative development process documentation\",\n        \"architectural choices justification\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"additional feature extraction\",\n            \"seasonal adjustments\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"forecasting results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is crafted based on the provided instruction, incorporating the user's requirements for an advanced model enhancement and the specific tasks and metrics provided. Since the user has high expertise, the complexity of the problem is better reflected in the details provided. The requested iterative development documentation and architectural choices justification are also included.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "community detection", "instruction": "As a bioinformatics pioneer, your task is to design a challenging interdisciplinary project that blends advanced machine learning for yeast PPI network analysis. Request a multifaceted methodology that integrates deep, topological clustering (using node2vec or Walklets), hierarchical community detection, and dynamic community analysis with noise filtering. The project should be executed efficiently on resource-constrained hardware, while ensuring interpretability through visualizations and simplified explanations for non-experts, all within a step-by-step, accessible framework.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"community detection\",\n        \"application_domain\": \"bioinformatics, interdisciplinary research\",\n        \"description\": \"The project aims to design a bioinformatics project using advanced machine learning to analyze yeast protein-protein interaction (PPI) networks. It requires integrating deep topological clustering (node2vec or Walklets), hierarchical community detection, dynamic community analysis, and noise filtering. The focus is on efficiency for resource-constrained hardware, interpretability with visualizations, and simplicity for non-experts in a step-by-step, accessible framework.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"efficiency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time on resource-constrained hardware\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Yeast PPI Network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"protein-protein interactions\"],\n            \"specification\": {\n                \"node_type\": \"protein\",\n                \"edge_type\": \"interactions\"\n            },\n            \"description\": \"A yeast protein-protein interaction network for deep learning analysis.\",\n            \"preprocessing\": [\"node2vec or Walklets for topological clustering\", \"noise filtering\"],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"graph-based\",\n                \"community detection visualizations\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Interdisciplinary PPI Network Analysis Model\",\n            \"family\": \"graph neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"deep clustering algorithms\": [\"node2vec\", \"Walklets\"],\n                \"community detection methods\": [\"hierarchical\", \"dynamic\"],\n                \"noise filtering techniques\": {},\n                \"resource constraints\": {\"Hardware\": \"resource-constrained\"}\n            },\n            \"description\": \"A complex machine learning model that combines deep clustering, hierarchical and dynamic community analysis, noise filtering for yeast PPI network analysis.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Interpretability: Explainable AI techniques, simplified explanations for non-experts\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"resource-efficient algorithms\"],\n        \"target_device\": \"resource-constrained hardware (e.g., edge devices, IoT)\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": {\n            \"steps\": [\"Step-by-step guide for data preprocessing, model training, and interpretation\"]\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the main aspects of the instruction, such as the blend of techniques, resource constraints, and focus on interpretability. The task is categorized under graph machine learning and specifically addresses yeast PPI network analysis. Performance metrics include accuracy and efficiency, and the instruction-driven details about visualizations and resource-constrained hardware are represented. However, certain aspects like specific values for performance metrics and deployment details are not provided and left unspecified.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "node classification", "instruction": "As a data analyst for TrinuviaTech, devise a novel node classification model using a Heterogeneous Graph Neural Network (HGNN) with a temporal attention mechanism in the context of the food distribution dataset. The task requires differentiating between suppliers based on fine-grained transactional data, semantic relationships between suppliers, products, and regulations, and the impact of time-varying demand and industry-specific compliance. The model must excel in scalability for large graphs with sparse connectivity, while ensuring explainability and adaptability to real-time market dynamics.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"food distribution\",\n        \"description\": \"The user, as a data analyst for TrinuviaTech, needs a novel node classification model using Heterogeneous Graph Neural Networks (HGNN) with a temporal attention mechanism. The objective is to differentiate suppliers based on transactional data, semantic relationships between suppliers, products, and regulations, and consider time-varying demand and industry-specific compliance. The model must be scalable, explainable, and adaptable to real-time market dynamics.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"scalability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"explainability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            },\n            {\n                \"name\": \"connectivity scalability\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"food distribution dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"supplier_node_labels\", \"product_node_labels\", \"regulation_node_labels\"],\n            \"specification\": {\n                \"number_of_nodes\": {\n                    \"suppliers\": null,\n                    \"products\": null,\n                    \"regulations\": null\n                },\n                \"edges\": {\n                    \"transactional\": null,\n                    \"semantic\": null\n                },\n                \"time_series_dimensions\": {\n                    \"time_varying_demand\": null,\n                    \"industry_compliance\": null\n                }\n            },\n            \"description\": \"A heterogeneous graph dataset with fine-grained transactional data, semantic relationships, and time-varying dynamics for supplier differentiation.\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"dimensionality reduction\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\"graph structure\", \"temporal patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Heterogeneous Graph Neural Network (HGNN) with Temporal Attention Mechanism\",\n            \"family\": \"Heterogeneous Graph Learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"node_types\": [\"suppliers\", \"products\", \"regulations\"],\n                    \"neural_layers\": {\n                        \"hgnn\": [null, null],\n                        \"temporal_attention\": [null, null]\n                    }\n                },\n                \"parameters\": {\n                    \"learning_rate\": null,\n                    \"batch_size\": null,\n                    \"hidden_units\": null\n                }\n            },\n            \"description\": \"A model designed for node classification with HGNN and temporal attention, targeting supplier differentiation in a dynamic food distribution network.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider using graph sampling or subgraph extraction for scalability\",\n        \"Include explanations for model predictions for interpretability\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"node embedding generation\", \"temporal feature extraction\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"real-time adaptable model serving\"],\n        \"demonstration\": \"custom visualization of model performance and decision-making processes\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided instruction describes a specific project request, which is parsed into a JSON object accordingly. The user's intent is to build a model, with an expertise level assumed to be high due to the complexity of the task. The problem area is graph machine learning, with node classification as the task, and food distribution as the context. Performance metrics include accuracy, scalability, and explainability. Complexity metrics target inference time, memory footprint, and connectivity scalability. The model and dataset details are specified to meet the project's requirements.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "As a premier healthcare institution catering to diverse global communities, we demand a sophisticated, multi-class image segmentation system. This must classify complex dermatological conditions (rash subtypes, melanomas, and nuanced variations like atopic eczema vs. seborrheic keratosis), ensuring robustness against skin tone variations, image resolution inconsistencies, and practical scalability for large-volume, real-time user adoption in a technologically advanced, intuitive platform.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"healthcare\",\n        \"description\": \"The user requires a sophisticated multi-class image segmentation system for classifying complex dermatological conditions such as rash subtypes, melanomas, and distinguishing nuanced variations like atopic eczema vs. seborrheic keratosis. The system must be robust against skin tone variations, handle image resolution inconsistencies, and be scalable for large-volume, real-time use on a technologically advanced, intuitive platform.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"robustness\",\n                \"value\": null\n            },\n            {\n                \"name\": \"specificity\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"scalability\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Dermatological Image Dataset (custom)\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"rash_subtype\", \"melanoma\", \"atopic_eczema\", \"seborrheic_keratosis\"],\n            \"specification\": null,\n            \"description\": \"A large, diverse dataset with complex dermatological conditions for training, considering skin tone variations, image resolution, and high precision.\",\n            \"preprocessing\": [\"skin tone normalization\", \"image resizing\"],\n            \"augmentation\": [\n                \"color jittering\",\n                \"Gaussian blur\",\n                \"random rotation\",\n                \"elastic transformations\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep convolutional neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"U-Net or ResNet-like\",\n                \"architecture_details\": \"highly customized for dermatological image segmentation\"\n            },\n            \"description\": \"An advanced deep learning model for complex dermatological image segmentation, robust against skin tone variations and image resolution inconsistencies.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Skin tone and image resolution variations need to be handled using domain-specific techniques and large, diverse datasets.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"domain-specific feature extraction\"],\n        \"target_device\": \"cloud-optimized for real-time inference\",\n        \"deployment_endpoint\": \"user-friendly API interface\",\n        \"inference_engine\": [\"GPU-optimized inference\"],\n        \"demonstration\": \"interactive live demo showcasing performance on various skin types and resolutions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is based on the given instruction, prioritizing a sophisticated, multi-class image segmentation system for dermatology. Expertise level is assumed to be high due to the complexity of the problem. Various aspects of the problem are handled like robustness, performance metrics, and scalability. The user requires a deep learning model, like a customized U-Net or ResNet, with target device and deployment considerations. The confidence score is high given the comprehensive response.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "question answering", "instruction": "As a project manager, seek a robust QA system for the TriviaQA dataset, requiring not only GPT-3's prowess but also a hierarchical fusion of transformers, adept at nested reasoning. Mandate real-time, sub-second responses under extreme load, guaranteeing seamless performance and adaptability for diverse, complex user queries in a resource-constrained environment.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"information retrieval\",\n        \"description\": \"The project goal is to develop a robust QA system for the TriviaQA dataset, leveraging GPT-3's capabilities and incorporating a hierarchical fusion of transformers for nested reasoning. The system must provide real-time, sub-second responses under high load and maintain seamless performance with adaptability for diverse, complex user queries in resource-constrained environments.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"response time\",\n                \"value\": 0.1,\n                \"unit\": \"seconds\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory consumption\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"TriviaQA\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"questions\", \"answers\"],\n            \"specification\": {\n                \"question_length\": null,\n                \"answer_length\": null,\n                \"data_distribution\": {\n                    \"train\": null,\n                    \"validation\": null,\n                    \"test\": null\n                }\n            },\n            \"description\": \"A large-scale trivia dataset for QA tasks, requiring advanced reasoning skills and integration with GPT-3.\",\n            \"preprocessing\": [\"nested question tokenization\", \"contextualized word embeddings\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical Fusion QA System with GPT-3\",\n            \"family\": \"Transformers (Hierarchical Fusion)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_architecture\": \"Hierarchical Transformer\",\n                \"integration_with_GPT-3\": \"yes\",\n                \"specific_features\": \"nested reasoning\"\n            },\n            \"description\": \"A state-of-the-art QA system that combines GPT-3's capabilities with a hierarchical transformer for efficient nested reasoning, designed for real-time performance in resource-constrained environments.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"title\": \"Diverse Complex Queries\",\n            \"description\": \"Users will present queries involving a wide range of topics and intricate reasoning.\"\n        },\n        {\n            \"title\": \"Adaptability\",\n            \"description\": \"The system must be adaptable to handle changing data distribution and new questions over time.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"query optimization\", \"context pruning\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"high-performance, real-time QA service\",\n        \"inference_engine\": [\"TensorFlow serving\", \"Hugging Face Transformers\"],\n        \"demonstration\": \"Live demos showcasing real-time, sub-second response times under varying query complexities\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the given project requirements, specifying a high-end expertise level, the details of the dataset, a robust model design using GPT-3 and hierarchical transformers, and clear performance and complexity metrics. The service section includes real-time capabilities and adaptability in a resource-constrained setting. Some specific metric values are left null to be filled in with actual project evaluation.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "Develop a cutting-edge time-series forecasting model utilizing a novel bidirectional LSTM framework, tailored for a distinct solar-wind hybrid dataset. The model should deliver hourly energy predictions for the subsequent 72 hours with sub-millisecond precision, while maintaining real-time adaptability, efficient parallel execution, and demonstrating exceptional accuracy within a stringent latency constraint of 5 milliseconds.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy/solar power\",\n        \"description\": \"The task is to develop a cutting-edge time-series forecasting model using a novel bidirectional LSTM framework specifically for a solar-wind hybrid dataset. The model should predict hourly energy for the next 72 hours with sub-millisecond precision, ensuring real-time adaptability and efficient parallel execution, while meeting a strict latency constraint of 5 milliseconds.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"sub-millisecond precision\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": 5,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"real-time adaptability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"parallel execution efficiency\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Solar-Wind Hybrid Dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"hourly energy\"],\n            \"specification\": {\n                \"prediction horizon\": 72,\n                \"latency constraint\": 5\n            },\n            \"description\": \"A specialized dataset for time-series forecasting of solar energy, incorporating solar and wind data, with hourly predictions for the next 72 hours.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Novel Bi-LSTM Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"framework\": \"LSTM\",\n                \"architecture\": \"bidirectional\",\n                \"time_series_forecasting\": true\n            },\n            \"description\": \"An advanced time-series forecasting model based on a bidirectional LSTM architecture designed for a solar-wind hybrid dataset, capable of hourly energy predictions with sub-millisecond accuracy.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Latency constraints and sub-millisecond precision require efficient parallelism and real-time adaptability in the model\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized\"],\n        \"demonstration\": \"5ms latency performance demonstration\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided information accurately represents the user's intent to build a high-quality time-series forecasting model with specific details on the dataset, task, performance metrics, and requirements. The confidence score is high since the structure adheres to the given schema and includes all the key elements necessary for initiating the project.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "You're now engaging in a specialized deep time-series analysis project using the intricate ETTm2 dataset, featuring ultra-dynamic, multi-sourced, and autocorrelated data from the energy industry. The train, validation, and test sets consist of balanced, temporally granular samples ( hourly timestamps for 3 years) to gauge model resilience. Your task involves forecasting the subsequent 96 hourly-demand steps (96 steps ahead, each with expanded 21-feature resolution) while incorporating intricate daily, weekly, and annual cycles, detecting outliers, and capturing long-term weather patterns. Your proposed model should surpass benchmark performance in terms of normalized root mean squared error (NRMSE) and mean absolute percentage error (MAPE), showcasing exceptional adaptability through extensive leave-one-out validation experiments, ensuring real-world grid forecasting accuracy.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy industry\",\n        \"description\": \"The user is working on a deep time-series analysis project with the ETTm2 dataset, which contains multi-sourced, autocorrelated data from the energy sector. The task is to forecast 96 hourly-demand steps ahead, considering daily, weekly, and annual cycles, while detecting outliers and accounting for long-term weather patterns. The goal is to achieve benchmark performance in NRMSE and MAPE using extensive leave-one-out validation for real-world grid forecasting accuracy.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"normalized root mean squared error (NRMSE)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute percentage error (MAPE)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ETTm2\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\n                {\n                    \"name\": \"hourly-demand\",\n                    \"expanded_resolution\": 21\n                }\n            ],\n            \"specification\": {\n                \"temporal_granularity\": \"hourly\",\n                \"duration\": \"3 years\",\n                \"imbalance_type\": \"balanced\",\n                \"sample_size\": {\n                    \"train\": \"train samples\",\n                    \"validation\": \"validation samples\",\n                    \"test\": \"test samples\"\n                },\n                \"additional_info\": \"96-hour-step-ahead forecasting and includes multiple feature resolution\"\n            },\n            \"description\": \"Ultra-dynamic data with hourly timestamps for 3 years, incorporating multi-source, autocorrelated, daily, weekly, and annual cycles in the energy industry.\",\n            \"preprocessing\": [\"detect outliers\", \"feature engineering for cycles and weather patterns\"],\n            \"augmentation\": [],\n            \"visualization\": [\"anomalies and patterns over time\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning models (e.g., LSTM, Transformer)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_performance\": \"outperform benchmark models\",\n                \"validation_method\": \"leave-one-out\"\n            },\n            \"description\": \"A specialized deep learning model for time-series forecasting, incorporating advanced handling of daily, weekly, and annual cycles, as well as outlier detection and long-term weather patterns.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"temporal embeddings\",\n            \"holiday and seasonality features\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"visualizing forecast results with benchmark comparison\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response mirrors the given instruction, outlining a high-level overview of the project, dataset, and model requirements. The expert level and extensive task details suggest the user's 'high' expertise. Performance metrics are included, with room for optimization. The provided preprocessing and model requirements reflect the challenging nature of the task and the need for benchmark beating performance. However, missing specific metric target values, source codes, or deployment-related details might be needed.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a project manager for a pioneering AI research group, design a sophisticated multi-stage image recognition model that can identify not only nebulae and exoplanets but also lesser-known cosmic phenomena. Utilize the Flickr-Galaxies dataset's obscure subset, while adhering to strict memory constraints and a labeling budget. Outline an efficient architecture, considering transfer learning with limited labeled examples, and predict milestones for benchmarking performance with minimal computational expenditure.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"astronomy\",\n        \"description\": \"Design a multi-stage image recognition model for detecting nebulae, exoplanets, and lesser-known cosmic phenomena using the Flickr-Galaxies dataset's obscure subset. Model should be efficient under strict memory constraints and labeling budget, incorporating transfer learning with limited labeled examples, and prioritize benchmarking milestones with minimal computational expenditure.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"memory efficiency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"computational efficiency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"unit\": \"milliseconds\",\n                \"value\": null\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"unit\": \"MB\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Flickr-Galaxies obscure subset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"cosmic phenomena\"],\n            \"specification\": {\n                \"image_size\": null,\n                \"number_of_samples\": null,\n                \"labels_distribution\": {\n                    \"nebulae\": null,\n                    \"exoplanets\": null,\n                    \"lesser-known\": null\n                }\n            },\n            \"description\": \"A subset of the Flickr-Galaxies dataset focusing on rare cosmic objects.\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"transfer learning-compatible resizing\"\n            ],\n            \"augmentation\": [\"limited data augmentation for efficiency\"],\n            \"visualization\": [\"progress monitoring of label distribution\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Multi-Stage Image Recognition Model\",\n            \"family\": \"deep convolutional neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"transfer learning (e.g., VGG, ResNet), with custom layers for multi-classification\",\n                \"labeled_examples_per_class\": null,\n                \"pre-trained_model_size\": null,\n                \"fine-tuning_depth\": null\n            },\n            \"description\": \"An advanced model using transfer learning and adapted for detecting nebulae, exoplanets, and lesser-known cosmic phenomena with limited labeled data.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Leverage large-scale pre-trained models with known performance on image recognition tasks\",\n        \"Explore transfer learning techniques to handle small dataset size\",\n        \"Use efficient model architectures and pruning techniques to meet memory constraints\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature extraction from pre-trained models\"],\n        \"target_device\": \"resource-constrained devices\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\n            \"efficient inference algorithms (e.g., quantization, model compression)\"\n        ],\n        \"demonstration\": \"prototype showcase of milestones and performance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON reflects the details provided in the instruction, focusing on the build intent for a multi-stage image recognition model with emphasis on transfer learning. Expertise level is assumed high given the requirement for designing a sophisticated model. The dataset's Flickr-Galaxies obscure subset and memory constraints are mentioned, along with specific performance metrics and complexity measures. Transfer learning and limited labeled data are accounted for in the model design and service options.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "Develop a real-time, high-performance image segmentation pipeline for the niche OceanSat-3 dataset, focusing on the intricate segmentation of land, water, structures, marine biodiversity (including rare species, coral reefs, and underwater detritus). Emphasize on integrating a cutting-edge fusion of Time-Aware Cascade Attention U-Net and PointRend, designed to cope with turbid waters and variable tides. The system must handle 16K resolution images with sub-pixel accuracy, while ensuring low latency, suitable for large-scale, dynamic coastal conservation initiatives that require continuous, high-frequency monitoring. Additionally, provide a detailed evaluation of the model's robustness under different lighting conditions and seasonal variations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"oceanography & conservation\",\n        \"description\": \"The user wants to develop a real-time, high-performance image segmentation pipeline for the OceanSat-3 dataset. The focus is on segmenting land, water, structures, marine biodiversity, including rare species, coral reefs, and underwater detritus. The system should integrate Time-Aware Cascade Attention U-Net and PointRend for turbid waters and variable tides, supporting 16K resolution images with sub-pixel accuracy and low latency for large-scale, dynamic coastal monitoring.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"sub-pixel accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"OceanSat-3 dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"resolution\": {\n                    \"width\": 16384,\n                    \"height\": 16384\n                },\n                \"pixel_depth\": null,\n                \"time_aware\": true\n            },\n            \"description\": \"A high-resolution image dataset designed for real-time image segmentation of OceanSat-3, focusing on land, water, structures, and marine biodiversity under challenging conditions.\",\n            \"preprocessing\": [\"Time-Aware preprocessing\"],\n            \"augmentation\": [\"Integration of PointRend and Cascade Attention U-Net fusion\"],\n            \"visualization\": [\"16K image support, sub-pixel analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Time-Aware Cascade Attention U-Net + PointRend\",\n            \"family\": \"neural networks\",\n            \"type\": \"image segmentation\",\n            \"specification\": {\n                \"architecture\": {\n                    \"model_fusion\": true,\n                    \"attention_mechanism\": \"Time-Aware Cascade Attention\",\n                    \"fine_grained_segmentation\": \"PointRend\"\n                },\n                \"performance\": {\n                    \"inference_speed\": null,\n                    \"latency_per_image\": null,\n                    \"memory_efficiency\": null\n                }\n            },\n            \"description\": \"A real-time image segmentation model designed for OceanSat-3 with high accuracy and sub-pixel segmentation under turbid waters and variable tides.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The model accounts for turbid waters and variable tides\",\n        \"Robustness under different lighting conditions and seasonal variations will be evaluated\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"latency optimization\"],\n        \"target_device\": \"real-time\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"GPU optimized\", \"TensorRT integration\"],\n        \"demonstration\": \"large-scale, high-frequency monitoring for coastal conservation\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON accurately captures the user's intent to build a machine learning pipeline, leveraging the expertise, and the requirements for the image segmentation task. Metrics such as accuracy, precision, and latency are included. The dataset specifications and model specifics are detailed. The challenge of handling turbid waters and different conditions are acknowledged, and there is a focus on real-time performance and demonstration for conservation initiatives.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "As a project manager, you must develop a state-of-the-art Visual Question Answering (VQA) system for the platform. Integrate TextVQA into the design, necessitating a novel, modular architecture that combines deep transformers, attention mechanisms, and interpretable intermediate representations. Ensure the model not only handles intricate visual-textual interactions but also demonstrates state-of-the-art accuracy, explainability, and adaptability to real-world scenarios with evolving visual and textual diversity.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"AI platform or multimedia\",\n        \"description\": \"The project requires the development of a state-of-the-art Visual Question Answering (VQA) system for the platform, integrating TextVQA and featuring a novel, modular architecture. The architecture should incorporate deep transformers, attention mechanisms, and interpretable intermediate representations, with a focus on handling complex visual-textual interactions, achieving state-of-the-art accuracy, explainability, and adaptability to diverse real-world scenarios.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"explainability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"adaptability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"ms\"\n            },\n            {\n                \"name\": \"model explainability\",\n                \"value\": null,\n                \"unit\": \"N/A\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"text\", \"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"architecture\": \"novel, combining deep transformers, attention mechanisms, and interpretable intermediate representations\"\n            },\n            \"description\": \"A Visual Question Answering (VQA) dataset that demands handling intricate visual-textual interactions and includesTextVQA, with a focus on real-world scenarios and diversity.\",\n            \"preprocessing\": [\"deep transformers, attention mechanisms, interpretable representations\"],\n            \"augmentation\": [\"diversity in visual and textual data\"],\n            \"visualization\": [\"model interpretability for visual components\"],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"state-of-the-art VQA\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"deep transformers, attention mechanisms\",\n                \"interpretability\": \"essential\"\n            },\n            \"description\": \"A VQA model integrating TextVQA, with a modular design that emphasizes deep transformers, attention mechanisms, and interpretable intermediate representations for real-world adaptability.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Modular architecture is a current trend in VQA, promoting scalability and ease of integration.\",\n        \"Deep transformers and attention mechanisms have shown strong performance in multimodal tasks.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"novel architecture and interpretability\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"efficient VQA engines\"],\n        \"demonstration\": \"demonstrating accuracy, explainability, and adaptability in a variety of real-world scenarios\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the key aspects of the given instruction, including the goal to build a high-level VQA system, integrating TextVQA, and the desired architectural and performance characteristics. Performance metrics such as accuracy, explainability, and adaptability are specified. However, specific model names, performance targets, and deployment details are not provided, so they are left as null or placeholders.\",\n        \"score\": 0.8\n    }\n}\n"}
{"task": "node classification", "instruction": "Transform the Enron Email dataset into a sophisticated node classification task by designing a Hierarchical Attentional Recurrent Graph Convolutional Network (HAR-GCN), specifically tailored for detecting not only explicit collaboration patterns but also intricate inter-department dynamics through multitask learning. Emphasize the development of a highly optimized model that can efficiently handle billion-node graphs with real-time performance, while capturing temporal dependencies and extracting implicit knowledge, all within strict memory constraints and minimal latency requirements for analyzing enterprise-wide employee interactions over an extended period.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"enterprise management\",\n        \"description\": \"The task involves transforming the Enron Email dataset into a node classification problem using a Hierarchical Attentional Recurrent Graph Convolutional Network (HAR-GCN), aiming to detect explicit collaboration patterns and intricate inter-department dynamics through multitask learning. The focus is on developing an optimized model capable of handling billion-node graphs in real-time, managing temporal dependencies, extracting implicit knowledge, and fulfilling strict memory constraints and minimal latency requirements.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"efficiency\",\n                \"value\": \"real-time\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": \"strict constraints\"\n            },\n            {\n                \"name\": \"latency\",\n                \"value\": \"minimal\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory_size\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Enron Email dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"node_labels\"],\n            \"specification\": {\n                \"node_count\": \"billion-scale\",\n                \"temporal\": true\n            },\n            \"description\": \"The dataset transformed into a graph representation, capturing enterprise-wide employee interactions over time.\",\n            \"preprocessing\": [\"graph creation\", \"temporal encoding\"],\n            \"augmentation\": [],\n            \"visualization\": [\"node embeddings\", \"graph structures\"],\n            \"source\": \"infer-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"HAR-GCN\",\n            \"family\": \"Graph Convolutional Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"Hierarchical Attentional and Recurrent\",\n                \"multitask_learning\": true,\n                \"node_classification\": true\n            },\n            \"description\": \"A highly optimized model for detecting collaboration patterns and inter-department dynamics using HAR-GCN on billion-node graphs.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Incorporates temporal dependencies and implicit knowledge extraction\",\n        \"Efficient handling for large graphs and real-time performance\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"node features engineering\", \"temporal feature engineering\"],\n        \"target_device\": \"edge or cloud\",\n        \"deployment_endpoint\": \"API-based or web service\",\n        \"inference_engine\": [\"optimized parallel processing\", \"GPU acceleration\"],\n        \"demonstration\": \"model performance visualization on ensemble of large-scale graphs\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is derived from the given instruction, mapping it to the schema. The user's intent is to build a model ('build' intent). Expertise level is assumed to be high due to the complexity and sophistication of the task. The dataset is transformed Enron Email, and the model, HAR-GCN, is tailored for the node classification task with the specified requirements. Performance metrics emphasize real-time performance, memory constraints, and minimal latency. The model's specifications address billion-scale graphs and multitask learning. Key concepts from the instruction, like handling temporal dependencies and extracting implicit knowledge, have been included.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "sequential recommendation", "instruction": "Design a state-of-the-art sequential recommendation system for a niche live streaming and immersive journalism platform, specifically tailored for the 'Chrono-Sensory Storytelling' domain. Utilize Alibaba Cloud's 'Temporal Fusion 3.0' on the 'Cosmic Content Fusion' dataset, which includes live chats with voice overlays, real-time emoji annotations, and multilingual subtitled video archives. The system must excel in concurrent analysis of audio-visual nuances, personalize narratives based on user micro-interactions, and optimize for sub-millisecond latency. Achieve explainable AI for continuous A/B testing and user-focused content adaptation, ensuring global appeal and fostering long-term audience loyalty in the ever-evolving content ecosystem.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"recommendation systems\",\n        \"downstream_task\": \"sequential recommendation\",\n        \"application_domain\": \"live streaming and immersive journalism\",\n        \"description\": \"Design a state-of-the-art sequential recommendation system for the 'Chrono-Sensory Storytelling' domain, leveraging Alibaba Cloud's 'Temporal Fusion 3.0' on the 'Cosmic Content Fusion' dataset. The system should handle live chats with voice overlays, real-time emoji annotations, and multilingual subtitled video archives. The focus is on concurrent analysis of audio-visual nuances, personalization based on user micro-interactions, and achieving sub-millisecond latency for low-latency streaming. Explainable AI is necessary for A/B testing and user-centric content adaptation, ensuring global appeal and long-term audience loyalty.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"sub-millisecond latency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"explainable AI\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency optimization\",\n                \"value\": null,\n                \"unit\": \"sub-milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Cosmic Content Fusion\",\n            \"modality\": [\"text\", \"image\", \"audio\", \"video\"],\n            \"target_variables\": [\"user_interactions\", \"content_recommendations\"],\n            \"specification\": {\n                \"live_chats\": true,\n                \"voice_overlays\": true,\n                \"emoji_annotations\": true,\n                \"multilingual_subtitles\": true\n            },\n            \"description\": \"A dataset for a live streaming and immersive journalism platform with diverse content including live chats, voice, emojis, and multilingual subtitles.\",\n            \"preprocessing\": [\"audio-visual feature extraction\"],\n            \"augmentation\": [\"real-time adaptation\"],\n            \"visualization\": [\"user interaction patterns\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Temporal Fusion 3.0 (Chrono-Sensory)\",\n            \"family\": \"neural networks\",\n            \"type\": \"sequential recommendation\",\n            \"specification\": {\n                \"audio-visual fusion\": true,\n                \"micro-interaction personalization\": true\n            },\n            \"description\": \"A state-of-the-art sequential recommendation system using Temporal Fusion 3.0 tailored for the 'Chrono-Sensory Storytelling' domain.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Explainable AI for A/B testing and content adaptation\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"contextual user embeddings\"],\n        \"target_device\": \"cloud-based\",\n        \"deployment_endpoint\": \"Alibaba Cloud\",\n        \"inference_engine\": [\"real-time, GPU-accelerated inference\"],\n        \"demonstration\": \"User-focused live streaming experience and personalized content recommendations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the provided instruction by specifying a 'build' intent, 'high' expertise level, and details the problem in the 'recommendation systems' area with a sequential recommendation task. The specific dataset, 'Cosmic Content Fusion', and use of 'Temporal Fusion 3.0' are mentioned, along with performance metrics like accuracy, sub-millisecond latency, and explainability. The service component covers necessary aspects for a live streaming platform, with global appeal and audience loyalty in mind.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "In a groundbreaking application of artificial intelligence, your machine learning team has been tasked with developing a predictive analytics platform for the complex Fluctuating Renewable Energy Grid dataset, characterized by extremely high-resolution time series data with 10,000 data points per time series (INPUT_SEQ_LEN=10,000, INPUT_DIM=5,000). This system must forecast not just short-term patterns (PRED_SEQ_LEN=1,024), but also forecast multi-step ahead scenarios, incorporating extreme volatility, sudden shifts, and harmonics caused by diverse renewable energy sources. The model must incorporate a self-correcting mechanism for handling anomalies, and demonstrate robustness through a novel combination of deep learning models and ensemble techniques.\r\n\r\nTo achieve excellence, devise a deep neural architecture that seamlessly integrates autoencoders, transformers, and long short-term memory networks, with adaptive attention mechanisms tailored for capturing long-range dependencies and subtle seasonalities. Emphasize the importance of advanced feature extraction methods, such as wavelet transforms and permutation invariant training, in capturing the intricate temporal patterns. Additionally, propose a hybrid training strategy that combines online and offline learning, fine-tuning the model with a progressive curriculum learning approach on the meticulously stratified and spatially distributed dataset, ensuring optimal performance across various grid scenarios and regions. Benchmark the model's performance using adjusted versions of F1 score, R^2, and mean absolute percentage error (MAPE), while demonstrating a comprehensive evaluation plan that addresses the model's uncertainty quantification and interpretability in the presence of complex renewable energy dynamics.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy and utilities\",\n        \"description\": \"A machine learning team is tasked with developing a predictive analytics platform for the Fluctuating Renewable Energy Grid dataset. The platform must forecast short-term patterns and multi-step scenarios with high-resolution data (10,000 points, 5,000 dimensions). The model should incorporate self-correcting mechanisms, deep learning, transformers, LSTM, adaptive attention, wavelet transforms, permutation invariant training, and a hybrid training strategy with online/offline learning and progressive curriculum learning.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1 score (adjusted)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"R^2\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MAPE (mean absolute percentage error)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"unit\": \"minutes per batch\",\n                \"value\": null\n            },\n            {\n                \"name\": \"memory size\",\n                \"unit\": \"MB\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Fluctuating Renewable Energy Grid\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 10000,\n                \"INPUT_DIM\": 5000\n            },\n            \"description\": \"A high-resolution time series dataset with 10,000 data points per series, capturing diverse renewable energy sources, extreme volatility, sudden shifts, and harmonics.\",\n            \"preprocessing\": [\"wavelet transforms\", \"permutation invariant training\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Deep Neural Architecture for Renewable Energy Forecasting\",\n            \"family\": \"neural networks\",\n            \"type\": [\"autoencoders\", \"transformers\", \"LSTM\", \"adaptive attention\"],\n            \"specification\": {\n                \"architecture\": [\n                    \"long-range dependencies captured by transformers\",\n                    \"seasonal patterns by LSTM with adaptive attention\",\n                    \"self-correcting mechanism\"\n                ],\n                \"training\": [\n                    \"hybrid online/offline learning\",\n                    \"progressive curriculum learning\"\n                ]\n            },\n            \"description\": \"Combines autoencoders, transformers, LSTM, and adaptive attention for a robust and interpretable forecast model.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"content\": \"Advanced feature extraction techniques and handling of renewable energy dynamics, anomaly detection, and interpretability.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"wavelet transforms\", \"permutation invariant training\", \"self-correcting mechanism\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": {\n            \"focus\": \"model uncertainty quantification and interpretability in complex energy dynamics\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The response is based on the detailed requirements provided, including the high-level overview, specific task (time-series forecasting), datasets, model architecture, and evaluation criteria. The information is assumed to be correct since it closely aligns with the given instruction and is structured according to the JSON schema.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "Create a cutting-edge VQA system for Visual Historical Archaeology, using the exclusive and diverse VHR-Anthropocene collection, which blends authentic Neolithic paintings with 3D-rendered paleolife reconstructions. Implement a hybrid model integrating a dual-attention GraphReasonNet and a state-of-the-art fusion of X-ALBEF and CTR-Transformer, focusing on discovering latent connections between extinct species, tools, and subtextual cultural codes. Strive for a benchmark accuracy of 85% in differentiating intricate symbolic patterns and demonstrate the model's capacity to analyze nuanced societal transformations in prehistoric civilizations through a custom Kappa evaluation metric.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"history and archaeology\",\n        \"description\": \"The task is to develop a cutting-edge VQA system for Visual Historical Archaeology, using the VHR-Anthropocene collection, which combines Neolithic paintings with 3D-rendered paleolife. The system should employ a hybrid model of GraphReasonNet with dual-attention and a fusion of X-ALBEF and CTR-Transformer, targeting the detection of latent connections between extinct species, tools, and cultural codes. The goal is to achieve benchmark accuracy of 85% in identifying intricate symbolic patterns and evaluate with a custom Kappa metric.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.85\n            },\n            {\n                \"name\": \"custom Kappa metric\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"VHR-Anthropocene collection\",\n            \"modality\": [\"image\", \"text\"],\n            \"target_variables\": [\"latent connections\", \"symbolic patterns\"],\n            \"specification\": {\n                \"image modalities\": \"Neolithic paintings and 3D-rendered paleolife\",\n                \"textual modality\": \"questions related to historical archaeology\"\n            },\n            \"description\": \"Exclusive and diverse dataset for visual historical archaeology with authentic paintings and reconstructed 3D paleolife for VQA tasks.\",\n            \"preprocessing\": [\"fusion of paintings and reconstructions\"],\n            \"augmentation\": [\"3D image augmentation\"],\n            \"visualization\": [\"connections and patterns analysis\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hybrid Model (GraphReasonNet + X-ALBEF & CTR-Transformer)\",\n            \"family\": \"neural networks\",\n            \"type\": \"ensemble models\",\n            \"specification\": {\n                \"model architecture\": \"dual-attention GraphReasonNet + fusion of X-ALBEF and CTR-Transformer\"\n            },\n            \"description\": \"A state-of-the-art VQA system that fuses graph-based and transformer-based models for improved analysis of prehistoric civilizations.\"\n        }\n    ],\n    \"knowledge\": [\n        \"3D-rendered paleolife reconstructions\",\n        \"Custom Kappa metric for nuanced societal transformation evaluation\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"fusion of image and text features\"],\n        \"target_device\": \"high-performance computing (GPU or cloud)\",\n        \"deployment_endpoint\": \"specific archaeology research platform\",\n        \"inference_engine\": [\"GPU inference\"],\n        \"demonstration\": \"analysis of a set of predefined questions on the dataset\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response covers all aspects of the user's instruction, reflecting the cutting-edge nature of the VQA system and the user's high expertise level. The specified performance metric of 85% accuracy is directly mentioned, while leaving room for the custom Kappa metric to be determined. Complexities like dataset augmentation and pre-processing, as well as the use of X-ALBEF and CTR-Transformer, are accurately incorporated. The target device and endpoint for deployment are not explicitly stated but assumed to be high-performance for a challenging VQA task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "visual question answering", "instruction": "Forge a high-performance, historical VQA system using the COCO-Concepts Enhanced version, integrating an advanced M6VX Transformer with a focus on deciphering complex visual storytelling, subtle object interactions, and nuanced subject characteristics in diverse historical contexts. Strive for an exceptional F1 score of 80% and design a tailored evaluation metric capturing social dynamics, ensuring cultural and historical accuracy.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"visual question answering\",\n        \"application_domain\": \"artificial intelligence\",\n        \"description\": \"The goal is to develop a high-performance historical VQA system using the COCO-Concepts Enhanced dataset. The system should employ an advanced M6VX Transformer, focusing on understanding complex visual storytelling, subtle object interactions, and nuanced subject characteristics in diverse historical settings. The targeted F1 score is 80%.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1 Score\",\n                \"value\": 0.8\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"Inference Time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"Memory Size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"COCO-Concepts Enhanced\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"visual storytelling\", \"object interactions\", \"subject characteristics\"],\n            \"specification\": {\n                \"domain\": \"historical\",\n                \"enhancements\": \"COCO-Concepts\"\n            },\n            \"description\": \"A dataset for historical VQA, incorporating advanced concepts for complex scenarios and diverse historical contexts.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced M6VX Transformer\",\n            \"family\": \"neural networks\",\n            \"type\": \"Transformer\",\n            \"specification\": {\n                \"architecture\": \"M6VX\",\n                \"focus\": [\"visual storytelling\", \"object interactions\", \"subject characteristics\"]\n            },\n            \"description\": \"An advanced Transformer designed for historical VQA, emphasizing complex visual analysis.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Social dynamics and cultural/historical accuracy are important aspects to consider during evaluation\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Visual storytelling and nuanced subject demonstrations.\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is based on the user's instruction, prioritizing a high-performance historical VQA system, F1 score requirement, and special focus on complexity and cultural accuracy. The user's high expertise level is noted. The COCO-Concepts Enhanced dataset is specified, and M6VX Transformer with its focus areas are mentioned. Evaluation metrics include F1 score with cultural dynamics, and a plan for demonstration is outlined.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "link prediction", "instruction": "Could a highly sophisticated, time-sensitive link predictor be designed for the Citeseer citation network, integrating timestamp analysis, fine-grained semantic matching, and a multi-author contribution model, while factoring in journal prestige scores, to accurately uncover hidden connections between publications?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"link prediction\",\n        \"application_domain\": \"scholarly research\",\n        \"description\": \"The user is asking for the development of a sophisticated link predictor for the Citeseer citation network, which requires integration of timestamp analysis, fine-grained semantic matching, a multi-author contribution model, and consideration of journal prestige scores to accurately identify hidden connections between publications.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Citeseer citation network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"node_type\": \"publications\",\n                \"edge_type\": \"citations\",\n                \"timestamp_analysis\": true,\n                \"semantic_features\": true,\n                \"multi_author_model\": true,\n                \"journal_prestige_scores\": true\n            },\n            \"description\": \"A citation network where the task is to predict links with a focus on timestamp analysis, semantic matching, and other factors.\",\n            \"preprocessing\": [\n                \"extract timestamp data\",\n                \"extract semantic features from publications\",\n                \"encode multi-author contributions\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"architecture\": [\"timestamp-aware\", \"fine-grained\", \"multi-author\", \"journal-embedded\"]\n            },\n            \"description\": \"A sophisticated GNN model that integrates timestamp analysis, semantic matching, multi-author contributions, and journal prestige scores for link prediction in Citeseer.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"GPU-accelerated\"\n        ],\n        \"demonstration\": {\n            \"examples\": [\n                \"Show predicted links for top 10 high-impact publications.\"\n            ]\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent to build a sophisticated link predictor. The model requirements and dataset details are derived from the instruction. The high expertise level is assumed given the complexity of the requested model and analysis. Performance metrics are focused on accuracy, precision, and recall, as appropriate for link prediction. The model family is specified as neural networks, with a focus on graph neural networks. Inference engine and demonstration are suggested based on the task complexity. The confidence score is not provided as it would require a subjective evaluation of the specificity of the requirements.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Deploy a state-of-the-art, transfer learning-based Graph Wavelet Neural Network (GWNN) architecture on the diverse Mouse Brain Neurite Tractography dataset, encompassing extensive genetic variability. The model must proficiently classify not only the primary neuron subclasses but also the elusive subtypes with extreme precision. Scrutinize the intricate interactions between spatial-temporal dynamics, pruning patterns, and molecular markers, and optimize for robustness against potential variations in the graph topologies.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"biomedical research\",\n        \"description\": \"The user wants to deploy a state-of-the-art, transfer learning-based Graph Wavelet Neural Network (GWNN) architecture on the Mouse Brain Neurite Tractography dataset. The model should classify not only primary neuron subclasses but also elusive subtypes with high precision, considering the genetic variability, intricate interactions between spatial-temporal dynamics, pruning patterns, and molecular markers. Optimization should focus on robustness against variations in graph topologies.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Mouse Brain Neurite Tractography dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"neuron_subclasses\", \"subtypes\"],\n            \"specification\": {\n                \"genetic_variability\": true,\n                \"graph_topology_variability\": true\n            },\n            \"description\": \"A diverse dataset with extensive genetic variability for graph-based neuron classification task, including primary subclasses and elusive subtypes, with focus on spatial-temporal dynamics, pruning patterns, and molecular markers\",\n            \"preprocessing\": [\n                \"graph normalization\",\n                \"feature extraction\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"network visualization\"\n            ],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"GWNN (Transfer Learning)\",\n            \"family\": \"Graph Wavelet Neural Networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_architecture\": \"state-of-the-art GWNN\",\n                \"transfer_learning\": true\n            },\n            \"description\": \"A Graph Wavelet Neural Network with transfer learning capabilities for classification of neuron subclasses and subtypes on the Mouse Brain Neurite Tractography dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Spatial-temporal dynamics play a crucial role in graph neural networks\",\n        \"Pruning patterns and molecular markers may serve as additional node features\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"node feature engineering from molecular markers\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"AI platform with robust graph processing capabilities\",\n        \"inference_engine\": [\"GPU-accelerated\"],\n        \"demonstration\": \"Interactive dashboard for model performance visualization\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response incorporates the user's intent to build, high expertise level, and the requirements for a Graph Wavelet Neural Network on the specific dataset. The performance metrics, such as accuracy, are unspecified to allow optimization. Preprocessing steps like graph normalization and feature extraction, as well as molecular marker-driven feature engineering, are considered. The robustness against graph topology variations and the target deployment environment are also addressed. However, it is assumed that the exact metric values will be filled in later based on experimentation or user input.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a cutting-edge AI project manager, your mandate is to engineer a sophisticated time-series forecasting system for \"Weather Intelligence,\" a comprehensive climate data set containing multivariate information (temperature, humidity, etc.) with nested complexities. The dataset consists of 96 sequential timestamps (INPUT_SEQ_LEN) and 21 diverse variables (INPUT_DIM) in a training partition, which is separate from the validation set for optimizing model tuning and a challenging test phase involving nested seasonality, anomalies, and an additional constraint: real-time adaptability to dynamically shifting weather patterns. Your objective is to create a model that not only minimizes mean squared error (MSE) but also improves upon mean absolute percentage error (MAPE), while showcasing exceptional long-term pattern recognition and forecasting accuracy for future meteorological events over PRED_SEQ_LEN=96 steps and PRED_DIM=21 dimensions. Additionally, incorporate explainable AI principles to facilitate the understanding of model decisions.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"climate science, meteorology\",\n        \"description\": \"You are asked to design a sophisticated time-series forecasting system for Weather Intelligence dataset. The data set contains multivariate climate data with nested complexities, a train partition with 96 sequential timestamps and 21 variables, a separate validation set, and a test phase with nested seasonality, anomalies, and real-time adaptability. The goal is to develop a model that minimizes MSE and MAPE, while demonstrating strong long-term forecasting accuracy for future weather events (96 steps, 21 dimensions) and incorporates explainable AI for interpretability.\",\n        \"performance_metrics\": [\n            {\"name\": \"mean squared error\", \"value\": null},\n            {\"name\": \"mean absolute percentage error\", \"value\": null}\n        ],\n        \"complexity_metrics\": [\n            {\"name\": \"inference time\", \"unit\": \"seconds\"},\n            {\"name\": \"memory size\", \"unit\": \"GB\"}\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Weather Intelligence\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 96,\n                \"INPUT_DIM\": 21\n            },\n            \"description\": \"A comprehensive climate dataset for time-series forecasting, containing multivariate data with nested complexities. Separated into train, validation, and test partitions.\",\n            \"preprocessing\": [\"handling nested seasonality\", \"anomaly detection\"],\n            \"augmentation\": [],\n            \"visualization\": [\"time-series patterns\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced Time-series Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"parameters\": {\n                    \"model complexity\": \"high\",\n                    \"explainability techniques\": \"LIME, SHAP\"\n                }\n            },\n            \"description\": \"A complex neural network-based model designed for time-series forecasting with a focus on minimizing MSE, MAPE, and facilitating explainable AI for the Weather Intelligence dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Implement ensemble methods to improve robustness against anomalies\",\n        \"Use autoencoder for feature extraction and compression\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature extraction\", \"ensembling\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"real-time\"],\n        \"demonstration\": \"Model output visualizations with explanations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is crafted based on the given instruction, focusing on the building a complex forecasting system with the specified performance metrics and complexity constraints. The user's high expertise level is reflected, and a detailed explanation of the task is included in the description. Model-related details are also provided with a strong emphasis on explainability. Some additional insights are included in the knowledge and service sections to enhance the project.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Construct a high-performance, explainable node classification model for the arXiv Multi-disciplinary Collaboration Network using a novel Quantum-Inspired Graph Neural Network (QGNN) with advanced entanglement regularization. The model must discern not only primary research domains but also detect subtle subfields within joint work, achieving utmost precision and computational effectiveness, with an added constraint of benchmarking against the previous state-of-the-art.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"scientific collaboration\",\n        \"description\": \"The task is to construct a high-performance, explainable node classification model for the arXiv Multi-disciplinary Collaboration Network using a Quantum-Inspired Graph Neural Network (QGNN) with advanced entanglement regularization. The model should identify both primary research domains and subtle subfields within joint work, aiming for high precision and computational effectiveness, and it must outperform state-of-the-art benchmarks.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"training time\",\n                \"value\": null,\n                \"unit\": \"hours\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"arXiv Multi-disciplinary Collaboration Network\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"research_domain\", \"subfield\"],\n            \"specification\": null,\n            \"description\": \"A collaboration network dataset from arXiv, containing primary research domains and the need for detecting subfields in joint work.\",\n            \"preprocessing\": [\n                \"entanglement regularization\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Quantum-Inspired Graph Neural Network (QGNN)\",\n            \"family\": \"novel Quantum-based models\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"entanglement_regularization\": \"advanced\"\n            },\n            \"description\": \"A model that leverages quantum-inspired techniques for node classification in the arXiv Multi-disciplinary Collaboration Network.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Quantum-Inspired Graph Neural Networks are a recent and potentially high-performing approach.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"efficient\", \"explainable\"],\n        \"demonstration\": \"benchmarking against state-of-the-art models\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is constructed based on the instruction, focusing on building a high-performance node classification model using QGNN. The user's expertise is assumed to be high due to the complexity of the task. Performance metrics, including precision, recall, accuracy, and F1 score, are suggested for evaluation. Complexity metrics consider training time and memory usage. The dataset is specified as a graph and includes preprocessing steps. The model and knowledge sections reflect the specific model and the understanding that the QGNN might offer a competitive advantage.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "As the project manager for a cutting-edge research initiative, your machine learning development team has been tasked with tackling a unique node classification challenge in the field of condensed matter physics. Utilizing the High-Temporal Resolution Material Property Network (HTRMPN), we aim to analyze the intricate web of synthesized materials, their electronic properties, and experimental observations. The data, stored in an encrypted and temporally evolving graph, will necessitate the development of a novel Temporal Graph Attention Network (TGAT) model that can not only classify material nodes into novel phases but also predict phase transitions with subatomic precision. To achieve this, the team must incorporate quantum mechanical insights and develop an adaptive learning framework. The success of this project will revolutionize materials discovery, pushing the boundaries of traditional property-based predictions.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"condensed matter physics\",\n        \"description\": \"The task is to develop a novel Temporal Graph Attention Network (TGAT) model for node classification in the High-Temporal Resolution Material Property Network (HTRMPN) dataset. The model should classify material nodes into novel phases and predict phase transitions with subatomic precision, incorporating quantum mechanical insights and an adaptive learning framework.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean absolute error\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"High-Temporal Resolution Material Property Network (HTRMPN)\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"material phase\", \"phase transition\"],\n            \"specification\": {\n                \"encrypted\": true,\n                \"temporal-evolving\": true,\n                \"structure\": {\n                    \"material nodes\": {\n                        \"attributes\": \"electronic properties\"\n                    }\n                }\n            },\n            \"description\": \"Dataset for node classification in condensed matter physics, containing encrypted and temporally evolving graphs representing synthesized materials and their properties.\",\n            \"preprocessing\": [\"decryption\", \"feature engineering\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Temporal Graph Attention Network (TGAT)\",\n            \"family\": \"neural networks\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"insights\": \"quantum mechanical\",\n                \"adaptiveness\": \"adaptive learning framework\"\n            },\n            \"description\": \"A Temporal Graph Attention Network designed specifically for the High-Temporal Resolution Material Property Network, targeting material node classification and subatomic phase prediction.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Data is encrypted and requires decryption, graph structure necessitates quantum mechanical insights and adaptive learning\",\n        \"Pushing the boundaries of traditional materials property predictions\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"quantum-inspired\", \"phase transition-specific\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized\", \"cloud-based\"],\n        \"demonstration\": \"Real-time visualization of material phase classification and transition predictions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure accurately reflects the task provided, including the need for high expertise due to the complexity and specialized field. Metrics cover both performance and computational requirements. The model requirements and insights are captured in the 'model' object, and additional knowledge from the task is included in 'knowledge'. The service section accounts for necessary steps not covered in the instruction, like feature engineering and deployment.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image classification", "instruction": "As a project manager for a groundbreaking image recognition initiative, I mandate a next-gen ML model that not only distinguishes between diverse domestic and rare feline species, considering extinct breeds and individual identity through subtle markings, behavior, and crossbreeds, but also deciphers subtle age groups (neonatal, mature, and geriatric), adapts to varying lighting conditions, extreme size fluctuations, and imaging challenges like blurriness, tilt, and partial occlusions. The model must exhibit unparalleled accuracy amidst global cultural diversity in coat patterns, grooming habits, and must consistently learn from an ever-evolving, exponentially large, and geographically dispersed dataset. Furthermore, it should incorporate a novel algorithm for continuous adaptation to emerging breed variations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"zoology\",\n        \"description\": \"The project requires a next-generation image recognition model capable of distinguishing between diverse domestic and rare feline species, considering extinct breeds, individual identity through markings, behavior, and crossbreeds. The model must also identify age groups (neonatal, mature, and geriatric), handle varying lighting conditions, size fluctuations, and imaging challenges like blurriness, tilt, and partial occlusions. It should exhibit high accuracy across global cultural diversity in coat patterns and grooming habits, and continually learn from an ever-evolving, large, and geographically dispersed dataset, incorporating a novel algorithm for continuous adaptation to emerging breed variations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"species\", \"age_group\"],\n            \"specification\": null,\n            \"description\": \"A large, geographically dispersed dataset with varying images of domestic and rare felines, covering diverse coat patterns, grooming habits, and various scenarios.\",\n            \"preprocessing\": [\n                \"image resizing\",\n                \"lighting normalization\",\n                \"augmentation for size and imaging challenges\"\n            ],\n            \"augmentation\": [\n                \"blur, tilt, partial occlusion simulation\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep convolutional neural networks (CNNs) with advanced image processing techniques\",\n            \"specification\": null,\n            \"description\": \"A highly specialized model designed for fine-grained image classification of felines, incorporating real-time adaptation and robustness to diverse conditions.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Global biodiversity, regional variations in feline characteristics, and advancements in unsupervised and transfer learning techniques.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature extraction from raw images\",\n            \"contextual feature enhancement\"\n        ],\n        \"target_device\": \"cloud-based for scalable and efficient processing\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU acceleration\"],\n        \"demonstration\": \"Interactive web application showcasing real-time predictions and model performance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is structured according to the schema, reflecting the high-level intent (build) and the complexity of the task at hand. The problem description, dataset requirements, and model specifications are detailed, including the need for a novel algorithm and robustness to various challenges. The expert level is set to 'high' due to the complexity and requirements. Some specific metric values and units are missing, as those would typically require specific numbers.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As the project manager for the elite AI research team, your mandate now extends to design a highly-advanced time-series forecasting system. The Electricity dataset, with its complex nested seasonality, evolving long-term trends, and dynamically shifting short-term anomalies, poses a unique challenge. You must adhere to strict requirements: divide the data into train, validation, and test sets, maintaining non-standard input sequences of 168 hourly readings (INPUT_SEQ_LEN=168) and comprehensive 500-feature observations (INPUT_DIM=500). The model must not only predict the subsequent 288-hourly steps (PRED_SEQ_LEN=288) but demonstrate exceptional resilience to outliers, adaptability to diverse sinusoidal patterns, and tolerate autocorrelated noise in a real-world setting. Implement state-of-the-art deep learning frameworks, such as Hierarchical Attention LSTM, and optimize for precision using advanced performance metrics, including adaptive SMAPE, rolling MASE with a custom window size of 32, and a nested cross-validation loop for dynamic hyperparameter tuning. Additionally, require the development of a comprehensive benchmarking study comparing your model to five competitor algorithms and showcase interpretability of the model's decision-making process.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy management\",\n        \"description\": \"Design a highly-advanced time-series forecasting system for an Electricity dataset with complex nested seasonality, evolving long-term trends, and dynamic short-term anomalies. The model must handle non-standard input sequences of 168 hourly readings and 500-feature observations. The goal is to predict 288-hourly steps ahead while being resilient to outliers, adapt to diverse sinusoidal patterns, and handle autocorrelated noise. Implementation should utilize state-of-the-art Hierarchical Attention LSTM, optimized for precision with metrics like adaptive SMAPE, rolling MASE with a custom window size, and include a benchmarking study against five competitor algorithms, along with model interpretability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"adaptive SMAPE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"rolling MASE (custom window size 32)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Electricity dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 168,\n                \"INPUT_DIM\": 500\n            },\n            \"description\": \"A complex dataset with nested seasonality, long-term trends, and dynamic short-term anomalies, suitable for a time-series forecasting challenge.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical Attention LSTM\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_architecture\": \"State-of-the-art in time-series forecasting\",\n                \"features\": \"Hierarchical attention and LSTM layers for adaptability and resilience\",\n                \"inference_speed\": null,\n                \"memory_consumption\": null,\n                \"hyperparameter_tuning\": \"Nested cross-validation\"\n            },\n            \"description\": \"A highly-advanced time-series forecasting model using Hierarchical Attention LSTM, optimized for precision with adaptive SMAPE and rolling MASE, and capable of handling dynamic conditions.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Comprehensive benchmarking study against five competitor algorithms\",\n        \"Interpretability of model decision-making\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"state-of-the-art\"],\n        \"demonstration\": \"Explainability of model predictions and performance\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is structured based on the given instruction, indicating the project manager's responsibility for a time-series forecasting task with specific requirements. The level of expertise is assumed to be high due to the advanced requirements. The area, task, and dataset details are derived from the instructions, and the performance metrics and model requirements are specified accordingly. The missing metric values are placeholders and should be filled with target values during actual implementation.\",\n        \"score\": 0.98\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a cutting-edge project manager for an advanced time-series analytics team, your mandate is to develop a state-of-the-art forecasting system utilizing the arduous and extensive MetroTraffic dataset. This dataset contains fine-grained, ultra-high-dimensional series (10,000 hourly observations, each with 5,000 complex transport indicators, INPUT_SEQ_LEN=288, INPUT_DIM=5,000), reflecting intricate daily, weekly, and seasonal patterns. The task now calls for the creation of an innovative model that not only predicts numerous future steps (PRED_SEQ_LEN=144) but also detects anomalies dynamically, accounting for non-linear interdependencies, long-range spatio-temporal correlations, and real-time data shifts. Your challenge is to design a model with peak performance, minimizing both normalized root mean squared error (NRMSE) and log-cosh loss, while addressing complex dynamic trends and handling data stationarity issues. The project must also feature a robust feature selection strategy, a deep learning architecture integrating Transformer layers, and an explainability module that unveils predictive insights. Don't forget to detail the step-by-step pipeline, including preprocessing, feature extraction, and rigorous hyperparameter tuning.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"transportation\",\n        \"description\": \"The user is tasked with developing a state-of-the-art forecasting system using the MetroTraffic dataset. The model should predict 144 steps ahead, detect anomalies, account for non-linear interdependencies, long-range spatio-temporal correlations, and real-time data shifts. The performance metrics are NRMSE and log-cosh loss, while emphasizing peak performance, feature selection, Transformer-based deep learning architecture, and explainability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"NRMSE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"log-cosh loss\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"hours\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"MetroTraffic\",\n            \"modality\": [\n                \"time series\",\n                \"tabular\"\n            ],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 288,\n                \"INPUT_DIM\": 5000,\n                \"PRED_SEQ_LEN\": 144\n            },\n            \"description\": \"A large-scale dataset with 10,000 hourly observations and 5,000 complex transport indicators, reflecting intricate daily, weekly, and seasonal patterns in transportation.\",\n            \"preprocessing\": [\n                \"Data cleaning, handling stationarity issues\"\n            ],\n            \"augmentation\": [\n                \"None specified, likely focusing on synthetic data generation for anomaly detection\"\n            ],\n            \"visualization\": [\n                \"Exploratory data analysis for feature understanding\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"Transformer-based deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"Transformer layers\",\n                \"hyperparameters\": {\n                    \"model complexity\": \"optimized for peak performance\",\n                    \"feature selection method\": \"rigorous strategy\"\n                }\n            },\n            \"description\": \"A cutting-edge model with Transformer layers, designed for time-series forecasting, anomaly detection, non-linear interdependencies, and explainability.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Will need to handle data stationarity, non-linearities, and real-time data shifts; might involve techniques like differential privacy or domain adaptation.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"preprocessing\",\n            \"feature extraction\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\n            \"integrate with a scalable, real-time serving system\"\n        ],\n        \"demonstration\": \"Performance results with detailed feature importance and predictive insights\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response captures the complexity of the task, includes details on the dataset, performance metrics, and necessary steps. The use of a high-level model type and advanced features indicate a thorough understanding of the requirements. The potential need for expert-level expertise is indicated by the requirement for rigorous hyperparameter tuning and complex feature selection.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "image classification", "instruction": "Create an innovative, deep-learning-powered image classification model using the fusion of MViT and Squeeze-and-Excitation (SE) mechanisms, tailored for recognizing not only subtle gender and age disparities but also emotional micro-expressions and ethnicity in a highly discriminative dataset containing occluded, low-resolution, and fast-moving facial expressions under various weather conditions and cultural backdrops.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"face recognition, possibly security or emotion analysis\",\n        \"description\": \"The user requires an advanced image classification model combining MViT (Multi-View Transformer) and Squeeze-and-Excitation (SE) mechanisms. The model should be specifically designed to accurately recognize gender, age disparities, emotional micro-expressions, and ethnicity. The dataset is highly discriminative, presenting challenges due to occlusions, low-resolution, fast-moving facial expressions, and variation in weather conditions and cultural backgrounds.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"gender accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"age accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"micro-expression recognition accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"ethnicity accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"gender\", \"age\", \"emotional state\", \"ethnicity\"],\n            \"specification\": {\n                \"type\": [\"occluded\", \"low-resolution\", \"fast-moving\"],\n                \"weather_conditions\": [\"varied\"],\n                \"cultural_backdrops\": [\"varied\"]\n            },\n            \"description\": \"Highly discriminative dataset for image classification, including faces with occlusions, low-quality, fast-moving expressions, and diverse environmental conditions.\",\n            \"preprocessing\": [\"data augmentation (handling occlusions, resolution, and movement)\"],\n            \"augmentation\": [\"random cropping, resizing, and realistic occlusion techniques\"],\n            \"visualization\": [\"model input-output examples\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"MViT-SE fusion model\",\n            \"family\": \"deep learning, specifically transformer-based\",\n            \"type\": \"neural networks, likely a convolutional and transformer hybrid\",\n            \"specification\": {\n                \"architecture_details\": \"MViT blocks with Squeeze-and-Excitation layers\",\n                \"performance\": \"tunable based on training results\",\n                \"accuracy-oriented\": true\n            },\n            \"description\": \"A deep learning model combining MViT and SE mechanisms, designed for advanced facial expression analysis.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Potential challenges: handling occlusions, low-quality data, and temporal dynamics.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"attention-based feature extraction\", \"robust to noise\"],\n        \"target_device\": \"potentially cloud or GPU-enabled systems due to model complexity\",\n        \"deployment_endpoint\": \"optional, depending on the final deployment requirement\",\n        \"inference_engine\": [\"TensorFlow, PyTorch, or a custom framework\"],\n        \"demonstration\": \"example facial expression analysis results or accuracy curves on the challenging dataset\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response accurately captures the user's request for a complex image classification model, tailored for specified tasks. Expertise level is set to 'high' as the project requires advanced knowledge. Performance metrics reflect the complexity and discriminative nature of the task. Challenges, preprocessing, and model characteristics are identified.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As the project manager for the elite AI research team, your mandate is to create a highly sophisticated time-series forecasting model for the Electricity dataset. This dataset exhibits intricate dynamics, seasonal fluctuations, extended trends, and sporadic anomalies spanning multiple years. The data has been meticulously partitioned into train, validation, and test sets, with non-standard input sequences of varying lengths (INPUT_SEQ_LEN ranging from 96 to 576) and 321-dimensional observations. Your challenge is to devise a robust model that forecasts the subsequent 96-step sequences (PRED_SEQ_LEN=96) with high resolution predictions (PRED_DIM=321), while demonstrating resilience to extreme outliers, adaptability to irregular temporal patterns, and resilience to concept drift. To ensure model excellence, you must optimize for advanced evaluation metrics, such as mean squared logarithmic error, mean absolute scaled error, and incorporate a nested rolling forecast window for real-time performance monitoring and tuning. The model must also incorporate explainability features for interpretable insights.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy\",\n        \"description\": \"Create a sophisticated time-series forecasting model for the Electricity dataset, which contains intricate dynamics, seasonal fluctuations, trends, and anomalies across multiple years. The input sequences have non-standard lengths (96 to 576) and 321 dimensions. The challenge is to forecast 96-step sequences with high-resolution predictions and demonstrate resilience to outliers, irregular patterns, and concept drift. Optimize for advanced metrics like mean squared logarithmic error and mean absolute scaled error, and use a nested rolling forecast window for real-time monitoring and tuning. Incorporate explainability features for interpretable insights.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"mean_squared_logarithmic_error\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean_absolute_scaled_error\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Electricity dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": {\"min\": 96, \"max\": 576},\n                \"INPUT_DIM\": 321,\n                \"PRED_SEQ_LEN\": 96,\n                \"PRED_DIM\": 321\n            },\n            \"description\": \"A time-series dataset with complex dynamics, seasonal fluctuations, and irregularities, partitioned into train, validation, and test sets.\",\n            \"preprocessing\": [\"non-standard sequence normalization\", \"outlier handling\"],\n            \"augmentation\": [],\n            \"visualization\": [\"feature importance analysis\", \"temporal pattern visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"model_structure\": \"deep state space model, possibly with LSTM or transformers\",\n                \"explainability\": \"incorporate LIME or SHAP for interpretability\"\n            },\n            \"description\": \"A sophisticated time-series forecasting model with deep learning architecture, designed to handle Electricity dataset complexities and advanced evaluation metrics.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"nested rolling forecast window\", \"real-time performance monitoring\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"explanatory visualizations and interpretable insights\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure aligns with the given instruction, reflecting a high-level project for building a complex time-series forecasting model with specific details. The user's expertise is assumed to be high, as managing an elite AI research team suggests deep knowledge. The challenge and requirements of the model, dataset characteristics, and performance optimization are appropriately captured. However, the specific model structure and some metric values are left open for optimization based on the user's preferences.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "As the machine learning team embarks on the enhanced smart city project, they must now develop an advanced parking management system using M2Det. This involves refining the model on the 'PKLot' dataset, which requires integrating temporal, seasonal, and weather-sensitive features (accounting for low light and harsh weather). The model must achieve a minimum accuracy of 97% and boast sub-second response times (<100ms), accompanied by a comprehensive report detailing adaptability, performance comparisons with prior models, and rigorous real-world scenario testing.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"smart city\",\n        \"description\": \"The task is to develop an advanced parking management system using M2Det, focusing on the 'PKLot' dataset. The model must be refined to integrate temporal, seasonal, and weather-sensitive features, particularly for low light and harsh weather conditions. The minimum accuracy requirement is 97% and the system should have sub-second response time (<100ms). A comprehensive report is needed including adaptability analysis, performance comparison with previous models, and rigorous real-world scenario testing.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.97\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"response time\",\n                \"value\": 100,\n                \"unit\": \"ms\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"PKLot\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"temporal_features\": true,\n                \"seasonal_features\": true,\n                \"weather_features\": true\n            },\n            \"description\": \"A dataset for refining M2Det model in the context of an advanced parking management system, considering temporal, seasonal, and weather-sensitive aspects.\",\n            \"preprocessing\": [\"integration of temporal, seasonal, and weather features\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"M2Det\",\n            \"family\": \"neural networks\",\n            \"type\": \"object detection\",\n            \"specification\": {\n                \"accuracy_target\": 0.97,\n                \"response_time\": \"<100ms\"\n            },\n            \"description\": \"Advanced parking management model based on M2Det with integrated temporal, seasonal, and weather-sensitive features for the PKLot dataset.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"temporal, seasonal, and weather integration\"],\n        \"target_device\": \"edge device\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for real-time performance\"],\n        \"demonstration\": \"rigorous real-world scenario testing results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the core aspects of the given instruction, detailing the user's intent to build a model (M2Det) for a smart city parking management system. The problem description, performance and complexity metrics align with the given requirements. The high expertise level is inferred based on the advanced nature of the project. The source of the dataset is assumed to be 'user-link', and a specific target device for deployment is mentioned. The missing information, like deployment endpoint and rigorous real-world scenario details, could be filled by the user in the future.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "node classification", "instruction": "Using the Chandelier Neuron Network dataset from the Allen Institute for Brain Science, design a GraphWaveNet specifically tailored for identifying rare neurosynaptic subtypes with enhanced attention modules, optimizing F1-score, and integrating graph-level explainability techniques for deciphering complex brain connectivity patterns in mouse brains.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"neuroscience\",\n        \"description\": \"The user wants to design a GraphWaveNet using the Chandelier Neuron Network dataset from the Allen Institute for Brain Science. The task is to identify rare neurosynaptic subtypes, enhance attention modules, optimize for F1-score, and incorporate graph-level explainability techniques for understanding complex brain connectivity in mouse brains.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1-score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Chandelier Neuron Network dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"neurosynaptic_subtypes\"],\n            \"specification\": {\n                \"nodes\": {\n                    \"node_types\": \"synaptic subtypes\",\n                    \"edges\": {\n                        \"connectivity patterns\": \"complex brain connections\"\n                    }\n                },\n                \"size\": {\n                    \"node_count\": null,\n                    \"edge_count\": null\n                },\n                \"format\": {\n                    \"data_structure\": \"adjacency matrix or graph\"\n                }\n            },\n            \"description\": \"A graph-based dataset containing neurosynaptic subtypes and brain connectivity data for Chandelier neurons in mouse brains.\",\n            \"preprocessing\": [\n                \"Enhanced data preprocessing for graph representation\"\n            ],\n            \"augmentation\": [\n                \"Graph augmentation techniques for rare subtype identification\"\n            ],\n            \"visualization\": [\n                \"Graph-level explainability visualization methods\"\n            ],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"GraphWaveNet\",\n            \"family\": \"Attention-based Graph Neural Network\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_architecture\": {\n                    \"attention_modules\": \"enhanced for rare subtypes\",\n                    \"explainability_layers\": \"incorporated\"\n                },\n                \"hyperparameters\": {\n                    \"optimizer\": \"optimized for F1-score\"\n                },\n                \"node_features\": \"graph-level features\"\n            },\n            \"description\": \"A custom GraphWaveNet designed specifically for identifying rare neurosynaptic subtypes, leveraging attention and explainability techniques.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Chandelier neurons play a critical role in neural circuitry\",\n        \"Dataset is large and complex, requiring advanced graph processing techniques\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"Fine-tuning for graph representation\"\n        ],\n        \"target_device\": \"high-performance computing cluster\",\n        \"deployment_endpoint\": \"neuroscience cloud platform\",\n        \"inference_engine\": [\"GPU-based inference\"],\n        \"demonstration\": \"Interactive visualization of results and explainability\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response captures the user's requirements accurately, indicating a 'build' intent with 'high' expertise. It details the problem as graph machine learning with node classification, specifying the Chandelier Neuron Network dataset and GraphWaveNet model customization. Performance metric is F1-score, and complexity metrics include inference time and memory size. Given the complexity of the task and the need for explainability, it's assumed that preprocessing and model development will be challenging.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "question answering", "instruction": "As the project manager for our cutting-edge AI initiative, you are tasked with designing a state-of-the-art question-answering system that leverages the prowess of RoBERTa, specifically tailored for the advanced SQuAD 2.0 challenge. The system must not only exceed a stringent benchmark of 98% precision, recall, and F1 score, but also demonstrate exceptional adaptability to handle intricate queries with a historically informed context. It is essential to ensure real-time responsiveness, with all responses generated in under 1.6 seconds, even when dealing with multi-sentence comprehension and unconventional language expressions. In addition, outline a scalable design that can dynamically expand to accommodate a diverse global user base and their linguistic nuances across different domains and time periods.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"e-learning, customer support\",\n        \"description\": \"The project aims to design a state-of-the-art question-answering system using RoBERTa for the SQuAD 2.0 challenge. It must surpass a benchmark of 98% precision, recall, and F1 score, handle intricate queries with historical context, demonstrate real-time response (<1.6 seconds), and be scalable to accommodate diverse global users and linguistic nuances across domains and time periods.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.98\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": 0.98\n            },\n            {\n                \"name\": \"F1 score\",\n                \"value\": 0.98\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"response time\",\n                \"value\": 1.6,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"SQuAD 2.0\",\n            \"modality\": [\"text\", \"multimodal\"],\n            \"target_variables\": [\"context\", \"question\", \"answer\"],\n            \"specification\": null,\n            \"description\": \"A comprehensive dataset for question answering, leveraging RoBERTa and requiring sophisticated comprehension of historical context and unconventional language.\",\n            \"preprocessing\": [\"historical context extraction\", \"unnovel language handling\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"RoBERTa-based Question-Answering System\",\n            \"family\": \"neural networks\",\n            \"type\": \"transformer\",\n            \"specification\": {\n                \"model_architecture\": \"RoBERTa\",\n                \"training_pipeline\": \"adversarial\",\n                \"time_efficiency\": \"real-time response\"\n            },\n            \"description\": \"A highly advanced system tailored for SQuAD 2.0, optimized for precision, recall, and F1, with emphasis on handling complex queries.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Incorporate historical context understanding algorithms and multi-domain, multilingual adaptability mechanisms.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"contextual embeddings\", \"multi-sentence understanding\"],\n        \"target_device\": \"cloud or edge (real-time responsiveness)\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU accelerated\", \"optimized for speed\"],\n        \"demonstration\": \"multi-domain, cross-time period user case scenarios\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is based on the provided project description. It reflects the 'build' intent, targeting a high expertise level, and specifying requirements for a state-of-the-art QA system. Performance expectations, adaptability, and real-time response are detailed. The SQuAD 2.0 dataset is linked with RoBERTa's transformer and relevant preprocessing, augmentation, and scaling aspects are included. The service layer addresses real-time deployment and cloud or edge targeting.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "text classification", "instruction": "As a project manager for a specialized machine learning team, you have been handed a unique challenge to develop a cutting-edge text classification system. The project centers around the detection of subtle nuances in online forum discussions, differentiating between genuine emotional support posts (label E, 0) from empathetic yet automated responses generated by advanced AI algorithms (label A, 1). To outperform current benchmark models, the team must design a deep transformer-based architecture with attention mechanisms, incorporating sentiment analysis and dialect recognition. You must strive for a high harmonic mean of precision and recall, ensuring at least 95% detection rate within a tight time constraint of 20 seconds per inference pass, while accounting for potential class imbalance. The final model must also be interpretable to provide insights into AI's response behavior.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"emotional support detection in online forums\",\n        \"description\": \"The project aims to develop a text classification system that can distinguish genuine emotional support posts (label E, 0) from AI-generated empathetic responses (label A, 1) in online forum discussions. The team should design a deep transformer-based model with attention mechanisms, incorporating sentiment analysis and dialect recognition, to outperform benchmarks.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"harmonic mean of precision and recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"detection rate\",\n                \"value\": 0.95,\n                \"unit\": \"%\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time per pass\",\n                \"value\": 20,\n                \"unit\": \"seconds\"\n            }\n        ],\n        \"class_imbalance\": true\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Online Forum Discussions\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"post_type\", \"sentiment\", \"dialect\"],\n            \"specification\": null,\n            \"description\": \"A dataset containing genuine emotional support posts and AI-generated empathetic responses for text classification in online forum discussions.\",\n            \"preprocessing\": [\"sentiment analysis\", \"dialect recognition\"],\n            \"augmentation\": [],\n            \"visualization\": [\"interpretability analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Deep Transformer with Attention\",\n            \"family\": \"neural networks\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"transformer-based\",\n                \"attention_mechanisms\": \"true\",\n                \"interpretability\": true\n            },\n            \"description\": \"A cutting-edge model designed for text classification, leveraging sentiment analysis and dialect recognition, and aiming for high precision and recall with interpretability.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"sentiment analysis\", \"dialect recognition\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"optimized for real-time performance\"],\n        \"demonstration\": \"model interpretation and response behavior insights\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the project instruction by identifying the text classification task for detecting genuine support vs AI-generated responses. The need for a high-performing deep transformer with attention, sentiment analysis, and dialect recognition is specified. Metrics include a focus on harmonic mean, detection rate, and time constraints. The dataset and model are defined, while the project requirements around interpretability and demonstrating AI response behavior are incorporated.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "In your quest to revolutionize the realm of predictive analytics, you've been commissioned to design an advanced, fault-tolerant time-series forecasting framework for the MetropolisCity dataset. This extraordinary collection contains an intricate web of interdependent data points from various sectors like energy consumption, traffic flow, and climate variables, where each time series spans a staggering 3000 timestamps (EXTENDED_TIME_SCALE=3000) with 15 multidimensional attributes (EXTENDED_DIMENSIONS=15). The data presents an additional challenge due to its non-stationary nature and the presence of exogenous shocks, requiring a model that can gracefully handle concept drift and anomalies.\r\n\r\nThe dataset has been partitioned into train, validation, and test sets, with a complex input pattern: 720 consecutive observations (EXTENDED_INPUT_SEQ_LEN=720) representing both historical trends and cross-sectional dependencies. The task is to predict the next 1440 steps (EXTENDED_PRED_SEQ_LEN=1440) with precision, taking into account not only the traditional L1 and L2 loss metrics but also introducing a novel metric, 'Dynamic Trend Coherence' (DTC), which gauges the model's ability to adapt and maintain coherence amidst evolving trends within a rolling 24-hour period.\r\n\r\nIn addition to these requirements, the model must possess the ability to scale horizontally across distributed systems while maintaining real-time performance, enabling real-world applications in smart cities and industrial ecosystems. Showcase your expertise by developing a model architecture that exhibits state-of-the-art forecasting capabilities, resilience, and responsiveness to rapid data fluctuations, pushing the boundaries of what's considered possible in time-series forecasting.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"smart cities and industrial ecosystems\",\n        \"description\": \"The task involves designing an advanced time-series forecasting framework for the MetropolisCity dataset, dealing with non-stationarity, exogenous shocks, concept drift, and anomaly detection. The dataset spans 3000 timestamps with 15 multidimensional attributes and has been partitioned into train, validation, and test sets with a complex input pattern of 720 historical observations and 1440 steps to predict. Key performance metrics include L1 and L2 loss, along with a new metric called Dynamic Trend Coherence (DTC). The model should be scalable, fault-tolerant, and capable of real-time performance.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"L1 loss\",\n                \"value\": null\n            },\n            {\n                \"name\": \"L2 loss\",\n                \"value\": null\n            },\n            {\n                \"name\": \"Dynamic Trend Coherence (DTC)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"horizontal scalability\",\n                \"value\": null,\n                \"unit\": \"distributed systems\"\n            },\n            {\n                \"name\": \"real-time performance\",\n                \"value\": null,\n                \"unit\": \"\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"MetropolisCity\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"EXTENDED_TIME_SCALE\": 3000,\n                \"EXTENDED_DIMENSIONS\": 15\n            },\n            \"description\": \"An intricate dataset containing time series data from various sectors with 3000 timestamps and 15 multidimensional attributes, suitable for advanced time-series forecasting in the context of smart cities and industrial ecosystems.\",\n            \"preprocessing\": [\"non-stationarity handling\", \"exogenous shocks removal\"],\n            \"augmentation\": [],\n            \"visualization\": [\"dynamic trend analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"state-of-the-art time-series forecasting models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"e.g., Transformer-based, LSTM with attention mechanism\",\n                \"handling_non_stationarity\": \"e.g., Seasonality, trend decomposition\"\n            },\n            \"description\": \"An advanced, scalable, and fault-tolerant model architecture for time-series forecasting, addressing the challenges of data fluctuations and evolving trends in real-world environments.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Handling non-stationarity techniques: https://link-to-technical-papers.com/non-stationary-series/\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"horizontal scalability\", \"real-time integration\"],\n        \"target_device\": \"edge, cloud\",\n        \"deployment_endpoint\": \"custom API or compatible deployment platform\",\n        \"inference_engine\": [\"real-time streaming\", \"distributed computing\"],\n        \"demonstration\": \"live performance demonstration with dynamically evolving data\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the complexities and specific requirements mentioned in the instruction, detailing the expert-level expertise of the user and emphasizing the need for state-of-the-art, scalable, and resilient modeling. The novel metric, DTC, and the handling of complex input patterns are captured. The potential for misunderstanding lies mainly in the specifics of the model architecture and technical papers for non-stationarity handling; however, these can be further clarified with more details or links.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "Imagine a challenging task for a machine learning project where you are tasked with building a highly specialized translation engine, focused on real-time, spontaneous communication between English and a rarely explored dialect of Chinese, the Wu Dialect (spoken in Shanghai). This dialect presents unique linguistic features, such as slang, rapid verbal exchanges, and regional slang idioms that are rarely documented. The project requires the implementation of an advanced Transformer-XL architecture, as opposed to BERT, to capture the long-range dependencies in conversation flows. The model should not only translate word-for-word but also adapt to the nuances in intonation, tone, and cultural subtexts, delivering a response that sounds as if it were written by a native Wu Dialect speaker. Additionally, design the model to include a sophisticated contextual feedback system, which can dynamically correct translations in real-time, based on user interactions and continuously learn and improve from the slightest linguistic discrepancies. This project should excel at rendering authentic dialogues that seamlessly blend into the colloquial world of Wu Dialect conversations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"cross-cultural communication\",\n        \"description\": \"The task is to build a specialized translation engine for real-time, spontaneous communication between English and the Wu Dialect (spoken in Shanghai). The project requires a Transformer-XL architecture, focusing on long-range dependencies in conversation, capturing slang, rapid exchanges, and regional idioms. The model should adapt to intonation, tone, and cultural nuances, have a contextual feedback system for real-time corrections, and continually learn from user interactions.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"bleu_score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"fluency\",\n                \"value\": null\n            },\n            {\n                \"name\": \"adaptability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory_usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"real-time_feedback_rate\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Custom Wu Dialect corpus\",\n            \"modality\": [\"text\", \"audio\"],\n            \"target_variables\": [\"translated_text\"],\n            \"specification\": {\n                \"source_language\": \"English\",\n                \"target_language\": \"Wu Dialect\",\n                \"data_type\": \"real-time conversation data\",\n                \"features\": [\"word_sequences\", \"intonation_samples\", \"colloquial_exchanges\"]\n            },\n            \"description\": \"A dataset of English-Wu Dialect conversations, including real-time data on intonation, tone, slang, and regional expressions.\",\n            \"preprocessing\": [\"tokenizer for Wu Dialect\", \"data normalization\"],\n            \"augmentation\": [\"synthetic data generation for slang and colloquial expressions\"],\n            \"visualization\": [\"linguistic feature distribution\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Transformer-XL for Wu Dialect Translation\",\n            \"family\": \"Transformer\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"Transformer-XL\",\n                \"sequence_length\": null,\n                \"embedding_dim\": null,\n                \"num_heads\": null,\n                \"hidden_units\": null\n            },\n            \"description\": \"An advanced Transformer-XL model for translating English to Wu Dialect, considering long-range dependencies and context-adaptive language nuances.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Targeting colloquial expressions, slang, and regional idioms requires extensive knowledge of Wu Dialect culture and linguistic nuances.\",\n        \"Using Transformer-XL for its ability to capture long conversation flows.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"contextual feedback mechanism\",\n            \"real-time error correction algorithms\"\n        ],\n        \"target_device\": \"PC or cloud\",\n        \"deployment_endpoint\": \"cloud-based translation API\",\n        \"inference_engine\": [\"on-device processing\", \"real-time communication protocols\"],\n        \"demonstration\": \"example translations demonstrating cultural immersion and accuracy\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This JSON response accurately captures the project requirements, including the specific task (Transformer-XL based translation engine), the domain (rarely explored Wu Dialect), unique features such as capturing slang and intonation, the contextual feedback system, and the performance metrics. However, some numeric values for performance and complexity metrics are missing, as they would typically be determined through experimentation and tuning.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "node classification", "instruction": "Task the machine learning team with a specialized node classification problem using the Enron Email dataset, focusing on unraveling intricate patterns in employee interactions within the Energy sector. Design a state-of-the-art Heterogeneous Graph Neural Network (HetGNN) architecture that integrates both department and sub-department graphs, capturing fine-grained expertise dynamics. Optimize for an ultra-fast inference pipeline capable of processing highly dense graphs with over 50 million edges, while maintaining real-time performance under stringent constraints: less than 50 milliseconds latency on resource-constrained hardware tailored for energy sector analytics.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"energy sector\",\n        \"description\": \"The task involves applying a specialized node classification problem to the Enron Email dataset with a focus on understanding employee interactions in the Energy sector. The objective is to design a Heterogeneous Graph Neural Network (HetGNN) that combines department and sub-department graphs to capture expertise dynamics at a fine-grained level. The primary goal is to achieve an ultra-fast inference pipeline, capable of handling dense graphs with over 50 million edges while maintaining real-time performance with a latency constraint of less than 50 milliseconds on resource-constrained hardware for energy sector analytics.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": 50,\n                \"unit\": \"milliseconds\"\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency\",\n                \"value\": 50,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Enron Email dataset\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"employee interactions\", \"expertise dynamics\"],\n            \"specification\": {\n                \"nodes\": {\n                    \"departments\": {\n                        \"size\": null,\n                        \"density\": null\n                    },\n                    \"sub-departments\": {\n                        \"size\": null,\n                        \"density\": null\n                    }\n                },\n                \"edges\": {\n                    \"inter-department\": {\n                        \"total\": null,\n                        \"density\": null\n                    },\n                    \"intra-department\": {\n                        \"total\": null,\n                        \"density\": null\n                    }\n                },\n                \"edge_types\": [\"department_links\", \"sub_department_links\"]\n            },\n            \"description\": \"A graph dataset reflecting employee interactions in the Energy sector, containing department and sub-department graphs for a node classification task using a HetGNN.\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"edge feature engineering\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Heterogeneous Graph Neural Network\",\n            \"family\": \"graph neural networks\",\n            \"type\": \"HetGNN\",\n            \"specification\": {\n                \"architecture\": {\n                    \"integration\": \"department and sub-department\",\n                    \"fine-grained expertise capture\": true\n                },\n                \"performance\": {\n                    \"resource constrained\": true,\n                    \"inference speed target\": \"real-time\"\n                }\n            },\n            \"description\": \"A state-of-the-art HetGNN designed for employee interactions in the Energy sector, integrating department and sub-department graphs for comprehensive expertise dynamics.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"data_type\": \"dataset characteristics\",\n            \"information\": \"sparse, high-dense edge connections\"\n        },\n        {\n            \"data_type\": \"domain insights\",\n            \"information\": \"energy sector analytics requirements and constraints\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"node embedding\",\n            \"graph pooling\"\n        ],\n        \"target_device\": \"resource-constrained hardware\",\n        \"deployment_endpoint\": \"energy sector analytics platform\",\n        \"inference_engine\": [\"lightweight, optimized for latency\"],\n        \"demonstration\": \"real-time performance demonstration\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent to build a machine learning model, focusing on a node classification task. Expertise is assumed high due to the specific requirements for a state-of-the-art HetGNN and optimizing for ultra-fast inference on resource-constrained hardware. Performance metrics include accuracy and a stringent latency requirement. Dataset, model, and service requirements are derived directly from the task description.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "For the imminent underwater archeological expedition involving extreme depth and unique marine environments, the development team must enhance the YOLOv5 object detection system. The model must now identify a wider array of targets, including historical artifacts, elusive marine waste, active salvage tools, and biologically hazardous materials. It must maintain a stringent 98% average precision under challenging scenarios like turbid waters, low light, and partial occlusions. Moreover, adhere to strict real-time constraints of 20 milliseconds per frame, with a data set encrypted using state-of-the-art cryptographic protocols. Ensure seamless integration with divers' advanced wearable devices, which must provide not only real-time alerts but also generate predictive maps that minimize disturbance to the delicate underwater ecosystem while preserving historical integrity.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"underwater archaeology\",\n        \"description\": \"The user wants to enhance the YOLOv5 object detection system for an underwater archeological expedition. The model should detect historical artifacts, marine waste, active salvage tools, and biologically hazardous materials while maintaining a 98% average precision under challenging conditions like turbid waters, low light, and partial occlusions. It must process in real-time with a constraint of 20 milliseconds per frame and securely integrate with divers' wearable devices for real-time alerts and predictive maps.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"average precision\",\n                \"value\": 0.98\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time per frame\",\n                \"value\": 20,\n                \"unit\": \"milliseconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Underwater Archaeology Data (encrypted)\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"artifacts\", \"marine_waste\", \"salvage_tools\", \"biological_hazards\"],\n            \"specification\": {\n                \"encrypted\": true\n            },\n            \"description\": \"A dataset for enhancing YOLOv5 for underwater object detection with various challenging scenarios and requirements.\",\n            \"preprocessing\": [\"data encryption\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"YOLOv5 Enhanced for Underwater Archaeology\",\n            \"family\": \"YOLO\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"target_objects\": [\n                    \"historical_artifacts\",\n                    \"marine_waste\",\n                    \"salvage_tools\",\n                    \"biologically_hazardous_materials\"\n                ],\n                \"scenarios\": [\n                    \"turbid_waters\",\n                    \"low_light\",\n                    \"partial_occlusions\"\n                ]\n            },\n            \"description\": \"An enhanced YOLOv5 model with improved target recognition and performance under extreme underwater conditions.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The model must integrate with divers' wearable devices for real-time alerts and predictive maps.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"real-time data processing\"],\n        \"target_device\": \"divers' wearable devices\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"state-of-the-art cryptographic protocols\"],\n        \"demonstration\": \"real-time alerts and predictive maps\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the requested enhancement and adapts to the given constraints and requirements, including the security aspect. The explicit details on performance metrics, complexity, and the focus on integration with wearable devices and underwater ecosystem preservation demonstrate a thorough understanding of the task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "sequential recommendation", "instruction": "## Adapted Prompt for Sequential Anime Fan Experience Platform ##\r\nWithin the 'AnimeVerse X' project, create a sophisticated recommendation engine for anime enthusiasts. Leveraging the exclusive 'AnimeResonance' dataset, design a cutting-edge MFT-Transformer with Dual-Context Emotion and Context-Aware FanSub Commentary fusion (DFC-Model). This model should decode user preferences by understanding nuanced emotions, fan culture, and temporal sentiment shifts in 'AnimeVerse Chatter.' Additionally, incorporate time-sensitive fan art curation and topic-based group discussions to generate dynamic recommendations. Measure the system's impact on enhancing user dwell time and exclusive community involvement.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"recommendation systems\",\n        \"downstream_task\": \"sequential recommendation\",\n        \"application_domain\": \"entertainment\",\n        \"description\": \"For the 'AnimeVerse X' project, you are asked to develop a sophisticated recommendation engine within the context of a sequential anime fan experience platform. The main focus is on the exclusive 'AnimeResonance' dataset, where the task involves designing an MFT-Transformer with Dual-Context Emotion and Context-Aware FanSub Commentary fusion (DFC-Model). The model should capture user preferences by analyzing nuanced emotions, fan culture, and temporal sentiment changes in 'AnimeVerse Chatter.' Additionally, include time-sensitive fan art curation and topic-based group discussions for dynamic recommendations. The evaluation criteria are the system's impact on increasing user dwell time and fostering exclusive community involvement.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"user dwell time\",\n                \"value\": null\n            },\n            {\n                \"name\": \"community involvement\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"AnimeResonance\",\n            \"modality\": [\"text\", \"multimodal\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"type\": \"sequential\",\n                \"emotions\": true,\n                \"fan_culture\": true,\n                \"temporal_sentiment\": true\n            },\n            \"description\": \"The exclusive dataset for the project, containing user interactions, anime data, and fan art data, where temporal sentiment, emotions, and fan culture are key factors to consider.\",\n            \"preprocessing\": [\"emotion analysis\", \"contextual analysis\", \"temporal sentiment analysis\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"MFT-Transformer (DFC-Model)\",\n            \"family\": \"neural networks\",\n            \"type\": \"transformer\",\n            \"specification\": {\n                \"architecture\": \"MFT\",\n                \"emotion_fusion\": \"Dual-Context Emotion\",\n                \"context_fusion\": \"Context-Aware FanSub Commentary\",\n                \"time_sensitivity\": true\n            },\n            \"description\": \"The cutting-edge recommendation model that decodes user preferences through complex fusion techniques and analyzes temporal sentiment in user interactions.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"time-sensitive fan art curation\", \"topic-based discussion creation\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"enhanced user experience on the AnimeVerse X platform\"\n    },\n    \"confidence\": {\n        \"rationale\": \"This JSON response captures the essence of the user's instruction, indicating a building ('build' intent) task, with high expertise ('high' expertise level). The area is recommendation systems, targeting sequential recommendations. The 'AnimeResonance' dataset and the DFC-Model are created, considering elements like emotion, fan culture, and temporal sentiment. Performance metrics (dwell time and community involvement) and feature engineering elements of the service are also included. However, specific performance target values are left open for optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a project manager for the elite AI development team, you are now mandated to conceive a groundbreaking, deep-learning-based time-series forecasting platform. The challenge lies in handling an extensive, high-dimensional dataset (ILI-5000) with intricate, non-linear patterns across multiple interrelated sectors. The dataset spans 7 diverse dimensions (INPUT_SEQ_LEN=45, capturing historical trends), and demands the creation of a modular, hierarchical model that forecasts the subsequent 48-hour horizon (PRED_SEQ_LEN=48) with exceptional accuracy, considering long-term dependencies and subtle interannual cycles. Additionally, the project requires the implementation of explainable AI techniques, automated feature selection, and a distributed architecture to handle variable scales, while optimizing performance usingnot only Mean Squared Error (MSE) and Mean Absolute Error (MAE) but also introducing new metrics like F1-Score and RMSLE. Ensure the final solution is robust, adaptable, and provides actionable insights for real-time decision-making.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"healthcare\",\n        \"description\": \"You need to design a groundbreaking, deep-learning-based time-series forecasting platform for the ILI-5000 dataset. The dataset is high-dimensional and has complex non-linear patterns across multiple interrelated sectors, with 7 dimensions (INPUT_SEQ_LEN=45) and a 48-hour forecasting horizon (PRED_SEQ_LEN=48). The platform must handle long-term dependencies and subtle interannual cycles. Requirements include explainable AI techniques, automated feature selection, a distributed architecture, and optimization for performance using MSE, MAE, F1-Score, and RMSLE. The goal is to create a robust, adaptable solution providing actionable insights for real-time decision-making.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MSE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"MAE\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1-Score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"RMSLE\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory_size\",\n                \"value\": null,\n                \"unit\": \"GB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ILI-5000\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 45,\n                \"PRED_SEQ_LEN\": 48,\n                \"dimensions\": 7\n            },\n            \"description\": \"A large, high-dimensional dataset with intricate patterns across multiple sectors, capturing historical trends over 45 data points and forecasting a 48-hour horizon.\",\n            \"preprocessing\": [\"dimensionality reduction\", \"data normalization\"],\n            \"augmentation\": [],\n            \"visualization\": [\"interannual cycles analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"hierarchical_structure\": true,\n                \"explainable\": true,\n                \"automated_feature_selection\": true\n            },\n            \"description\": \"A modular, hierarchical deep learning model for time-series forecasting, designed to handle complex patterns in the ILI-5000 dataset with explainable AI, automated feature selection, and a distributed architecture.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"cross-correlation analysis\", \"lag features\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"custom API\",\n        \"inference_engine\": [\"GPU accelerated\"],\n        \"demonstration\": \"real-time dashboard for actionable insights\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure reflects the instruction's requirements, detailing the high-level objective ('build'), the high level of expertise expected, and the specific problem domain, task, and dataset characteristics. Performance metrics are included, and the model's deep-learning focus is appropriate for the task. However, some specific metric targets, like the F1-Score, are also open-ended. The distributed architecture and real-time dashboard are suggested based on general expectations for such projects.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "image classification", "instruction": "The project manager demands a custom-designed CNN for niche fine-grained flower classification in the CIFAR-100 dataset, targeting 99.8% accuracy with minimal computational overhead. Mandate the integration of MobileNetV2 for transfer learning, but also optimize for low-power embedded devices with limited GPU RAM.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"computer vision\",\n        \"description\": \"The task is to design a custom CNN for fine-grained flower classification in the CIFAR-100 dataset, with a target accuracy of 99.8%. The model should be optimized for minimal computational overhead, and specifically integrate MobileNetV2 for transfer learning, while catering to low-power embedded devices with limited GPU RAM.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.998\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null, \n                \"unit\": \"ms\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null, \n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"CIFAR-100\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"flower_class\"],\n            \"specification\": {\n                \"image_size\": [32, 32, 3]\n            },\n            \"description\": \"The CIFAR-100 dataset for fine-grained flower classification task, targeting low-power embedded devices.\",\n            \"preprocessing\": [\"MobileNetV2 transfer learning\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Custom CNN\",\n            \"family\": \"CNN\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"MobileNetV2-based with transfer learning\",\n                \"GPU RAM optimization\": true\n            },\n            \"description\": \"A custom CNN model for fine-grained flower classification, leveraging MobileNetV2 for transfer learning and optimized for low-power embedded devices with limited GPU RAM.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"MobileNetV2 feature extraction\"],\n        \"target_device\": \"low-power embedded devices\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized for low-power devices\"],\n        \"demonstration\": \"Evaluation on low-power embedded hardware\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the key aspects specified in the instruction. The intent is to build a model, with high expertise level. The problem lies in computer vision, specifically image classification for fine-grained flower classification. The target performance metric is set to 99.8% accuracy, and the model should cater to minimal computational overhead and low-power embedded devices. MobileNetV2 is included for transfer learning, and the model requirements are adjusted to accommodate the resource constraints.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "link prediction", "instruction": "Elaborate on the development of a novel, highly efficient and explainable deep learning model, specifically tailored for link prediction in the Citeseer repository. Emphasize the importance of handling sparse data, integrating domain knowledge, and optimizing performance while ensuring interpretability in the face of limited citation patterns.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"link prediction\",\n        \"application_domain\": \"scientific citation networks\",\n        \"description\": \"The task requires developing a novel, highly efficient, and explainable deep learning model for link prediction in the Citeseer repository. Attention must be given to handling sparse data, integrating domain knowledge, and optimizing performance while ensuring interpretability in situations with limited citation patterns.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"AUC-ROC\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Citeseer\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"edges\"],\n            \"specification\": {\n                \"sparse_data\": true\n            },\n            \"description\": \"A scientific citation network dataset where the task is to predict future citation links.\",\n            \"preprocessing\": [\"handling sparse data\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Novel Deep Learning Model\",\n            \"family\": \"explainable deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"tailored for link prediction\",\n                \"integrates_domain_knowledge\": true,\n                \"interpretability_techniques\": [\"attention mechanisms\", \"explainable graph neural networks\"]\n            },\n            \"description\": \"A deep learning model designed specifically for link prediction in the Citeseer repository with an emphasis on efficiency, interpretability, and handling sparse data by integrating domain knowledge and using interpretable techniques.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"text\": \"Citeseer's unique characteristics make it a challenging dataset in link prediction, necessitating a model that is robust to sparse data and designed for interpretability in the face of limited citation patterns.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"domain-specific feature extraction\"],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorFlow serving\"],\n        \"demonstration\": \"Interactive case studies showcasing interpretability\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response accurately represents the user's instruction by detailing the intent to build a novel model, specifying the area and task, handling sparse data, integrating domain knowledge, and ensuring interpretability. Performance metrics are specified, while leaving space for optimization, and the deployment environment and some related tasks are clearly defined.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "As the AI project director for a cutting-edge luxury fashion e-commerce platform, you're faced with the challenge of bridging the gap in communication for a sophisticated customer base that spans multiple continents. The platform has recently merged with a high-end fashion house renowned for its intricate design language and exclusive industry acronyms, as well as a niche sustainable fashion startup using environmentally specific terminologies. Your mandate is to design a state-of-the-art machine translation system that not only translates haute couture requests promptly, but also discerns regional fashion dialects, translates technical terms related to sustainable fabrics and production methods, and adapts to nuances in fashion culture, ensuring each translated message preserves the luxury brand's tone and prestige. Moreover, outline a comprehensive integration plan for integrating this system into the sophisticated CRM platform and devise a comprehensive training program for in-house fashion consultants to harness the technology's power, aiming to elevate customer interactions and reduce response times without compromising exclusivity.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"luxury fashion, e-commerce, sustainability\",\n        \"description\": \"Design a machine translation system for a high-end fashion e-commerce platform, translating haute couture requests, regional fashion dialects, technical terms on sustainable fabrics, and preserving luxury brand tone. The system must integrate into a CRM, and a training program for in-house fashion consultants is required.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"response time\",\n                \"value\": null\n            },\n            {\n                \"name\": \"accuracy (luxury tone)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision (technical terms)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall (regional dialects)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"real-time translation capability\",\n                \"value\": null,\n                \"unit\": \"delay-sensitive\"\n            },\n            {\n                \"name\": \"system scalability\",\n                \"value\": null,\n                \"unit\": \"requests/second\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"luxury fashion terms\", \"technical sustainable terms\"],\n            \"specification\": null,\n            \"description\": \"A diverse collection of haute couture requests, fashion dialects, technical sustainability data, and luxury brand communication samples.\",\n            \"preprocessing\": [\"specialized terminology processing\"],\n            \"augmentation\": [\"domain-specific translation variations\"],\n            \"visualization\": [\"data distribution analysis\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"neural machine translation\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"sequence-to-sequence\",\n                \"model_size\": null,\n                \"encoder_decoder_layers\": null\n            },\n            \"description\": \"A sophisticated NMT system for luxury fashion translations.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Luxury fashion industry specific jargon, regional fashion slang, and sustainability terminology need to be considered.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"brand tone preservation algorithms\",\n            \"custom dialect recognition\"\n        ],\n        \"target_device\": \"cloud\",\n        \"deployment_endpoint\": \"sophisticated CRM platform\",\n        \"inference_engine\": [\"GPU-optimized\"],\n        \"demonstration\": \"tailored training sessions and personalized translations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is created based on the given instruction, which focuses on designing a high-end machine translation system for a luxury fashion e-commerce platform. The expertise level is assumed to be high due to the complexity of the task. A comprehensive integration plan, training, and specific metrics are proposed. However, actual model specifications and performance values are left open for optimization.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a leading-edge AI project manager for a specialized time-series forecasting team, you have been commissioned to design an advanced predictive model using the recently released ORISv4 dataset. This dataset comprises ultra-dense, geospatially-tagged financial data with extreme granularity, posing unique challenges due to variablelength sequences (MAX_SEQ_LEN=2048), a diverse range of asset types (ASSET_TYPES=50), and a multidimensional prediction task (PRED_SEQ_LEN=128, PRED_DIM=15). The model must not only optimize for precision, recall, and F1-score, but also dynamically adapt to unstructured economic indicators and unexpected market shifts, showcasing adaptability and resistance to data drift. Your team's objective is to surpass the latest record in Explainable AI-driven forecasts while reducing computational requirements by 40% compared to earlier projects, all while meeting a tight project deadline of 30 days.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"finance\",\n        \"description\": \"The task is to design an advanced predictive model for time-series forecasting using the ORISv4 dataset. The dataset has ultra-dense, geospatially-tagged financial data with variable length sequences (MAX_SEQ_LEN=2048), diverse asset types (ASSET_TYPES=50), and a multidimensional prediction task with sequences of length PRED_SEQ_LEN=128 and PRED_DIM=15. The model should optimize for precision, recall, and F1-score, while being adaptable to unstructured economic indicators and handling unexpected market shifts. The goal is to achieve Explainable AI-driven forecasts with a 40% reduction in computational requirements compared to previous projects within a 30-day deadline.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1-score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"computational efficiency\",\n                \"value\": -0.4,\n                \"unit\": \"percentage reduction compared to previous projects\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ORISv4\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"financial indicators\"],\n            \"specification\": {\n                \"MAX_SEQ_LEN\": 2048,\n                \"ASSET_TYPES\": 50,\n                \"PRED_SEQ_LEN\": 128,\n                \"PRED_DIM\": 15\n            },\n            \"description\": \"The recently released ORISv4 dataset with ultra-dense, geospatially-tagged financial data for time-series forecasting, including variable-length sequences, diverse asset types, and a multidimensional prediction task.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"advanced time-series model\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"adaptability\": \"to unstructured economic indicators and unexpected market shifts\",\n                \"data_drift_resistance\": true\n            },\n            \"description\": \"A state-of-the-art, adaptable model designed for Explainable AI-driven time-series forecasting, targeting precision, recall, and F1-score optimization, and a 40% reduction in computational requirements compared to earlier projects.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"explanable AI-driven forecasts\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the instruction by specifying a build task for an AI project manager. The problem statement describes the ORISv4 dataset's properties and the requirements for the model, which include optimizing precision, recall, and F1-score, adaptability, and computational efficiency. The dataset, model, and performance metrics are derived directly from the given instruction.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "image segmentation", "instruction": "In a scenario where you've been commissioned to develop a cutting-edge, real-time monitoring system for the Arctic ecosystem, leveraging high-resolution data from multiple Sentinel-1 and Sentinel-2 missions, your team is challenged with the complex task of differentiating between ice sheets, arctic tundra, submerged ice, fragile permafrost, and unique wildlife habitats. With constraints on satellite revisit times and energy consumption, design and implement a novel fusion of image segmentation models, such as a hybrid of EfficientNet and Mask R-CNN, optimizing for interpretability, precision at scale, and energy-efficient inference. Can you create a model that not only outperforms existing methods in accuracy but also adapts dynamically to seasonal changes while maintaining the resilience to handle the extreme conditions?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image segmentation\",\n        \"application_domain\": \"ecology, environmental monitoring\",\n        \"description\": \"The user is tasked with developing a real-time monitoring system for the Arctic ecosystem, which requires differentiating between ice sheets, arctic tundra, submerged ice, fragile permafrost, and wildlife habitats. The project involves using high-resolution data from Sentinel-1 and Sentinel-2 missions, with constraints on satellite revisit times and energy consumption. The focus is on a novel fusion of image segmentation models, specifically a hybrid of EfficientNet and Mask R-CNN, aiming for high accuracy, interpretability, precision at scale, and energy-efficient inference, while adapting to seasonal changes and handling extreme conditions.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"interpretability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision_at_scale\",\n                \"value\": null\n            },\n            {\n                \"name\": \"energy_efficiency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference_time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"energy_consumption\",\n                \"value\": null,\n                \"unit\": \"kWh\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Sentinel-1 and Sentinel-2 missions\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"ice sheets\", \"arctic tundra\", \"submerged ice\", \"permafrost\", \"wildlife habitats\"],\n            \"specification\": {\n                \"resolutions\": [\n                    {\n                        \"sensor\": \"Sentinel-1\",\n                        \"resolution\": \"high\"\n                    },\n                    {\n                        \"sensor\": \"Sentinel-2\",\n                        \"resolution\": \"high\"\n                    }\n                ],\n                \"satellite_revisit_times\": null,\n                \"energy_consumption_per_image\": null\n            },\n            \"description\": \"High-resolution imagery from Sentinel-1 and Sentinel-2 missions for monitoring the Arctic ecosystem with extreme conditions.\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"feature extraction\"\n            ],\n            \"augmentation\": [\"seasonal\"],\n            \"visualization\": [\"classification maps\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hybrid of EfficientNet and Mask R-CNN\",\n            \"family\": \"neural network\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_complexity\": {\n                    \"parameters\": null,\n                    \"FLOPs\": null\n                },\n                \"interpretability_techniques\": null,\n                \"optimized_for\": [\"energy-efficient\", \"interpretable\"]\n            },\n            \"description\": \"A state-of-the-art image segmentation model combining the efficiency of EfficientNet and advanced object detection of Mask R-CNN, designed for real-time monitoring and extreme environment adaptability.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"feature fusion\",\n            \"adapting for seasonal changes\"\n        ],\n        \"target_device\": \"energy-efficient hardware (e.g., embedded devices or edge computing)\",\n        \"deployment_endpoint\": \"real-time monitoring infrastructure\",\n        \"inference_engine\": [\"optimized for the target device\"],\n        \"demonstration\": \"seasonal performance demonstration\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure captures the essence of the given problem, including the image segmentation task, specific models, constraints, and performance metrics. The user's high expertise level is indicated, and seasonal adaptation and energy efficiency are key considerations. However, specific metric values are not provided and would need to be filled based on future model performance.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "time-series classification", "instruction": "You are now tackling a specialized time-series classification challenge using the Intricate Physical Phenomena dataset, which consists of high-resolution, noisy, and non-stationary signals. The train, validation, and test splits have been carefully curated with unevenly sampled observations (INPUT_SEQ_LEN=1000, INPUT_DIM=300, introducing missing data). The task demands not only precise classification (labels: {A, B, C, D}) but also resilience to outliers and phase shifts. Your objective is to engineer a deep learning model that demonstrates superior F1-score and robustness under various time lags, without using any data augmentation techniques.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"engineering\",\n        \"description\": \"You are tasked with a specialized time-series classification challenge using the Intricate Physical Phenomena dataset, featuring high-resolution, noisy, and non-stationary signals. The dataset splits contain unevenly sampled observations (INPUT_SEQ_LEN=1000, INPUT_DIM=300) with missing data, and the objective is to classify between labels {A, B, C, D} while achieving a high F1-score and being robust to outliers and phase shifts. Data augmentation techniques should not be employed.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1-score\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"response to outliers\",\n                \"value\": null,\n                \"unit\": \"tolerance\"\n            },\n            {\n                \"name\": \"phase shift robustness\",\n                \"value\": null,\n                \"unit\": \"degrees\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Intricate Physical Phenomena\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [\"A\", \"B\", \"C\", \"D\"],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 1000,\n                \"INPUT_DIM\": 300\n            },\n            \"description\": \"A high-resolution, noisy, and non-stationary time-series dataset with uneven sampling and missing data for time-series classification.\",\n            \"preprocessing\": [\n                \"handling missing data\",\n                \"imputation\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_structure\": {\n                    \"use_of_deep_layers\": true,\n                    \"residual_connections\": false,\n                    \"dropout_layers\": true,\n                    \"special_layers\": [\"robust layers for outliers\"]\n                },\n                \"optimization\": {\n                    \"regularization techniques\": [\"dropout\", \"weight regularization\"]\n                }\n            },\n            \"description\": \"A deep learning model designed for time-series classification in the Intricate Physical Phenomena dataset, demonstrating high F1-score and robustness against outliers and phase shifts.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"handling missing data\", \"normalization\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": null\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response reflects the information provided in the instruction, including the dataset description, the task of achieving high F1-score and robustness, the absence of data augmentation, and the intention to engineer a deep learning model. Expertise is assumed high due to the complexity of the task. Some missing information could be fill in more details of feature engineering and normalization process, as well as target device and deployment options.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "multimodal forgery detection", "instruction": "As the global job market becomes more competitive, forged resumes and certificates have infiltrated the professional realm, posing a severe threat to the integrity of skills assessments and hiring processes. Develop a highly sophisticated multimodal forgery detection system that integrates visual, text, and behavioral analysis for detecting subtle nuances in audio recordings, facial expressions, and even handwriting patterns, ensuring the authenticity of LinkedIn profiles, CVs, and official transcripts in real-time. This cutting-edge solution must also provide granular explanations for its detection decisions, maintaining the highest standard of fairness and accountability.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"multimodal learning\",\n        \"downstream_task\": \"multimodal forgery detection\",\n        \"application_domain\": \"cybersecurity, job market integrity\",\n        \"description\": \"The user is asking to build a highly sophisticated multimodal forgery detection system, capable of integrating visual, text, and behavioral analysis to detect forged resumes, certificates, LinkedIn profiles, CVs, and official transcripts in real-time. It should focus on audio recordings, facial expressions, and handwriting patterns. The system must provide detailed explanations for detection decisions and maintain fairness and accountability.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"false positive rate\",\n                \"value\": null\n            },\n            {\n                \"name\": \"false negative rate\",\n                \"value\": null\n            },\n            {\n                \"name\": \"explanation generation accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"real-time processing\",\n                \"value\": true\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Multimodal forgery dataset (specifically for LinkedIn profiles, CVs, transcripts, etc)\",\n            \"modality\": [\n                \"image\",\n                \"text\",\n                \"audio\",\n                \"video\",\n                \"multimodal\"\n            ],\n            \"target_variables\": [\"forgery_status\"],\n            \"specification\": {\n                \"audio_depth\": null,\n                \"image_dimensions\": null,\n                \"text_length\": null,\n                \"video_duration\": null,\n                \"data_samples\": null\n            },\n            \"description\": \"A comprehensive dataset for multimodal forgery detection, including visual, text, and behavioral data for real-time analysis.\",\n            \"preprocessing\": [\n                \"audio normalization\",\n                \"image feature extraction\",\n                \"text preprocessing\",\n                \"behavioral data preprocessing\"\n            ],\n            \"augmentation\": [\n                \"audio synthesis\",\n                \"image augmentation\",\n                \"text augmentation\"\n            ],\n            \"visualization\": [\n                \"data modalities correlation analysis\",\n                \"performance metric visualizations\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Multimodal Forgery Detection Model\",\n            \"family\": \"neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"architecture\": \"Convolutional Neural Networks (CNNs) for images, Recurrent Neural Networks (RNNs) for text, and Deep Learning models for audio and behavioral analysis\",\n                \"number_of_layers\": null,\n                \"accuracy_target\": null,\n                \"explainability_module\": true\n            },\n            \"description\": \"A deep learning model that integrates various modalities to detect forgery in professional documents and behavioral data.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Recent research on multimodal fusion and explainable AI methods\",\n        \"Importance of fairness and explainability in detecting sensitive forgery cases\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"contextual embeddings\",\n            \"attention mechanisms\"\n        ],\n        \"target_device\": \"cloud or edge\",\n        \"deployment_endpoint\": \"real-time forgery detection API\",\n        \"inference_engine\": [\n            \"TensorFlow\",\n            \"PyTorch\"\n        ],\n        \"demonstration\": \"Interactive explanations for detection decisions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the task by indicating a 'build' intent, high expertise level, and specifying multimodal forgery detection as the problem area. It includes relevant performance metrics like accuracy and fairness, accounting for the need for granular explanations. The dataset and model details are specific to the task, and a list of required services and potential inference engines is provided. However, some metric values and exact models architectures are hypothetical and would require additional information from the user.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "image classification", "instruction": "As a project manager for the AI team, your mandate is to develop an advanced image recognition system using the 'CryptocarpusCrypticus and Monocots Plant Seedlings Dataset'. Task: engineer a real-time, transfer learning-based convolutional neural network (ResNet-50), fine-tuning on the unique plant varietal features. Target accuracy above 95%, maintaining latency below 0.5 seconds per image analysis for seamless user experience. Outline potential challenges and expected improvements over a baseline model in the project documentation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"botany or agriculture\",\n        \"description\": \"The project involves developing an advanced image recognition system, specifically for real-time plant seedlings classification using ResNet-50 with transfer learning. The target accuracy is above 95% and the system must process images with an inference latency of less than 0.5 seconds.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"inference latency\",\n                \"value\": 0.5\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"latency per image analysis\",\n                \"value\": 0.5,\n                \"unit\": \"seconds\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"CryptocarpusCrypticus and Monocots Plant Seedlings Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"plant_varietal_features\"],\n            \"specification\": {\n                \"train_split\": \"presumably given\",\n                \"test_split\": \"presumably given\",\n                \"image_shape\": \"presumably specified in the dataset description\"\n            },\n            \"description\": \"A dataset for real-time plant seedlings recognition, with ResNet-50 fine-tuning required.\",\n            \"preprocessing\": [\"transfer learning (ResNet-50)\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"ResNet-50\",\n            \"family\": \"convolutional neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"type_of_transfer_learning\": \"presumably fine-tuning\",\n                \"base_model_layers\": \"resnet50\",\n                \"custom_layers\": \"for plant varietal features\"\n            },\n            \"description\": \"Fine-tuned ResNet-50 model for real-time image recognition of plant seedlings\"\n        }\n    ],\n    \"knowledge\": [\n        \"Challenges: Transfer learning performance, computational efficiency, overfitting, real-time constraint. Improvements: Customized layers, better data augmentation, efficient inference techniques.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"adaptation for plant varietal features\"\n        ],\n        \"target_device\": \"presumably specified in the project requirements\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"real-time processing\"],\n        \"demonstration\": \"real-time image analysis with latency and accuracy feedback\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent to build an image recognition system, targeting a high level of expertise. The area, task, and application domain are specific to plant seedlings. Performance metrics and complexity metrics are included. Challenges and improvements are mentioned, along with expected service requirements. Since specific details like training splits and exact latency are not given, they have been left unspecified (e.g., 'presumably given').\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "tabular regression", "instruction": "For a prestigious real estate data challenge, develop a state-of-the-art tabular regression model using the House Price dataset. In addition to standard prediction tasks, ensure missing value imputation with domain-specific rules, encode categorical variables with custom feature embeddings, and apply feature selection based on economic indicators. Compute the root mean squared error (RMSE) on logarithm-transformed eval data, differentiating high-end properties and reflecting real-world price discrepancies.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"tabular data analysis\",\n        \"downstream_task\": \"tabular regression\",\n        \"application_domain\": \"real estate\",\n        \"description\": \"The user is participating in a real estate data challenge, requiring a state-of-the-art tabular regression model for house price prediction. The model must handle missing values with domain-specific imputation, encode categorical variables using custom feature embeddings, and apply feature selection based on economic indicators. The model should evaluate using root mean squared error (RMSE) on log-transformed data, focusing on high-end properties to account for real-world price variations.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"RMSE\",\n                \"value\": null,\n                \"target_value\": \"optimized for high-end properties\"\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"House Price dataset\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"house_price\"],\n            \"specification\": {\n                \"contains_missing_values\": true,\n                \"categorical_variables\": true\n            },\n            \"description\": \"A dataset for a real estate challenge, containing house price information and requiring imputation, categorical encoding, and feature selection.\",\n            \"preprocessing\": [\n                \"missing value imputation with domain-specific rules\",\n                \"categorical variable encoding with custom feature embeddings\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"state-of-the-art\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"handling_missing_data\": \"domain-specific imputation\",\n                \"encoding_categorical\": \"custom embeddings\"\n            },\n            \"description\": \"A state-of-the-art tabular regression model for the House Price dataset with focus on prediction, missing value imputation, categorical encoding, and economic indicators-based feature selection.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\n            \"domain-based feature engineering\",\n            \"economic indicators-based feature selection\"\n        ],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"Include a high-end property and explain how RMSE is computed with real-world price discrepancies\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response covers all the aspects of the task given, from the model building to the evaluation criterion (RMSE) and additional processing steps. The expert-level expertise is assumed based on the complexity of the task. The only missing piece could be the target RMSE value for the high-end properties, which would need to be derived from the dataset or competition guidelines.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series anomaly detection", "instruction": "Train a cutting-edge, multi-step time-series anomaly detection model using a diverse ensemble of server datasets (ASD, PSM, and additional contemporaneous sources), considering real-time data streams and historical patterns. Ensure model scalability and performance optimization for seamless deployment on my enterprise server infrastructure to pinpoint not only sudden spikes but also gradual anomalies and potential seasonal variations.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series anomaly detection\",\n        \"application_domain\": \"IT infrastructure\",\n        \"description\": \"The user requests a multi-step time-series anomaly detection model that can handle diverse server datasets (ASD, PSM, and contemporaneous sources). The model should be scalable, optimized for performance, and suitable for real-time data streams and detecting both sudden spikes and gradual anomalies, as well as potential seasonal variations. The model must be designed for seamless deployment on the user's enterprise server infrastructure.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            },\n            {\n                \"name\": \"F1 Score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"scalability\",\n                \"value\": null\n            },\n            {\n                \"name\": \"performance optimization\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"compute resource usage\",\n                \"value\": null,\n                \"unit\": \"% CPU\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ASD\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"real-time_data\": true,\n                \"historical_data_coverage\": null,\n                \"data_stream_dimensions\": null\n            },\n            \"description\": \"Server dataset ASD for anomaly detection\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"feature normalization\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        },\n        {\n            \"name\": \"PSM\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"real-time_data\": true,\n                \"historical_data_coverage\": null,\n                \"data_stream_dimensions\": null\n            },\n            \"description\": \"Server dataset PSM for anomaly detection\",\n            \"preprocessing\": [\n                \"data cleaning\",\n                \"feature extraction\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        },\n        {\n            \"name\": \"Contemporary Sources\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"real-time_data\": true,\n                \"historical_data_coverage\": null,\n                \"data_stream_dimensions\": null\n            },\n            \"description\": \"Additional contemporaneous datasets for anomaly detection\",\n            \"preprocessing\": [\n                \"data integration\",\n                \"feature engineering\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Multi-Step Ensemble Anomaly Detection Model\",\n            \"family\": \"ensemble models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model architecture\": \"ensemble of different algorithms (e.g., LSTM, GRU, Prophet)\",\n                \"number_of_models\": null,\n                \"real-time_prediction\": true,\n                \"seasonality_handling\": true\n            },\n            \"description\": \"An advanced model using diverse algorithms, tailored for server anomaly detection with scalability and performance optimization\"\n        }\n    ],\n    \"knowledge\": [\n        \"consider real-time data streams, historical patterns, and data from multiple sources for improved accuracy\",\n        \"account for gradual anomalies and seasonal variations in the detection process\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\n            \"dynamic feature selection\",\n            \"feature importance analysis\"\n        ],\n        \"target_device\": \"enterprise server infrastructure\",\n        \"deployment_endpoint\": \"custom API or production environment\",\n        \"inference_engine\": [\"C++ for real-time processing\", \"GPU acceleration\"],\n        \"demonstration\": \"providing a live demo showcasing detection results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the user's intent for building an advanced anomaly detection model, details about the ensemble of time-series datasets, and performance and complexity requirements. The requested sophistication level is high given the multi-step model and the emphasis on enterprise infrastructure. The chosen ensemble models and techniques are appropriate for the task. Some details, such as specific model architecture or target values, are missing and can be filled in after further consultation.\",\n        \"score\": 0.8\n    }\n}\n"}
{"task": "image classification", "instruction": "For an upcoming advanced image classification project, your team has been tasked with developing a state-of-the-art system for a niche domain: underwater ethological analysis. You have access to a diverse set of underwater photographs, capturing various marine species, their behaviors, and unique environmental elements. The goal is to not only identify 50 distinct species of marine life (including cryptic species and rare sub-species) but also to classify their activities into 15 distinct ethological categories such as mating rituals, feeding patterns, and social interactions. Please design an annotation process, propose a tailored deep learning architecture, and outline a strategy for evaluating the model's performance in low-visibility conditions while preserving the color and texture nuances of the underwater world.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"aquatic research\",\n        \"description\": \"Your team is to develop a state-of-the-art image classification system for underwater ethological analysis. The project involves identifying 50 distinct species of marine life, including cryptic and rare sub-species, and categorizing their activities into 15 ethological categories. The system must handle low-visibility conditions and preserve color and texture nuances.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"precision\",\n                \"value\": null\n            },\n            {\n                \"name\": \"recall\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Underwater Ethological Analysis Dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"species\", \"ethological_category\"],\n            \"specification\": {\n                \"image_size\": null,\n                \"color_depth\": null\n            },\n            \"description\": \"A diverse set of underwater photographs capturing marine species, behaviors, and environmental elements for annotation and training.\",\n            \"preprocessing\": [\n                \"Enhance color and texture preservation\"\n            ],\n            \"augmentation\": [\n                \"Low-visibility condition simulation\",\n                \"Image normalization\"\n            ],\n            \"visualization\": [\n                \"Sample image annotations and category distribution\"\n            ],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"UnderwaterEthoClassifier\",\n            \"family\": \"Convolutional Neural Networks (e.g., DenseNet, ResNet, or specialized models like U-Net)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"number_of_layers\": null,\n                    \"detection_layers\": null,\n                    \"classification_layers\": null\n                },\n                \"training_details\": {\n                    \"optimizer\": null,\n                    \"learning_rate\": null,\n                    \"epochs\": null\n                }\n            },\n            \"description\": \"A deep learning architecture tailored for underwater ethological analysis, capable of handling low-visibility, color, and texture nuances.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"text\": \"Consider transfer learning from similar high-quality underwater image datasets or pre-trained models to improve performance in low-visibility conditions.\"\n        },\n        {\n            \"text\": \"Collaborate with domain experts for annotation accuracy and ethological understanding.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"Annotation guidelines for nuanced classification\"],\n        \"target_device\": \"Edge or Cloud GPU-based for efficient low-visibility inference\",\n        \"deployment_endpoint\": \"Custom or existing platform for hosting and serving the model in underwater monitoring systems\",\n        \"inference_engine\": [\"Real-time or offline inference, depending on the system's hardware\"],\n        \"demonstration\": \"Interactive dashboard showcasing classification results and heatmaps of model confidence\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON is crafted based on the provided instruction, capturing the high-level requirements, problem domain, and complexity. The user's expertise is assumed to be high due to the advanced nature of the task. Performance metrics like accuracy, precision, and recall are relevant, as well as constraints on inference time and memory. The instruction suggests a CNN architecture and tailored solutions for low-visibility and nuances.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "sequential recommendation", "instruction": "For the upgraded fitness app, design an advanced recommendation system that not only suggests personalized workout sequences, but also dynamically adjusts them based on user's progress, including real-time performance analysis, goal alignment, past workout enjoyment, and integration of external fitness data, ensuring long-term engagement and continuous improvement.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"recommendation systems\",\n        \"downstream_task\": \"sequential recommendation\",\n        \"application_domain\": \"health and fitness\",\n        \"description\": \"The user requires an advanced recommendation system for a fitness app. The system should personalize workout sequences, dynamically adjust based on user progress, real-time performance analysis, goal alignment, past workout enjoyment, and external fitness data integration. The goal is to increase long-term engagement and promote continuous improvement for users.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"personalization\",\n                \"value\": null\n            },\n            {\n                \"name\": \"engagement_rate\",\n                \"value\": null\n            },\n            {\n                \"name\": \"goal_relevance\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"response_time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory_usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"user_profile_data\",\n            \"modality\": [\"tabular\"],\n            \"target_variables\": [\"fitness_goals\", \"past_workout_history\", \"user_preferences\"],\n            \"specification\": null,\n            \"description\": \"User's personal data, including progress, preferences, and past workout history.\",\n            \"preprocessing\": [\"data cleaning\", \"feature extraction\"],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"performance trends\",\n                \"goal alignment visualization\"\n            ],\n            \"source\": \"user-upload\"\n        },\n        {\n            \"name\": \"external_data\",\n            \"modality\": [\"tabular\", \"time series\"],\n            \"target_variables\": [\"health_indicators\", \"external_fitness_data\"],\n            \"specification\": null,\n            \"description\": \"Integration of external fitness data, such as wearable sensor data or app integrations.\",\n            \"preprocessing\": [\"data synchronization\", \"feature extraction\"],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"real-time performance analysis\",\n                \"integration visualization\"\n            ],\n            \"source\": \"user-link\" \n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Advanced Recommendation System\",\n            \"family\": \"neural networks\",\n            \"type\": \"sequential recommendation\",\n            \"specification\": {\n                \"architecture\": \"deep learning-based, possibly with a recurrent or transformer component\",\n                \"parameters\": \"number of layers, hidden units, and learning rate\"\n            },\n            \"description\": \"A complex system leveraging deep learning to dynamically recommend personalized workout sequences.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Incorporate user feedback loops for continuous model improvement\",\n        \"Use reinforcement learning to optimize sequence suggestions\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"custom embeddings for user progress analysis\", \"goal-oriented ranking\"],\n        \"target_device\": \"smartphones, wearable devices, and cloud\",\n        \"deployment_endpoint\": \"backend API for real-time recommendations\",\n        \"inference_engine\": [\"on-device processing\", \"server-side computation\"],\n        \"demonstration\": \"Interactive UI showcasing personalized workout sequences and progress updates\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is crafted based on the given instruction, demonstrating a 'build' intent for a complex recommendation system. The user's expertise level is assumed as 'high'. The problem areas are recommendation systems and sequential recommendation, within a fitness context. Specific performance metrics are not provided but can be inferred to be relevant. The system's complexity and dynamic adjustment align with the instruction, and multiple data modalities are considered. The confidence score is moderately high due to the extensive requirements.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "image classification", "instruction": "For a highly accurate and fine-grained classification of my diverse collection of cat images, including breeds,colors, and coat patterns, recommend a state-of-the-art convolutional neural network architecture suitable for multi-label image classification, while considering computational efficiency and real-time performance.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"animal recognition, pet care\",\n        \"description\": \"The user wants to build a state-of-the-art model for fine-grained multi-label classification of diverse cat images, including breed, color, and coat pattern recognition. Real-time performance and computational efficiency are key requirements.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"mean average precision (mAP)\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"milliseconds\"\n            },\n            {\n                \"name\": \"memory usage\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"User's Cat Images\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\n                \"breed\",\n                \"color\",\n                \"coat_pattern\"\n            ],\n            \"specification\": null,\n            \"description\": \"A diverse collection of cat images for multi-label classification\",\n            \"preprocessing\": [\n                \"image resizing\",\n                \"data augmentation\"\n            ],\n            \"augmentation\": [\n                \"random cropping\",\n                \"color jitter\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"convolutional neural networks\",\n            \"type\": \"state-of-the-art\",\n            \"specification\": {\n                \"architecture\": \"e.g., EfficientNet, DenseNet, or ResNeXt\",\n                \"parameters\": {\n                    \"depth\": \"Determined by the chosen architecture\",\n                    \"width\": \"Determined by the chosen architecture\",\n                    \"efficientNet_size\": \"Not specified\"\n                },\n                \"efficiency\": \"Targeted for computational efficiency\"\n            },\n            \"description\": \"A fine-grained multi-label cat image classifier using a state-of-the-art CNN architecture with an emphasis on computational efficiency and real-time performance.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"content\": \"Considering both computational efficiency and real-time performance suggests using techniques like MobileNet, Xception, or a SqueezeNet derivative, as they are lightweight and optimized for these requirements.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"high-performance embedded devices, mobile, or cloud\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-optimized, tensorFlow.js or edgeTPU\"],\n        \"demonstration\": {\n            \"example\": \"Interactive UI showcasing breed, color, and pattern predictions on hover or selection\",\n            \"format\": \"Real-time results\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response adheres to the schema and captures the detailed requirements of a machine learning project for image classification. The user's intent is to build, and their expertise is high. Metrics include accuracy and mean average precision for classification performance. Computational efficiency and real-time performance are considered, with suggestions for lightweight CNN architectures. The process for handling the dataset and choosing a model is clear, as is the expected service such as real-time predictions on targeted devices and a demonstration.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series classification", "instruction": "As a project manager for the advanced machine learning team, you're faced with a sophisticated time-series classification challenge using the elusive Handwriting dataset. The dataset, stratified into train, validation, and test segments, consists of intricate, high-dimensional time series (INPUT_SEQ_LEN=152, INPUT_DIM=3) reflecting real-world patterns. Your team's objective is to develop a cutting-edge model that not only accurately predicts labels ranging from 0 to 25 but also demonstrates robustness across varying lengths and feature complexity. Additionally, the model must exhibit exceptional performance and generalization on unseen fixed sequences, with the benchmark being state-of-the-art accuracy metrics.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series classification\",\n        \"application_domain\": \"artificial intelligence/finance (handwriting recognition)\",\n        \"description\": \"The task involves developing a cutting-edge time-series classification model on the Handwriting dataset. The dataset is stratified into train, validation, and test sets with high-dimensional, intricate time series data (INPUT_SEQ_LEN=152, INPUT_DIM=3) representing real-world patterns. The model must predict labels ranging from 0 to 25, demonstrate robustness to varying lengths and feature complexity, and achieve state-of-the-art accuracy on unseen fixed sequences.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"robustness to varying lengths\",\n                \"value\": null,\n                \"unit\": \"\"\n            },\n            {\n                \"name\": \"robustness to feature complexity\",\n                \"value\": null,\n                \"unit\": \"\"\n            },\n            {\n                \"name\": \"state-of-the-art performance\",\n                \"value\": null,\n                \"unit\": \"\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Handwriting dataset\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 152,\n                \"INPUT_DIM\": 3\n            },\n            \"description\": \"A stratified dataset into train, validation, and test segments, with high-dimensional and complex time series data for time-series classification, ranging from label 0 to 25.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"high-performance models\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"state-of-the-art\": true\n            },\n            \"description\": \"A cutting-edge neural network model designed for time-series classification on the Handwriting dataset, demonstrating exceptional accuracy and robustness to length and feature complexity variations.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": {\n            \"description\": \"State-of-the-art performance demonstration on unseen fixed sequences\"\n        }\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON representation is structured according to the provided schema and includes high-level details from the given task. The intent is clear to build a sophisticated model, expertise is assumed to be high given the project manager role, and the problem area and downstream task are specified. Performance metrics are set to the benchmark of state-of-the-art accuracy. Complexity is mentioned in terms of robustness. Specific model details are assumed based on the level of sophistication required. Missing parts are placeholders, which could be completed based on further information from the user.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "question answering", "instruction": "As a project manager for a machine learning development team, you've been tasked with creating a specialized knowledge management system for a niche industry - underwater archaeology. The team has been requested to design an AI-powered question-answering platform using the limited and highly technical \"DeepSeaArchaeologyQA\" dataset. The platform should demonstrate efficient understanding of maritime historical artifacts, excavation methods, and historical significance. Aim to develop a mid-range model that balances accuracy with response time, catering to the needs of researchers and enthusiasts alike. The model should be scalable and capable of handling domain-specific jargon effectively without sacrificing its efficiency. What steps and models would you recommend for this project?", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"question answering\",\n        \"application_domain\": \"underwater archaeology\",\n        \"description\": \"The project involves designing an AI-powered question-answering platform for underwater archaeology. The platform should be based on the 'DeepSeaArchaeologyQA' dataset, focusing on understanding maritime historical artifacts, excavation methods, and historical significance. The model should achieve a balance between accuracy and response time, be scalable, and handle domain-specific jargon efficiently.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"response time\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"scalability\",\n                \"value\": null,\n                \"unit\": \"None (desirable)\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"DeepSeaArchaeologyQA\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"domain\": \"underwater archaeology\",\n                \"jargon_bound\": true\n            },\n            \"description\": \"A specialized dataset for underwater archaeology with a focus on question-answering. It contains data on maritime historical artifacts, excavation methods, and historical significance.\",\n            \"preprocessing\": [\"handling domain-specific jargon\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"mid-range question-answering model\",\n            \"family\": \"neural networks (e.g., transformers or LSTM-based)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"mid-range architecture balancing accuracy and speed\",\n                \"parameters\": \"optimized for the mid-range performance\",\n                \"FLOPs\": \"sufficient for reasonable response time\"\n            },\n            \"description\": \"A neural network model designed specifically for underwater archaeology question answering, with a focus on efficiency and domain understanding.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The dataset contains limited and technical information, emphasizing the need for models that can extract and understand domain-specific knowledge effectively.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"adaptation to domain-specific jargon\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU for fast response time\"],\n        \"demonstration\": \"Demonstration of efficient handling of niche questions and artifacts using the platform\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The provided response reflects the requirements of the project manager, including a focus on building a model with a specific dataset and task, performance metrics, and a balance between accuracy and speed. The information about the dataset and model complexities, knowledge required, and deployment considerations are derived from the instructions. High expertise level is assumed given the project manager role.\",\n        \"score\": 0.95\n    }\n}"}
{"task": "image classification", "instruction": "As a project manager for a senior-level space image analysis competition, seek a deep learning model to classify diverse celestial objects (galaxies, nebulae, and meteors) using a specific, less conventional dataset sourced from NASA archives. Evaluate the complexity of data preprocessing, model selection (e.g., convolutional neural networks with transfer learning), and the potential for achieving state-of-the-art accuracy with limited labeled samples.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"image classification\",\n        \"application_domain\": \"astronomy\",\n        \"description\": \"As a project manager for a space image analysis competition, you need to develop a deep learning model to classify celestial objects like galaxies, nebulae, and meteors using an unconventional NASA dataset. The focus is on evaluating data preprocessing complexity, leveraging transfer learning with convolutional neural networks, and achieving state-of-the-art accuracy with limited labeled samples.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"state-of-the-art comparison\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"data preprocessing complexity\",\n                \"value\": null,\n                \"unit\": \"effort or time\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"NASA unconventional space image dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"galaxies\", \"nebulae\", \"meteors\"],\n            \"specification\": {\n                \"source\": \"NASA archives\",\n                \"label_distribution\": \"limited labeled samples\"\n            },\n            \"description\": \"Unconventional dataset containing celestial images to be classified into galaxies, nebulae, and meteors with challenging sample availability.\",\n            \"preprocessing\": [],\n            \"augmentation\": [\n                \"transfer learning-based data augmentation\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"convolutional neural networks\",\n            \"type\": \"deep learning\",\n            \"specification\": {\n                \"transfer learning approach\": true\n            },\n            \"description\": \"A deep learning model incorporating transfer learning techniques for classifying celestial objects from the NASA dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Limited labeled data implies a focus on semi-supervised or few-shot learning techniques.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"showcase performance on a small subset of test data\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure is derived from the given instruction, focusing on the user's intent to build a model, their high expertise level, and the project's requirements for image classification, transfer learning, and limited labeled data. Performance metrics include accuracy and state-of-the-art comparison, along with a placeholder for data preprocessing complexity. The unconventional NASA dataset is mentioned with appropriate properties, and a convolutional neural network model is suggested for the task.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "As a machine learning project manager for a specialized team in advanced energy demand forecasting, your team must develop an autoregressive integrated moving average (ARIMA) model using the hourly ETTm2 dataset with seasonality adjustments. This dataset consists of solar, wind, and load data for the last two years, organized into train (first 80%), validation (months 5-7), and test (months 8-10) partitions. Model performance must exceed a MAE of 2% and MSE of 5% on predicting the next 96 steps, considering the interdependencies across 7 distinct features. Ensure efficient feature engineering and regularization is applied to minimize prediction errors.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy\",\n        \"description\": \"The task is to develop an ARIMA model for advanced energy demand forecasting using the hourly ETTm2 dataset, with seasonality adjustments. The dataset includes solar, wind, and load data for the past two years, split into train, validation (months 5-7), and test (months 8-10) partitions. Model performance must have a mean absolute error (MAE) less than 2% and mean squared error (MSE) less than 5% in predicting the next 96 steps while considering the interdependencies across 7 features.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"MAE\",\n                \"value\": 0.02\n            },\n            {\n                \"name\": \"MSE\",\n                \"value\": 0.05\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"prediction steps\",\n                \"value\": 96,\n                \"unit\": \"time steps\"\n            },\n            {\n                \"name\": \"features\",\n                \"value\": 7\n            }\n        ],\n        \"preprocessing\": {\n            \"techniques\": [\"seasonality adjustments\"]\n        },\n        \"regularization\": {\n            \"methods\": [\"applied\"]\n        }\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ETTm2\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"time_range\": \"past two years\",\n                \"train_split\": \"80%\",\n                \"validation_months\": \"5-7\",\n                \"test_months\": \"8-10\",\n                \"features\": 7\n            },\n            \"description\": \"Hourly dataset with solar, wind, and load data for the last two years, split into train, validation, and test partitions.\",\n            \"preprocessing\": [\n                {\n                    \"step\": \"seasonality adjustments\"\n                }\n            ],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"ARIMA\",\n            \"family\": \"\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"model_name\": \"ARIMA\",\n                \"forecast_horizon\": 96,\n                \"feature_interdependencies\": \"7 distinct features\"\n            },\n            \"description\": \"An ARIMA model designed for advanced energy demand forecasting, with efficient feature engineering and regularization techniques.\"\n        }\n    ],\n    \"knowledge\": [],\n    \"service\": {\n        \"feature_engineering\": [\"None provided in the instruction\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response accurately reflects the instruction for developing an ARIMA model with specific performance, dataset, and preprocessing requirements. The model type, ARIMA, is suitable for forecasting with time-series data, and the metrics, MAE, MSE, and feature interdependencies are clearly defined. Regularization is mentioned to minimize prediction errors. However, since there's no information about the target device or deployment, those are left as empty.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "For a cutting-edge research project, your task is to design and implement a Hierarchical Attention GraphSAGE (HAGS) model that integrates multi-scale neighborhood aggregation for the challenging problem of node classification in the biochemical domain, leveraging the challenging ChEMBL database. The model must not only demonstrate exceptional transfer learning capabilities but also optimize for interpretability, allowing researchers to trace reasoning behind predictions. It must be trained on a limited labeled dataset while maintaining a minimum F1-score of 0.9 and an average inference time of 25ms per molecule to cater to high-throughput screening applications in drug discovery. Additionally, your model should be scalable to accommodate future additions of chemical compounds without significant performance degradation.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"biochemical\",\n        \"description\": \"The project involves designing and implementing a Hierarchical Attention GraphSAGE (HAGS) model for node classification in the biochemical domain using the ChEMBL database. The model should have exceptional transfer learning capabilities, focus on interpretability, maintain a minimum F1-score of 0.9, and have an average inference time of 25ms per molecule for high-throughput screening in drug discovery. It should be scalable for future additions of chemical compounds.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"F1-score\",\n                \"value\": 0.9\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"average inference time\",\n                \"value\": 25,\n                \"unit\": \"ms\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ChEMBL\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"chemical compound classification\"],\n            \"specification\": {\n                \"size\": \"limited\",\n                \"interpretability_required\": true\n            },\n            \"description\": \"A challenging biochemical dataset for node classification using a GraphSAGE model, focusing on drug discovery with high-throughput screening constraints.\",\n            \"preprocessing\": [\n                \"multi-scale neighborhood aggregation\"\n            ],\n            \"augmentation\": [],\n            \"visualization\": [\n                \"interpretability features for model predictions\"\n            ],\n            \"source\": \"direct-search\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical Attention GraphSAGE (HAGS)\",\n            \"family\": \"neural networks\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"transfer_learning\": true,\n                \"interpretable\": true,\n                \"num_of_parameters\": null,\n                \"flops\": null,\n                \"train_speed\": null\n            },\n            \"description\": \"A model that integrates multi-scale neighborhood aggregation for node classification in the biochemical domain, emphasizing interpretability and fast inference time.\"\n        }\n    ],\n    \"knowledge\": [\n        \"The model should handle transfer learning for chemical compound classification and be scalable for future additions.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"optimized for high-throughput screening\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"optimized for real-time molecular analysis\"],\n        \"demonstration\": \"interpretability-driven reasoning for predictions\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON structure has been constructed based on the provided instruction, taking into account the user's high expertise level. The problem area, task, and datasets are derived from the text. Performance metrics, complexity constraints, and specific model requirements have been included. Some information like exact data size or specific model architecture details are left open-ended, as they would need more specific information from the user or research.\",\n        \"score\": 0.85\n    }\n}\n"}
{"task": "text classification", "instruction": "As a highly specialized machine learning project manager for a cutting-edge AI research team, you've been tasked with developing a groundbreaking text classification model. The team has been assigned the \"Quantum Mindset Dataset,\" a confidential collection of texts that blend philosophical debates, quantum physics, and AI-generated content. The objective is to classify these texts as either reflecting a human intellectual discourse (labeled 0) or showcasing an advanced AI's comprehension of these topics (labeled 1). The challenge lies in differentiating between the intricate human interpretations and the AI's ability to simulate intellectual depth. To impress the scientific community, strive for state-of-the-art accuracy and explainability in your model. Additionally, the project manager must also develop a method for assessing the model's ethical implications on the future of AI-human collaboration. Good luck in navigating this intellectually demanding project.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"philosophy, quantum physics, and AI research\",\n        \"description\": \"The task is to develop a groundbreaking text classification model using the Quantum Mindset Dataset, which consists of philosophical debates, quantum physics, and AI-generated content. The objective is to classify texts as human intellect (0) or AI understanding (1) while achieving state-of-the-art accuracy and explainability. Additionally, the model's ethical implications on AI-human collaboration should be assessed.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"explainability\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Quantum Mindset Dataset\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"human_intellect\", \"ai_comprehension\"],\n            \"specification\": null,\n            \"description\": \"A confidential dataset combining philosophical debates, quantum physics, and AI-generated content, with the aim to classify human intellect versus AI comprehension.\",\n            \"preprocessing\": [],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"\",\n            \"family\": \"\",\n            \"type\": \"neural networks with explainable AI methods\",\n            \"specification\": {\n                \"explainability_techniques\": [\"attention mechanisms\", \"LIME\", \"SHAP\"]\n            },\n            \"description\": \"A cutting-edge text classification model using neural networks, optimized for high accuracy and explainability on the Quantum Mindset Dataset, differentiating between human intellect and AI comprehension.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Potential ethical implications to consider: bias in data, transparency, intellectual property, AI's role in shaping human discourse, and societal impact on collaborative learning.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [],\n        \"demonstration\": \"A comprehensive model interpretation and ethical analysis report\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response has been constructed based on the provided instruction, maintaining the schema guidelines. The task of building a model is clearly stated with high expertise level. The area and task are in natural language processing and text classification. The Quantum Mindset Dataset, performance metrics, and the need for ethical implications are all captured. The model type and specifications align with the requirements, and some best practices are suggested for explanation and ethics assessment.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "time-series forecasting", "instruction": "You are working on a specialized deep temporal forecasting project, utilizing the intricate ElectricityDemand dataset. This data contains seasonality and trends in hourly consumption over 3 years. The train, validation, and test splits consist of historical data with a unique context window (INPUT_SEQ_LEN=504 hourly readings, including 21 specific features). Your challenge is to design and fine-tune a state-of-the-art Seasonal Autoregressive Integrated Moving Average with Exponential Smoothing (SARIMA-ES) model, anticipating future values for PRED_SEQ_LEN=168 hours, also factoring in long-range dependencies. Performance must be assessed via mean squared logarithmic error (MSLE) and mean absolute percentage error (MAPE), requiring a balance between accuracy and interpretability.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"time-series analysis\",\n        \"downstream_task\": \"time-series forecasting\",\n        \"application_domain\": \"energy\",\n        \"description\": \"You are tasked with building a deep temporal forecasting project using the ElectricityDemand dataset, focusing on hourly electricity consumption with seasonality and trends over 3 years. The objective is to design and fine-tune a state-of-the-art SARIMA-ES model with a context window of 504 hourly readings and a forecasting horizon of 168 hours, considering long-range dependencies. Performance will be measured using mean squared logarithmic error (MSLE) and mean absolute percentage error (MAPE), aiming for a balance between accuracy and interpretability.\",\n        \"performance_metrics\": [\n            {\"name\": \"mean squared logarithmic error (MSLE)\", \"value\": null},\n            {\"name\": \"mean absolute percentage error (MAPE)\", \"value\": null}\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"ElectricityDemand\",\n            \"modality\": [\"time series\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"INPUT_SEQ_LEN\": 504,\n                \"specific_features\": {\n                    \"hourly readings\": 21,\n                    \"seasonality and trends\": {},\n                    \"unique context window\": 504\n                }\n            },\n            \"description\": \"A dataset for electricity demand forecasting with 3 years of hourly data, including 21 specific features, seasonality, and trends.\",\n            \"preprocessing\": [\"feature extraction\", \"time-series normalization\"],\n            \"augmentation\": [],\n            \"visualization\": [\"anomaly detection\", \"forecast visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"SARIMA-ES\",\n            \"family\": \"time-series forecasting\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"long-range dependencies\": true,\n                \"hidden layers\": [],\n                \"model architecture\": \"SARIMA with Exponential Smoothing\"\n            },\n            \"description\": \"A state-of-the-art SARIMA-ES model designed for deep temporal forecasting of electricity demand, considering long-range dependencies.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Consider using seasonal decomposition for feature extraction\",\n        \"Regularly evaluate model interpretability during hyperparameter tuning\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"feature engineering, decomposition\", \"selecting relevant components\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"TensorFlow Serving\", \"due to its flexibility\"],\n        \"demonstration\": \"Include a visual demonstration of forecast results\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response incorporates the user's intent to build a model, highlighting a deep temporal forecasting project. Expertise level is assumed high due to the specialized task. The area and downstream task are specified, as well as the requirements for data and performance metrics. The ElectricityDemand dataset is well described, with necessary preprocessing steps and model expectations. The SARIMA-ES model is a suitable choice for the task, and the required fine-tuning steps are included. The confidence score reflects a high level of confidence based on the instructions given.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "As a project manager for the enhanced safety initiative, task the ML team with the following: Develop a cutting-edge deep learning model based on the COCO dataset and an exclusive industrial scene augmentation, employing Hierarchical Anchor-Free Architectures. The model must specifically detect not only standard safety gear compliance but also intricate hazards like faulty machinery, slippery floors, and misplaced materials, targeting a stringent benchmark of 98% precision and real-time performance. Emphasize the importance of edge computing for on-site surveillance and continuous monitoring.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"industrial safety\",\n        \"description\": \"As a project manager, you want the ML team to develop a cutting-edge deep learning model using the COCO dataset, with industrial scene-specific augmentation. The model should detect safety gear compliance and intricate hazards like faulty machinery, slippery floors, and misplaced materials, aiming for 98% precision and real-time performance. Emphasis is on edge computing for on-site surveillance and continuous monitoring.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"precision\",\n                \"value\": 0.98\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": 0.0,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory size\",\n                \"value\": 0.0,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"real-time performance\",\n                \"value\": null,\n                \"unit\": \"yes\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"COCO dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [],\n            \"specification\": {\n                \"specific_augmentation\": \"industrial scene\"\n            },\n            \"description\": \"A base dataset for industrial scene object detection, augmented for specific hazards like faulty machinery, slippery floors, and misplaced materials.\",\n            \"preprocessing\": [],\n            \"augmentation\": [\n                \"industrial scene augmentation\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Hierarchical Anchor-Free Architecture\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": {\n                    \"target_tasks\": \"object detection\"\n                },\n                \"model_complexity\": {\n                    \"precision_target\": 0.98\n                }\n            },\n            \"description\": \"A deep learning model designed for detecting safety gear compliance and intricate hazards using the COCO dataset with industrial scene augmentation.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"text\": \"Emphasis on edge computing for real-time on-site surveillance and continuous monitoring.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"edge computing\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"real-time processing\"],\n        \"demonstration\": \"on-site surveillance and continuous monitoring\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the project manager's instruction, detailing the area, downstream task, and model requirements. The performance metric of 98% precision and the need for real-time performance are specified. The importance of edge computing for the surveillance system is also included. The schema is followed accordingly.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "text classification", "instruction": "As a project manager seeking to enhance the machine learning classification of the 20 Newsgroups dataset with enhanced scalability, you must evaluate and compare at least five state-of-the-art algorithms (e.g., BERT, XGBoost, and Hugging Face's Transformer variants) while considering their fine-tuning parameters, computational efficiency, and potential for transfer learning. Additionally, assess the impact of ensemble methods and provide a detailed time-cost analysis for both training and inference stages, factoring in hardware acceleration options.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"text classification\",\n        \"application_domain\": \"text classification (e.g., news categorization)\",\n        \"description\": \"The project aims to enhance the machine learning classification of the 20 Newsgroups dataset with a focus on scalability. This requires evaluating, comparing, and experimenting with state-of-the-art algorithms like BERT, XGBoost, and Hugging Face's Transformer variants. Considerations include fine-tuning parameters, computational efficiency, transfer learning potential, ensemble methods, and a thorough time-cost analysis for training and inference stages, factoring in hardware acceleration options.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"efficiency (computational)\",\n                \"value\": null\n            },\n            {\n                \"name\": \"transfer learning effectiveness\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"training time\",\n                \"value\": null,\n                \"unit\": \"hours\"\n            },\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"20 Newsgroups\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"category\"],\n            \"specification\": {\n                \"size\": null,\n                \"dimensionality\": null\n            },\n            \"description\": \"A text classification dataset for news categorization with focus on scalability\",\n            \"preprocessing\": [\"Standard text preprocessing\"],\n            \"augmentation\": [],\n            \"visualization\": [],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"BERT, XGBoost, Hugging Face Transformers\",\n            \"family\": [\"neural networks, ensemble models\"],\n            \"type\": [\"transformers\", \"ensemble\"],\n            \"specification\": {\n                \"fine-tuning_params\": null,\n                \"computational_resources\": {\n                    \"GPU support\": true,\n                    \"CPU support\": true\n                }\n            },\n            \"description\": \"Comparative study of various state-of-the-art algorithms for enhanced classification of the 20 Newsgroups dataset.\"\n        }\n    ],\n    \"knowledge\": [\n        \"Scalability considerations and hardware acceleration options.\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"fine-tuning\", \"hyperparameter optimization\"],\n        \"target_device\": [\"cloud, edge devices, mobile\"],\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"GPU-accelerated, CPU fallback\"],\n        \"demonstration\": \"Results showcasing accuracy, efficiency, and transfer learning impacts\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response captures the essence of the project's requirements, focusing on algorithm evaluation, scalability, and performance metrics. Expertise is assumed to be high due to the complexity of the project. The ensemble methods, fine-tuning, hardware acceleration, and time-cost analysis are adequately addressed. However, some specific numerical values for performance metrics and complexity metrics are not provided, as they would be determined through the experimentation process.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "machine translation", "instruction": "Create a cutting-edge neural machine translation system for low-resource languages, specifically targeting indigenous dialects from remote Amazonian tribes. The model should integrate MARGE (Multilingual Representation and Generation for Exploratory Research) architecture, trained on a diverse mix of endangered languages and scientific articles. The project must prioritize performance on extremely low-resource devices with limited computational power, while achieving near-native translation quality and minimizing real-time latency for live conferencing scenarios.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"natural language processing\",\n        \"downstream_task\": \"machine translation\",\n        \"application_domain\": \"linguistics and indigenous language support\",\n        \"description\": \"The task is to create a cutting-edge neural machine translation system specifically for low-resource languages, focusing on indigenous dialects from remote Amazonian tribes. The model should utilize the MARGE architecture and be trained on a diverse mix of endangered languages and scientific articles. The priority is to achieve high performance on low-resource devices with limited computational power while maintaining near-native translation quality and minimizing real-time latency for live conferencing.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": null\n            },\n            {\n                \"name\": \"BLEU score\",\n                \"value\": null\n            },\n            {\n                \"name\": \"near-native translation quality\",\n                \"value\": null\n            },\n            {\n                \"name\": \"real-time latency\",\n                \"value\": null\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"inference time\",\n                \"value\": null,\n                \"unit\": \"seconds\"\n            },\n            {\n                \"name\": \"memory footprint\",\n                \"value\": null,\n                \"unit\": \"MB\"\n            },\n            {\n                \"name\": \"computational power requirement\",\n                \"value\": {\n                    \"minimum\": {\n                        \"processing_units\": null,\n                        \"memory\": null\n                    },\n                    \"target\": {\n                        \"processing_units\": \"low-end device-friendly\",\n                        \"memory\": \"limited\"\n                    }\n                }\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"MARGE training corpus\",\n            \"modality\": [\"text\"],\n            \"target_variables\": [\"translated_text\"],\n            \"specification\": {\n                \"languages\": [\"endangered indigenous languages\", \"scientific articles\"],\n                \"diversity\": \"mixed\"\n            },\n            \"description\": \"A diverse training dataset comprising endangered languages and scientific articles, serving as the foundation for the MARGE architecture.\",\n            \"preprocessing\": [\"low-resource data preprocessing\"],\n            \"augmentation\": [\"data augmentation for low-resource languages\"],\n            \"visualization\": [\"dataset language distribution analysis\"],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Neural Machine Translation System\",\n            \"family\": \"Transformer-based (MARGE architecture)\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architectural_details\": \"MARGE with low-resource optimizations\",\n                \"translated_language_domain\": \"low-resource indigenous dialects\"\n            },\n            \"description\": \"A state-of-the-art neural machine translation model using MARGE, specifically designed for low-resource indigenous languages with optimizations for limited hardware.\"\n        }\n    ],\n    \"knowledge\": [\n        \"MARGE architecture and its effectiveness in multilingual scenarios\",\n        \"Adaptation to low-resource scenarios for machine translation\"\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"adaptation for extremely low-resource devices\"],\n        \"target_device\": \"low-resource devices\",\n        \"deployment_endpoint\": null,\n        \"inference_engine\": [\"optimized for real-time latency\"],\n        \"demonstration\": \"live translation scenarios for indigenous languages\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The parsed JSON adheres to the given schema and accurately represents the task's requirements. The user's intent is to build, their expertise is assumed to be high due to the complexity. The MARGE architecture and low-resource optimizations are clearly specified. Performance metrics include accuracy, BLEU score, and low-latency. Complexity metrics consider device requirements and real-time latency optimization.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "node classification", "instruction": "Utilize the Mouse Brain Connectivity dataset, with a stringent 98% accuracy requirement, to develop a Graph Wavelet Neural Network (GWNN) for node classification. Emphasize on differentiating neuron types with minimal error, preserving edge importance, and demonstrating robustness against varying spatial scales in the dataset.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"graph machine learning\",\n        \"downstream_task\": \"node classification\",\n        \"application_domain\": \"neuroscience\",\n        \"description\": \"The goal is to develop a Graph Wavelet Neural Network (GWNN) using the Mouse Brain Connectivity dataset, targeting a high accuracy of 98%. The focus is on accurately differentiating neuron types, preserving edge importance, and ensuring robustness against varying spatial scales.\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"accuracy\",\n                \"value\": 0.98\n            }\n        ],\n        \"complexity_metrics\": []\n    },\n    \"dataset\": [\n        {\n            \"name\": \"Mouse Brain Connectivity\",\n            \"modality\": [\"graph\"],\n            \"target_variables\": [\"node_type\"],\n            \"specification\": {\n                \"accuracy_target\": 0.98,\n                \"spatial_scale_varying\": true\n            },\n            \"description\": \"A dataset for node classification in graph machine learning, focusing on mouse brain connectivity with the need for high accuracy and considerations for neuron type differentiation, edge importance, and spatial scale robustness.\",\n            \"preprocessing\": [\"Data normalization, preprocessing for GWNN\"],\n            \"augmentation\": [],\n            \"visualization\": [\"Graph structure and performance visualization\"],\n            \"source\": \"user-upload\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"Graph Wavelet Neural Network\",\n            \"family\": \"neural networks\",\n            \"type\": \"graph neural networks\",\n            \"specification\": {\n                \"architecture\": \"GWNN\",\n                \"architecture_details\": \"Differentiating neuron types, preserving edge importance, and handling varying spatial scales\"\n            },\n            \"description\": \"A Graph Wavelet Neural Network designed specifically for the Mouse Brain Connectivity dataset, aiming to meet the 98% accuracy requirement for node classification.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"content\": \"Understanding the dataset's edge properties and neuron types is crucial for the GWNN's success.\"\n        },\n        {\n            \"content\": \"Robustness against spatial scales may involve incorporating scale-specific features or wavelet transformations.\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [\"Graph convolutional operations\", \"Wavelet transformations\"],\n        \"target_device\": \"\",\n        \"deployment_endpoint\": \"\",\n        \"inference_engine\": [\"Support for GWNNs in deployment\"],\n        \"demonstration\": \"Demonstration of node classification performance across different neuron types and spatial scales\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The response captures the user's intent, the high-level requirements of accuracy, and the specific technical details. It acknowledges the dataset type and source, incorporates performance metrics, and specifies the model type (GWNN). The graph neural network architecture and preprocessing steps are aligned with the given constraints. Key knowledge points and service requirements are also included. The provided confidence score of 0.95 reflects the assumption that the user has a high level of expertise and the instruction is fairly clear.\",\n        \"score\": 0.95\n    }\n}\n"}
{"task": "object detection", "instruction": "As a project manager for the next-generation smart city initiative, we aim to design an advanced parking management system. The AI model should employ M2Det, a sophisticated variant, for real-time detection of occupied and vacant parking spots using the extensive 'PKLot' dataset. The system must demonstrate multi-level reasoning for intricate scene analysis, ensuring robust performance in low light, adverse weather, and dynamic environments. The model should not only exceed a detection accuracy of 95% but also prioritize efficiency with response times strictly below 150 milliseconds, while considering scalability and energy consumption for widespread deployment.", "resposne": "{\n    \"user\": {\n        \"intent\": \"build\",\n        \"expertise\": \"high\"\n    },\n    \"problem\": {\n        \"area\": \"computer vision\",\n        \"downstream_task\": \"object detection\",\n        \"application_domain\": \"smart city\",\n        \"description\": \"Design an advanced parking management system using M2Det for real-time detection of occupied and vacant parking spots in a next-generation smart city initiative. The system must exhibit multi-level reasoning for complex scene analysis and achieve a detection accuracy of at least 95% with response times below 150 milliseconds, while considering scalability and energy efficiency for large-scale deployment in challenging conditions (low light, adverse weather, dynamic environments).\",\n        \"performance_metrics\": [\n            {\n                \"name\": \"detection accuracy\",\n                \"value\": 0.95\n            },\n            {\n                \"name\": \"response time\",\n                \"value\": 150\n            }\n        ],\n        \"complexity_metrics\": [\n            {\n                \"name\": \"energy consumption\",\n                \"value\": null,\n                \"unit\": \"unknown\"\n            },\n            {\n                \"name\": \"scalability\",\n                \"value\": null\n            }\n        ]\n    },\n    \"dataset\": [\n        {\n            \"name\": \"PKLot dataset\",\n            \"modality\": [\"image\"],\n            \"target_variables\": [\"parking spot occupancy\"],\n            \"specification\": {\n                \"model_input\": \"M2Det compatible\"\n            },\n            \"description\": \"A comprehensive dataset for real-time parking spot detection using M2Det in a smart city setting.\",\n            \"preprocessing\": [\n                \"Adaptive to M2Det requirements\"\n            ],\n            \"augmentation\": [\n                \"Low light, adverse weather, and dynamic environment simulators\"\n            ],\n            \"visualization\": [],\n            \"source\": \"user-link\"\n        }\n    ],\n    \"model\": [\n        {\n            \"name\": \"M2Det\",\n            \"family\": \"deep learning\",\n            \"type\": \"neural networks\",\n            \"specification\": {\n                \"architecture\": \"sophisticated variant\",\n                \"scene analysis complexity\": \"multi-level\",\n                \"suitable_conditions\": \"low light, adverse weather, dynamic environments\"\n            },\n            \"description\": \"An advanced object detection model for real-time parking spot detection in M2Det, emphasizing accuracy and efficiency.\"\n        }\n    ],\n    \"knowledge\": [\n        {\n            \"performance goals\": \"real-time processing, robustness, scalability, and energy efficiency\"\n        },\n        {\n            \"application context\": \"smart city, next-generation infrastructure\"\n        },\n        {\n            \"technical challenges\": \"low-light, adverse weather, dynamic environments\"\n        }\n    ],\n    \"service\": {\n        \"feature_engineering\": [],\n        \"target_device\": \"IoT devices, edge computing\",\n        \"deployment_endpoint\": \"city-wide parking management system\",\n        \"inference_engine\": [\"optimized for real-time processing\"],\n        \"demonstration\": \"live parking spot occupancy visualization and recommendations\"\n    },\n    \"confidence\": {\n        \"rationale\": \"The JSON response is created based on the provided instruction, capturing the user's intent for building an advanced parking system, focusing on M2Det, performance metrics, and specific technical requirements. The expertise level is assumed high due to the project manager role. However, actual metric values are not provided, they are placeholders for optimization purposes. The information about the source of the PKLot dataset and the M2Det model's characteristics are inferred from the context.\",\n        \"score\": 0.95\n    }\n}\n"}
